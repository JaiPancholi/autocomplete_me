{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "autocomplete_me",
      "language": "python",
      "name": "autocomplete_me"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "BBC Tech - Trial Own Process.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvWcI8T2eOvw",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNXYErppeOvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ab8b6826-e860-4a5d-9ca2-c72f13488deb"
      },
      "source": [
        "# Google Only\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "ROOT_FOLDER = '/content/drive/My Drive/Code/autocomplete_me/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9p9MmnceOv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Set Variables for Local and Cloud File Finding\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(ROOT_FOLDER)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W397RMzgCvy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2ddb7603-45f5-4053-9813-150fb41c0fc6"
      },
      "source": [
        "!ls -l '/content/drive/My Drive/Code/autocomplete_me/src'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 27\n",
            "-rw------- 1 root root 2516 Jul 14 22:20 predict_utils.py\n",
            "drwx------ 2 root root 4096 Jul 11 13:20 __pycache__\n",
            "-rw------- 1 root root 3340 Jul 15 12:47 reader.py\n",
            "-rw------- 1 root root 3580 Jul 14 22:20 train_model_baseline.py\n",
            "-rw------- 1 root root 3203 Jul 14 22:20 train_utils.py\n",
            "-rw------- 1 root root 9341 Jul 12 14:24 utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fiv0531eOv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ab735948-bcc9-4a1c-cd0e-96fc266132a3"
      },
      "source": [
        "from src import utils, reader, predict_utils, train_utils\n",
        "from importlib import reload\n",
        "reload(utils)\n",
        "reload(reader)\n",
        "reload(predict_utils)\n",
        "reload(train_utils)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'src.train_utils' from '/content/drive/My Drive/Code/autocomplete_me/src/train_utils.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpn1lT4IeOv_",
        "colab_type": "text"
      },
      "source": [
        "## Load Text Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhWMNtqceOv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = reader.read_bbc_tech()\n",
        "content_type = 'BBC-TECH'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YyHF8aQeOwB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "6abeecec-b556-4b4b-cd2b-1161d0e4eab7"
      },
      "source": [
        "text[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'US duo in first spam conviction\\n\\nA brother and sister in the US have been convicted of sending hundreds of thousands of unsolicited e-mail messages to AOL subscribers.\\n\\nIt is the first criminal prosecution of internet spam distributors. Jurors in Virginia recommended that the man, Jeremy Jaynes, serve nine years in prison and that his sister, Jessica DeGroot, be fined $7,500. They were convicted under a state law that bars the sending of bulk e-mails using fake addresses.\\n\\nThey will be formally sentenced next year. A third defendant, Richard Rutkowski, was acquitted. Prosecutors said Jaynes was \"a snake oil salesman in a new format\", using the internet to peddle useless wares, news agency Associated Press reported. A \"Fed-Ex refund processor\" was supposed to allow people to earn $75 an hour working from home. Another item on sale was an \"internet history eraser\". His sister helped him process credit card payments. Jaynes amassed a fortune of $24m from his sales, prosecutors said. \"He\\'s been successful ripping people off all these years,\" AP quoted prosecutor Russell McGuire as saying. Jaynes was also found guilty of breaking a state law which prohibits the sending of more than 100,000 e-mails in 30 days, Virginia State Attorney General Jerry Kilgore reportedly said. Prosecutors had asked for 15 years in jail for Jaynes, and a jail term for his sister. But Jaynes\\' lawyer David Oblon called the nine-year recommended term \"outrageous\" and said his client believed he was innocent. He pointed out that all three of the accused lived in North Carolina and were unaware of the Virginia state law. Spam messages are estimated to account for at least 60% of all e-mails sent.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8y2Nv_MeOwE",
        "colab_type": "text"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Q8y2ILeOwH",
        "colab_type": "text"
      },
      "source": [
        "## Process Text Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtdMjwySG_ep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences, num_words, word_idx, idx_word = train_utils.preprocess_text(text)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESiYIwBkHN7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e30cdb5e-beb9-4dc7-9336-7d3dfd1c3391"
      },
      "source": [
        "features, labels = train_utils.pass_sliding_window(sequences, sequence_len=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 200287 sequences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gny329GmHSMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "afa5a4da-56ca-4beb-ba8f-13b4b98afb0d"
      },
      "source": [
        "labels = train_utils.one_hot_labels_and_improve_efficiency(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels matrix shape:  (200287, 12676)\n",
            "Labels matrix shape:  (200287, 12676)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta46gLn1eOwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Train Tokenizer and Apply\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# # Train\n",
        "# tokenizer = Tokenizer()\n",
        "# tokenizer.fit_on_texts(text)\n",
        "\n",
        "# # Apply Tokenzier on Documents (convert words to numbers)\n",
        "# sequences = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "# word_idx = tokenizer.word_index\n",
        "# num_words = len(word_idx) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIs4QU6ceOwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a797f46d-e0ba-43a1-945e-d2be1be6947c"
      },
      "source": [
        "# # Create Sliding Window\n",
        "# sequence_len = 10\n",
        "\n",
        "# features = []\n",
        "# labels = []\n",
        "\n",
        "# for sequence in sequences:\n",
        "#     for i in range(len(sequence) - sequence_len):\n",
        "#         window = sequence[i:sequence_len + i + 1]\n",
        "        \n",
        "#         features.append(window[:-1])\n",
        "#         labels.append(window[-1])\n",
        "\n",
        "# print(f'There are {len(features)} sequences.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 200287 sequences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqS50wWxeOwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c59224f3-2745-4c6d-d096-3d801a85293b"
      },
      "source": [
        "# # One Hot Encode Labels\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# labels = to_categorical(labels)\n",
        "# print('Labels matrix shape: ', labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels matrix shape:  (200287, 12676)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axQ5cQjnip1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Convert from float to int8\n",
        "# from scipy.sparse import csr_matrix\n",
        "# labels = csr_matrix(labels).astype(np.int8)\n",
        "# labels = labels.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eny8qjVzeOwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Test Train Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# features = np.array(features)\n",
        "# labels = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.20, random_state=42, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x5EeUMbkpPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3e847a3-4b35-443e-fa4b-8ec0e0b39152"
      },
      "source": [
        "import gc\n",
        "gc.enable()\n",
        "del labels\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8N7zK7IeOwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f4aecb22-098e-49bd-da90-c749a6320fcc"
      },
      "source": [
        "print('X_train shape: ', X_train.shape)\n",
        "print('X_test shape: ', X_test.shape)\n",
        "print('y_train shape: ', y_train.shape)\n",
        "print('y_test shape: ', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (160229, 10)\n",
            "X_test shape:  (40058, 10)\n",
            "y_train shape:  (160229, 12676)\n",
            "y_test shape:  (40058, 12676)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOA6uzXKlu0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bb405193-a7a8-4c62-d592-34ea529985d8"
      },
      "source": [
        "import sys\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
        "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
        "        num /= 1024.0\n",
        "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
        "\n",
        "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
        "                         key= lambda x: -x[1])[:10]:\n",
        "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                       y_train:  1.9 GiB\n",
            "                        y_test: 484.3 MiB\n",
            "                      features: 15.3 MiB\n",
            "                       X_train: 12.2 MiB\n",
            "                        X_test:  3.1 MiB\n",
            "                      word_idx: 576.1 KiB\n",
            "                      idx_word: 576.1 KiB\n",
            "                     sequences:  3.5 KiB\n",
            "                          text:  3.2 KiB\n",
            "                            __:  1.7 KiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DROHQO32eOwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "66ec7666-716e-4bb6-d7f6-89c9af02f09e"
      },
      "source": [
        "# Embedding Matrix\n",
        "# embedding_matrix = utils.create_embedding_matrix(word_idx, num_words, '/Users/jaipancholi/data/glove.6B.100d.txt')\n",
        "embedding_matrix = utils.create_embedding_matrix(word_idx, num_words, '/content/drive/My Drive/Code/autocomplete_me/data/glove.6B.100d.txt')\n",
        "embedding_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove Vectors loading with dimension 100\n",
            "There were 1062 words without pre-trained embeddings.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/src/utils.py:180: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.00656124, -0.04206555,  0.12508174, ..., -0.02506376,\n",
              "         0.14220549,  0.04648907],\n",
              "       [-0.02940788,  0.00775488,  0.02958461, ..., -0.0617054 ,\n",
              "         0.07386386, -0.02477734],\n",
              "       ...,\n",
              "       [-0.0030414 ,  0.07376623,  0.15909794, ..., -0.01099743,\n",
              "        -0.13780413,  0.04205515],\n",
              "       [-0.02349926, -0.06641477, -0.01852101, ...,  0.07821092,\n",
              "         0.12694902,  0.1010958 ],\n",
              "       [ 0.02721107,  0.00886596,  0.24643607, ...,  0.02826212,\n",
              "         0.23311737,  0.06475616]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IZp-EmFeOwY",
        "colab_type": "text"
      },
      "source": [
        "# Design Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1eSpudQeOwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13UN0ktV_pSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath('')))\n",
        "# # MODELS_DIR = os.path.join(ROOT_DIR, 'models')\n",
        "# MODELS_DIR = '/content/drive/My Drive/Code/autocomplete_me/models'\n",
        "# print(MODELS_DIR)\n",
        "\n",
        "# DATASET = 'BBC-TECH'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZOti2z7JJW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(filepath, X_train, y_train, X_test, y_test, use_pretrained_model=False, model=False, epochs=100):\n",
        "  if not model and not use_pretrained_model:\n",
        "    print('Provide one of either model or use_pretrained_model.')\n",
        "  elif model and use_pretrained_model:\n",
        "      print('Provide one of either model or use_pretrained_model.')\n",
        "  elif use_pretrained_model:\n",
        "    model = load_model(model_filepath)\n",
        "  \n",
        "  callbacks = [\n",
        "      EarlyStopping(monitor='val_accuracy', patience=25),\n",
        "      ModelCheckpoint(f'{model_filepath}', save_best_only=True, save_weights_only=False, monitor='val_accuracy')\n",
        "  ]\n",
        "\n",
        "  history = model.fit(\n",
        "      X_train, \n",
        "      y_train, \n",
        "      epochs=epochs, \n",
        "      batch_size=2048, \n",
        "      validation_data=(X_test, y_test), \n",
        "      verbose=1,\n",
        "      callbacks=callbacks\n",
        "  )\n",
        "\n",
        "  return history\n",
        "\n",
        "# model_filename = f'{DATASET}-custom-1.h5'\n",
        "# model_filepath = os.path.join(MODELS_DIR, model_filename)\n",
        "# print(model_filepath)\n",
        "# # model = load_model(model_filepath)\n",
        "\n",
        "# callbacks = [\n",
        "#     EarlyStopping(monitor='val_accuracy', patience=25),\n",
        "#     ModelCheckpoint(f'{model_filepath}', save_best_only=True, save_weights_only=False, monitor='val_accuracy')\n",
        "# ]\n",
        "\n",
        "# EPOCHS = 100\n",
        "\n",
        "# history = model.fit(\n",
        "#     X_train, \n",
        "#     y_train, \n",
        "#     epochs=EPOCHS, \n",
        "#     batch_size=2048, \n",
        "#     validation_data=(X_test, y_test), \n",
        "#     verbose=1,\n",
        "#     callbacks=callbacks\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHNsyM7H_qkC",
        "colab_type": "text"
      },
      "source": [
        "##V1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoT44K4meOwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(    \n",
        "    Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=embedding_matrix.shape[1],\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=True)\n",
        ")\n",
        "\n",
        "model.add(LSTM(64))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(num_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBtAHhA1eOwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aea4e1bd-b5bc-4ee5-d168-a42c2731c63a"
      },
      "source": [
        "# model_filename = f'{DATASET}-custom-1.h5'\n",
        "# model_filepath = os.path.join(MODELS_DIR, model_filename)\n",
        "# print(model_filepath)\n",
        "# # model = load_model(model_filepath)\n",
        "\n",
        "# callbacks = [\n",
        "#     EarlyStopping(monitor='val_accuracy', patience=25),\n",
        "#     ModelCheckpoint(f'{model_filepath}', save_best_only=True, save_weights_only=False, monitor='val_accuracy')\n",
        "# ]\n",
        "\n",
        "# EPOCHS = 100\n",
        "\n",
        "# history = model.fit(\n",
        "#     X_train, \n",
        "#     y_train, \n",
        "#     epochs=EPOCHS, \n",
        "#     batch_size=2048, \n",
        "#     validation_data=(X_test, y_test), \n",
        "#     verbose=1,\n",
        "#     callbacks=callbacks\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/models/BBC-TECH-custom-1.h5\n",
            "Epoch 1/100\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.7991 - accuracy: 0.7838 - val_loss: 15.4740 - val_accuracy: 0.3160\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.8123 - accuracy: 0.7799 - val_loss: 15.4353 - val_accuracy: 0.3168\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 6s 81ms/step - loss: 0.8044 - accuracy: 0.7830 - val_loss: 15.4022 - val_accuracy: 0.3168\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 6s 81ms/step - loss: 0.8072 - accuracy: 0.7814 - val_loss: 15.3841 - val_accuracy: 0.3173\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 6s 81ms/step - loss: 0.8054 - accuracy: 0.7816 - val_loss: 15.3953 - val_accuracy: 0.3180\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7968 - accuracy: 0.7840 - val_loss: 15.4555 - val_accuracy: 0.3162\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7976 - accuracy: 0.7832 - val_loss: 15.4852 - val_accuracy: 0.3175\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7932 - accuracy: 0.7862 - val_loss: 15.4751 - val_accuracy: 0.3177\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7946 - accuracy: 0.7852 - val_loss: 15.4777 - val_accuracy: 0.3178\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7982 - accuracy: 0.7843 - val_loss: 15.5425 - val_accuracy: 0.3171\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7934 - accuracy: 0.7845 - val_loss: 15.4654 - val_accuracy: 0.3174\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7961 - accuracy: 0.7851 - val_loss: 15.4784 - val_accuracy: 0.3182\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7881 - accuracy: 0.7865 - val_loss: 15.5655 - val_accuracy: 0.3162\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.7855 - accuracy: 0.7867 - val_loss: 15.6001 - val_accuracy: 0.3188\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 6s 82ms/step - loss: 0.7847 - accuracy: 0.7871 - val_loss: 15.6541 - val_accuracy: 0.3193\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7883 - accuracy: 0.7855 - val_loss: 15.5293 - val_accuracy: 0.3193\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7829 - accuracy: 0.7879 - val_loss: 15.5686 - val_accuracy: 0.3186\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7851 - accuracy: 0.7867 - val_loss: 15.6022 - val_accuracy: 0.3182\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7762 - accuracy: 0.7882 - val_loss: 15.6040 - val_accuracy: 0.3186\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7881 - accuracy: 0.7869 - val_loss: 15.6819 - val_accuracy: 0.3181\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7804 - accuracy: 0.7870 - val_loss: 15.6393 - val_accuracy: 0.3184\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7800 - accuracy: 0.7887 - val_loss: 15.6784 - val_accuracy: 0.3192\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7785 - accuracy: 0.7891 - val_loss: 15.6348 - val_accuracy: 0.3192\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7776 - accuracy: 0.7888 - val_loss: 15.6010 - val_accuracy: 0.3188\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7723 - accuracy: 0.7901 - val_loss: 15.6430 - val_accuracy: 0.3182\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7754 - accuracy: 0.7890 - val_loss: 15.6752 - val_accuracy: 0.3178\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7729 - accuracy: 0.7887 - val_loss: 15.7184 - val_accuracy: 0.3184\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7704 - accuracy: 0.7905 - val_loss: 15.6989 - val_accuracy: 0.3189\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7691 - accuracy: 0.7914 - val_loss: 15.7191 - val_accuracy: 0.3185\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7636 - accuracy: 0.7919 - val_loss: 15.7136 - val_accuracy: 0.3188\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7634 - accuracy: 0.7916 - val_loss: 15.7957 - val_accuracy: 0.3193\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7683 - accuracy: 0.7906 - val_loss: 15.7685 - val_accuracy: 0.3188\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7626 - accuracy: 0.7933 - val_loss: 15.8052 - val_accuracy: 0.3190\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.7608 - accuracy: 0.7933 - val_loss: 15.7667 - val_accuracy: 0.3199\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 7s 83ms/step - loss: 0.7613 - accuracy: 0.7922 - val_loss: 15.8178 - val_accuracy: 0.3204\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7572 - accuracy: 0.7939 - val_loss: 15.8529 - val_accuracy: 0.3189\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7574 - accuracy: 0.7937 - val_loss: 15.8178 - val_accuracy: 0.3196\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7537 - accuracy: 0.7927 - val_loss: 15.8034 - val_accuracy: 0.3193\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7609 - accuracy: 0.7926 - val_loss: 15.7914 - val_accuracy: 0.3198\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.7615 - accuracy: 0.7936 - val_loss: 15.8210 - val_accuracy: 0.3206\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7505 - accuracy: 0.7958 - val_loss: 15.8445 - val_accuracy: 0.3200\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7506 - accuracy: 0.7959 - val_loss: 15.8359 - val_accuracy: 0.3186\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7504 - accuracy: 0.7946 - val_loss: 15.8376 - val_accuracy: 0.3205\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.7458 - accuracy: 0.7954 - val_loss: 15.8366 - val_accuracy: 0.3214\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7393 - accuracy: 0.7975 - val_loss: 15.9246 - val_accuracy: 0.3207\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7458 - accuracy: 0.7957 - val_loss: 15.9479 - val_accuracy: 0.3200\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7427 - accuracy: 0.7971 - val_loss: 15.9495 - val_accuracy: 0.3211\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7461 - accuracy: 0.7964 - val_loss: 15.9242 - val_accuracy: 0.3214\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7430 - accuracy: 0.7975 - val_loss: 15.9115 - val_accuracy: 0.3213\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7414 - accuracy: 0.7973 - val_loss: 15.8785 - val_accuracy: 0.3196\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7390 - accuracy: 0.7984 - val_loss: 15.9250 - val_accuracy: 0.3198\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7368 - accuracy: 0.7973 - val_loss: 15.9053 - val_accuracy: 0.3195\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7302 - accuracy: 0.8000 - val_loss: 15.9368 - val_accuracy: 0.3206\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7374 - accuracy: 0.7987 - val_loss: 15.9152 - val_accuracy: 0.3211\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7387 - accuracy: 0.7971 - val_loss: 15.9523 - val_accuracy: 0.3208\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7368 - accuracy: 0.7983 - val_loss: 15.9531 - val_accuracy: 0.3206\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.7338 - accuracy: 0.7990 - val_loss: 15.9650 - val_accuracy: 0.3215\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7308 - accuracy: 0.8006 - val_loss: 16.0543 - val_accuracy: 0.3211\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7278 - accuracy: 0.8010 - val_loss: 15.9872 - val_accuracy: 0.3210\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7303 - accuracy: 0.8004 - val_loss: 16.0214 - val_accuracy: 0.3214\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.7244 - accuracy: 0.8022 - val_loss: 16.0085 - val_accuracy: 0.3222\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7305 - accuracy: 0.7994 - val_loss: 15.9835 - val_accuracy: 0.3204\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7289 - accuracy: 0.8007 - val_loss: 16.0656 - val_accuracy: 0.3217\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7269 - accuracy: 0.7999 - val_loss: 16.0867 - val_accuracy: 0.3209\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7262 - accuracy: 0.8009 - val_loss: 16.0850 - val_accuracy: 0.3213\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7201 - accuracy: 0.8024 - val_loss: 16.0809 - val_accuracy: 0.3219\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.7216 - accuracy: 0.8033 - val_loss: 16.0664 - val_accuracy: 0.3226\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 6s 81ms/step - loss: 0.7171 - accuracy: 0.8029 - val_loss: 16.1274 - val_accuracy: 0.3226\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7135 - accuracy: 0.8042 - val_loss: 16.1459 - val_accuracy: 0.3219\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7130 - accuracy: 0.8042 - val_loss: 16.0809 - val_accuracy: 0.3210\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7119 - accuracy: 0.8051 - val_loss: 16.0964 - val_accuracy: 0.3213\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7153 - accuracy: 0.8028 - val_loss: 16.1224 - val_accuracy: 0.3218\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7150 - accuracy: 0.8041 - val_loss: 16.1862 - val_accuracy: 0.3222\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7125 - accuracy: 0.8039 - val_loss: 16.2270 - val_accuracy: 0.3223\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.7079 - accuracy: 0.8066 - val_loss: 16.1604 - val_accuracy: 0.3233\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.7036 - accuracy: 0.8072 - val_loss: 16.2337 - val_accuracy: 0.3231\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7041 - accuracy: 0.8063 - val_loss: 16.1478 - val_accuracy: 0.3219\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7033 - accuracy: 0.8066 - val_loss: 16.1663 - val_accuracy: 0.3211\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7061 - accuracy: 0.8068 - val_loss: 16.2495 - val_accuracy: 0.3212\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7026 - accuracy: 0.8059 - val_loss: 16.1316 - val_accuracy: 0.3222\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7046 - accuracy: 0.8065 - val_loss: 16.1805 - val_accuracy: 0.3219\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7014 - accuracy: 0.8069 - val_loss: 16.1678 - val_accuracy: 0.3232\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7020 - accuracy: 0.8069 - val_loss: 16.2603 - val_accuracy: 0.3230\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.6994 - accuracy: 0.8071 - val_loss: 16.2996 - val_accuracy: 0.3215\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7064 - accuracy: 0.8054 - val_loss: 16.3277 - val_accuracy: 0.3218\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7014 - accuracy: 0.8066 - val_loss: 16.3058 - val_accuracy: 0.3214\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.7034 - accuracy: 0.8070 - val_loss: 16.3030 - val_accuracy: 0.3223\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.7062 - accuracy: 0.8069 - val_loss: 16.2075 - val_accuracy: 0.3223\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.6961 - accuracy: 0.8081 - val_loss: 16.2411 - val_accuracy: 0.3227\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.6982 - accuracy: 0.8077 - val_loss: 16.2885 - val_accuracy: 0.3229\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.6972 - accuracy: 0.8081 - val_loss: 16.3686 - val_accuracy: 0.3232\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.6913 - accuracy: 0.8108 - val_loss: 16.3535 - val_accuracy: 0.3229\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 6s 78ms/step - loss: 0.6947 - accuracy: 0.8095 - val_loss: 16.3334 - val_accuracy: 0.3228\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.6942 - accuracy: 0.8094 - val_loss: 16.2858 - val_accuracy: 0.3231\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.6898 - accuracy: 0.8103 - val_loss: 16.3458 - val_accuracy: 0.3230\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6925 - accuracy: 0.8092 - val_loss: 16.3653 - val_accuracy: 0.3235\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 6s 81ms/step - loss: 0.6857 - accuracy: 0.8104 - val_loss: 16.4038 - val_accuracy: 0.3236\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.6884 - accuracy: 0.8104 - val_loss: 16.3824 - val_accuracy: 0.3236\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.6858 - accuracy: 0.8117 - val_loss: 16.3392 - val_accuracy: 0.3230\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 6s 80ms/step - loss: 0.6838 - accuracy: 0.8110 - val_loss: 16.4351 - val_accuracy: 0.3229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt3pRn4k_2Jx",
        "colab_type": "text"
      },
      "source": [
        "## V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSI6BxH5ALw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(    \n",
        "    Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=embedding_matrix.shape[1],\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=True)\n",
        ")\n",
        "\n",
        "model.add(LSTM(256))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(num_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfRMwq-rALzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44a331c4-76ac-48e2-bee6-c60f46b141fc"
      },
      "source": [
        "# model_filename = f'{DATASET}-custom-2.h5'\n",
        "# model_filepath = os.path.join(MODELS_DIR, model_filename)\n",
        "# print(model_filepath)\n",
        "# # model = load_model(model_filepath)\n",
        "\n",
        "# callbacks = [\n",
        "#     EarlyStopping(monitor='val_accuracy', patience=25),\n",
        "#     ModelCheckpoint(f'{model_filepath}', save_best_only=True, save_weights_only=False, monitor='val_accuracy')\n",
        "# ]\n",
        "\n",
        "# EPOCHS = 500\n",
        "\n",
        "# history = model.fit(\n",
        "#     X_train, \n",
        "#     y_train, \n",
        "#     epochs=EPOCHS, \n",
        "#     batch_size=2048, \n",
        "#     validation_data=(X_test, y_test), \n",
        "#     verbose=1,\n",
        "#     callbacks=callbacks\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/models/BBC-TECH-custom-2.h5\n",
            "Epoch 1/500\n",
            "79/79 [==============================] - 8s 96ms/step - loss: 7.4905 - accuracy: 0.0493 - val_loss: 7.0584 - val_accuracy: 0.0571\n",
            "Epoch 2/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 6.9629 - accuracy: 0.0578 - val_loss: 6.9854 - val_accuracy: 0.0571\n",
            "Epoch 3/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 6.8698 - accuracy: 0.0607 - val_loss: 6.9367 - val_accuracy: 0.0673\n",
            "Epoch 4/500\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 6.7601 - accuracy: 0.0689 - val_loss: 6.8343 - val_accuracy: 0.0698\n",
            "Epoch 5/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 6.6199 - accuracy: 0.0782 - val_loss: 6.7341 - val_accuracy: 0.0800\n",
            "Epoch 6/500\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 6.4742 - accuracy: 0.0903 - val_loss: 6.6371 - val_accuracy: 0.0937\n",
            "Epoch 7/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 6.3232 - accuracy: 0.1010 - val_loss: 6.5465 - val_accuracy: 0.1021\n",
            "Epoch 8/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 6.1815 - accuracy: 0.1100 - val_loss: 6.4874 - val_accuracy: 0.1065\n",
            "Epoch 9/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 6.0602 - accuracy: 0.1170 - val_loss: 6.4424 - val_accuracy: 0.1126\n",
            "Epoch 10/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.9454 - accuracy: 0.1246 - val_loss: 6.4135 - val_accuracy: 0.1174\n",
            "Epoch 11/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.8409 - accuracy: 0.1309 - val_loss: 6.3892 - val_accuracy: 0.1225\n",
            "Epoch 12/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 5.7452 - accuracy: 0.1365 - val_loss: 6.3787 - val_accuracy: 0.1261\n",
            "Epoch 13/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.6544 - accuracy: 0.1410 - val_loss: 6.3690 - val_accuracy: 0.1292\n",
            "Epoch 14/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.5662 - accuracy: 0.1460 - val_loss: 6.3686 - val_accuracy: 0.1309\n",
            "Epoch 15/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.4837 - accuracy: 0.1504 - val_loss: 6.3724 - val_accuracy: 0.1332\n",
            "Epoch 16/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.4017 - accuracy: 0.1533 - val_loss: 6.3846 - val_accuracy: 0.1354\n",
            "Epoch 17/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.3265 - accuracy: 0.1567 - val_loss: 6.3864 - val_accuracy: 0.1387\n",
            "Epoch 18/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.2500 - accuracy: 0.1610 - val_loss: 6.4127 - val_accuracy: 0.1394\n",
            "Epoch 19/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 5.1767 - accuracy: 0.1647 - val_loss: 6.4329 - val_accuracy: 0.1405\n",
            "Epoch 20/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 5.1038 - accuracy: 0.1689 - val_loss: 6.4513 - val_accuracy: 0.1439\n",
            "Epoch 21/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 5.0337 - accuracy: 0.1727 - val_loss: 6.4711 - val_accuracy: 0.1447\n",
            "Epoch 22/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 4.9608 - accuracy: 0.1774 - val_loss: 6.5016 - val_accuracy: 0.1471\n",
            "Epoch 23/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 4.8934 - accuracy: 0.1814 - val_loss: 6.5233 - val_accuracy: 0.1490\n",
            "Epoch 24/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 4.8246 - accuracy: 0.1855 - val_loss: 6.5483 - val_accuracy: 0.1504\n",
            "Epoch 25/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 4.7547 - accuracy: 0.1892 - val_loss: 6.5916 - val_accuracy: 0.1538\n",
            "Epoch 26/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 4.6898 - accuracy: 0.1945 - val_loss: 6.6249 - val_accuracy: 0.1549\n",
            "Epoch 27/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 4.6247 - accuracy: 0.1999 - val_loss: 6.6632 - val_accuracy: 0.1552\n",
            "Epoch 28/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 4.5602 - accuracy: 0.2038 - val_loss: 6.7006 - val_accuracy: 0.1581\n",
            "Epoch 29/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 4.4979 - accuracy: 0.2083 - val_loss: 6.7274 - val_accuracy: 0.1581\n",
            "Epoch 30/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 4.4411 - accuracy: 0.2131 - val_loss: 6.7679 - val_accuracy: 0.1601\n",
            "Epoch 31/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 4.3813 - accuracy: 0.2178 - val_loss: 6.7998 - val_accuracy: 0.1608\n",
            "Epoch 32/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 4.3251 - accuracy: 0.2227 - val_loss: 6.8609 - val_accuracy: 0.1623\n",
            "Epoch 33/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 4.2698 - accuracy: 0.2280 - val_loss: 6.8800 - val_accuracy: 0.1623\n",
            "Epoch 34/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 4.2164 - accuracy: 0.2330 - val_loss: 6.9257 - val_accuracy: 0.1646\n",
            "Epoch 35/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 4.1606 - accuracy: 0.2377 - val_loss: 6.9789 - val_accuracy: 0.1656\n",
            "Epoch 36/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 4.1093 - accuracy: 0.2424 - val_loss: 7.0098 - val_accuracy: 0.1654\n",
            "Epoch 37/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 4.0598 - accuracy: 0.2469 - val_loss: 7.0461 - val_accuracy: 0.1677\n",
            "Epoch 38/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 4.0096 - accuracy: 0.2527 - val_loss: 7.1057 - val_accuracy: 0.1678\n",
            "Epoch 39/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.9598 - accuracy: 0.2580 - val_loss: 7.1499 - val_accuracy: 0.1695\n",
            "Epoch 40/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.9079 - accuracy: 0.2632 - val_loss: 7.2089 - val_accuracy: 0.1703\n",
            "Epoch 41/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 3.8661 - accuracy: 0.2673 - val_loss: 7.2504 - val_accuracy: 0.1728\n",
            "Epoch 42/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 3.8164 - accuracy: 0.2728 - val_loss: 7.2952 - val_accuracy: 0.1722\n",
            "Epoch 43/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 3.7720 - accuracy: 0.2771 - val_loss: 7.3414 - val_accuracy: 0.1736\n",
            "Epoch 44/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.7279 - accuracy: 0.2832 - val_loss: 7.3797 - val_accuracy: 0.1762\n",
            "Epoch 45/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.6832 - accuracy: 0.2877 - val_loss: 7.4484 - val_accuracy: 0.1746\n",
            "Epoch 46/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 3.6428 - accuracy: 0.2923 - val_loss: 7.5075 - val_accuracy: 0.1776\n",
            "Epoch 47/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 3.5997 - accuracy: 0.2985 - val_loss: 7.5435 - val_accuracy: 0.1785\n",
            "Epoch 48/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 3.5544 - accuracy: 0.3040 - val_loss: 7.5978 - val_accuracy: 0.1777\n",
            "Epoch 49/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 3.5183 - accuracy: 0.3072 - val_loss: 7.6468 - val_accuracy: 0.1791\n",
            "Epoch 50/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 3.4785 - accuracy: 0.3118 - val_loss: 7.6956 - val_accuracy: 0.1811\n",
            "Epoch 51/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 3.4378 - accuracy: 0.3174 - val_loss: 7.7545 - val_accuracy: 0.1808\n",
            "Epoch 52/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 3.3994 - accuracy: 0.3228 - val_loss: 7.7902 - val_accuracy: 0.1839\n",
            "Epoch 53/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.3582 - accuracy: 0.3275 - val_loss: 7.8375 - val_accuracy: 0.1836\n",
            "Epoch 54/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 3.3241 - accuracy: 0.3327 - val_loss: 7.8905 - val_accuracy: 0.1868\n",
            "Epoch 55/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.2861 - accuracy: 0.3358 - val_loss: 7.9473 - val_accuracy: 0.1846\n",
            "Epoch 56/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 3.2499 - accuracy: 0.3420 - val_loss: 7.9968 - val_accuracy: 0.1883\n",
            "Epoch 57/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.2112 - accuracy: 0.3463 - val_loss: 8.0583 - val_accuracy: 0.1877\n",
            "Epoch 58/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 3.1774 - accuracy: 0.3517 - val_loss: 8.1146 - val_accuracy: 0.1905\n",
            "Epoch 59/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 3.1448 - accuracy: 0.3552 - val_loss: 8.1940 - val_accuracy: 0.1903\n",
            "Epoch 60/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 3.1100 - accuracy: 0.3608 - val_loss: 8.2046 - val_accuracy: 0.1908\n",
            "Epoch 61/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.0751 - accuracy: 0.3663 - val_loss: 8.2952 - val_accuracy: 0.1924\n",
            "Epoch 62/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.0398 - accuracy: 0.3711 - val_loss: 8.3177 - val_accuracy: 0.1915\n",
            "Epoch 63/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.0114 - accuracy: 0.3743 - val_loss: 8.3755 - val_accuracy: 0.1923\n",
            "Epoch 64/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.9790 - accuracy: 0.3794 - val_loss: 8.4078 - val_accuracy: 0.1916\n",
            "Epoch 65/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 2.9490 - accuracy: 0.3834 - val_loss: 8.4722 - val_accuracy: 0.1934\n",
            "Epoch 66/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.9160 - accuracy: 0.3887 - val_loss: 8.5164 - val_accuracy: 0.1931\n",
            "Epoch 67/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 2.8855 - accuracy: 0.3928 - val_loss: 8.5934 - val_accuracy: 0.1941\n",
            "Epoch 68/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 2.8565 - accuracy: 0.3975 - val_loss: 8.6399 - val_accuracy: 0.1976\n",
            "Epoch 69/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.8250 - accuracy: 0.4024 - val_loss: 8.6988 - val_accuracy: 0.2003\n",
            "Epoch 70/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 2.7925 - accuracy: 0.4065 - val_loss: 8.7677 - val_accuracy: 0.2003\n",
            "Epoch 71/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.7688 - accuracy: 0.4104 - val_loss: 8.8171 - val_accuracy: 0.1997\n",
            "Epoch 72/500\n",
            "79/79 [==============================] - 9s 111ms/step - loss: 2.7420 - accuracy: 0.4140 - val_loss: 8.8672 - val_accuracy: 0.2012\n",
            "Epoch 73/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.7130 - accuracy: 0.4192 - val_loss: 8.9135 - val_accuracy: 0.2003\n",
            "Epoch 74/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 2.6824 - accuracy: 0.4232 - val_loss: 8.9753 - val_accuracy: 0.2014\n",
            "Epoch 75/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 2.6582 - accuracy: 0.4264 - val_loss: 9.0171 - val_accuracy: 0.2024\n",
            "Epoch 76/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 2.6349 - accuracy: 0.4313 - val_loss: 9.0503 - val_accuracy: 0.2034\n",
            "Epoch 77/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 2.6045 - accuracy: 0.4357 - val_loss: 9.1439 - val_accuracy: 0.2063\n",
            "Epoch 78/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.5759 - accuracy: 0.4396 - val_loss: 9.1587 - val_accuracy: 0.2077\n",
            "Epoch 79/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.5509 - accuracy: 0.4441 - val_loss: 9.2478 - val_accuracy: 0.2082\n",
            "Epoch 80/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.5217 - accuracy: 0.4496 - val_loss: 9.3159 - val_accuracy: 0.2079\n",
            "Epoch 81/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 2.4991 - accuracy: 0.4520 - val_loss: 9.3473 - val_accuracy: 0.2105\n",
            "Epoch 82/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.4760 - accuracy: 0.4568 - val_loss: 9.3834 - val_accuracy: 0.2103\n",
            "Epoch 83/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 2.4554 - accuracy: 0.4601 - val_loss: 9.4927 - val_accuracy: 0.2123\n",
            "Epoch 84/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.4252 - accuracy: 0.4644 - val_loss: 9.4870 - val_accuracy: 0.2141\n",
            "Epoch 85/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.4026 - accuracy: 0.4690 - val_loss: 9.5814 - val_accuracy: 0.2132\n",
            "Epoch 86/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 2.3761 - accuracy: 0.4736 - val_loss: 9.6240 - val_accuracy: 0.2150\n",
            "Epoch 87/500\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 2.3556 - accuracy: 0.4764 - val_loss: 9.7181 - val_accuracy: 0.2153\n",
            "Epoch 88/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.3294 - accuracy: 0.4822 - val_loss: 9.7784 - val_accuracy: 0.2153\n",
            "Epoch 89/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 2.3104 - accuracy: 0.4835 - val_loss: 9.8049 - val_accuracy: 0.2204\n",
            "Epoch 90/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.2838 - accuracy: 0.4890 - val_loss: 9.8610 - val_accuracy: 0.2181\n",
            "Epoch 91/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.2631 - accuracy: 0.4932 - val_loss: 9.9718 - val_accuracy: 0.2194\n",
            "Epoch 92/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 2.2381 - accuracy: 0.4970 - val_loss: 10.0086 - val_accuracy: 0.2224\n",
            "Epoch 93/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.2212 - accuracy: 0.5004 - val_loss: 10.0586 - val_accuracy: 0.2233\n",
            "Epoch 94/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.1947 - accuracy: 0.5049 - val_loss: 10.0615 - val_accuracy: 0.2233\n",
            "Epoch 95/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 2.1770 - accuracy: 0.5070 - val_loss: 10.1553 - val_accuracy: 0.2241\n",
            "Epoch 96/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 2.1505 - accuracy: 0.5133 - val_loss: 10.2104 - val_accuracy: 0.2247\n",
            "Epoch 97/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.1276 - accuracy: 0.5161 - val_loss: 10.2756 - val_accuracy: 0.2258\n",
            "Epoch 98/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.1123 - accuracy: 0.5187 - val_loss: 10.3601 - val_accuracy: 0.2284\n",
            "Epoch 99/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.0911 - accuracy: 0.5237 - val_loss: 10.3654 - val_accuracy: 0.2276\n",
            "Epoch 100/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 2.0705 - accuracy: 0.5265 - val_loss: 10.4749 - val_accuracy: 0.2296\n",
            "Epoch 101/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 2.0436 - accuracy: 0.5319 - val_loss: 10.5675 - val_accuracy: 0.2299\n",
            "Epoch 102/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.0310 - accuracy: 0.5339 - val_loss: 10.5539 - val_accuracy: 0.2315\n",
            "Epoch 103/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 2.0051 - accuracy: 0.5383 - val_loss: 10.6721 - val_accuracy: 0.2333\n",
            "Epoch 104/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.9877 - accuracy: 0.5409 - val_loss: 10.7323 - val_accuracy: 0.2331\n",
            "Epoch 105/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.9673 - accuracy: 0.5459 - val_loss: 10.7086 - val_accuracy: 0.2334\n",
            "Epoch 106/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.9453 - accuracy: 0.5506 - val_loss: 10.8256 - val_accuracy: 0.2358\n",
            "Epoch 107/500\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 1.9251 - accuracy: 0.5536 - val_loss: 10.8719 - val_accuracy: 0.2383\n",
            "Epoch 108/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.9118 - accuracy: 0.5554 - val_loss: 10.9713 - val_accuracy: 0.2369\n",
            "Epoch 109/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.8914 - accuracy: 0.5597 - val_loss: 11.0346 - val_accuracy: 0.2380\n",
            "Epoch 110/500\n",
            "79/79 [==============================] - 8s 104ms/step - loss: 1.8741 - accuracy: 0.5629 - val_loss: 11.1095 - val_accuracy: 0.2407\n",
            "Epoch 111/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.8579 - accuracy: 0.5650 - val_loss: 11.1549 - val_accuracy: 0.2400\n",
            "Epoch 112/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 1.8380 - accuracy: 0.5705 - val_loss: 11.1556 - val_accuracy: 0.2428\n",
            "Epoch 113/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.8168 - accuracy: 0.5742 - val_loss: 11.2385 - val_accuracy: 0.2431\n",
            "Epoch 114/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.7953 - accuracy: 0.5779 - val_loss: 11.3812 - val_accuracy: 0.2434\n",
            "Epoch 115/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 1.7767 - accuracy: 0.5807 - val_loss: 11.3633 - val_accuracy: 0.2438\n",
            "Epoch 116/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.7651 - accuracy: 0.5833 - val_loss: 11.4241 - val_accuracy: 0.2457\n",
            "Epoch 117/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.7441 - accuracy: 0.5876 - val_loss: 11.5153 - val_accuracy: 0.2484\n",
            "Epoch 118/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.7294 - accuracy: 0.5900 - val_loss: 11.5575 - val_accuracy: 0.2480\n",
            "Epoch 119/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.7093 - accuracy: 0.5936 - val_loss: 11.5689 - val_accuracy: 0.2475\n",
            "Epoch 120/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.6941 - accuracy: 0.5963 - val_loss: 11.6278 - val_accuracy: 0.2501\n",
            "Epoch 121/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.6779 - accuracy: 0.5991 - val_loss: 11.7060 - val_accuracy: 0.2504\n",
            "Epoch 122/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.6640 - accuracy: 0.6024 - val_loss: 11.7469 - val_accuracy: 0.2522\n",
            "Epoch 123/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.6407 - accuracy: 0.6083 - val_loss: 11.8073 - val_accuracy: 0.2543\n",
            "Epoch 124/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.6264 - accuracy: 0.6112 - val_loss: 11.9269 - val_accuracy: 0.2554\n",
            "Epoch 125/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.6095 - accuracy: 0.6131 - val_loss: 11.9455 - val_accuracy: 0.2542\n",
            "Epoch 126/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.5929 - accuracy: 0.6178 - val_loss: 11.9865 - val_accuracy: 0.2576\n",
            "Epoch 127/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.5752 - accuracy: 0.6209 - val_loss: 12.1151 - val_accuracy: 0.2572\n",
            "Epoch 128/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.5587 - accuracy: 0.6233 - val_loss: 12.1560 - val_accuracy: 0.2567\n",
            "Epoch 129/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 1.5469 - accuracy: 0.6260 - val_loss: 12.2493 - val_accuracy: 0.2610\n",
            "Epoch 130/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.5374 - accuracy: 0.6282 - val_loss: 12.2741 - val_accuracy: 0.2593\n",
            "Epoch 131/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.5124 - accuracy: 0.6323 - val_loss: 12.3699 - val_accuracy: 0.2611\n",
            "Epoch 132/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.5035 - accuracy: 0.6346 - val_loss: 12.3919 - val_accuracy: 0.2635\n",
            "Epoch 133/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.4903 - accuracy: 0.6375 - val_loss: 12.4724 - val_accuracy: 0.2627\n",
            "Epoch 134/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.4729 - accuracy: 0.6416 - val_loss: 12.5498 - val_accuracy: 0.2627\n",
            "Epoch 135/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.4546 - accuracy: 0.6458 - val_loss: 12.5754 - val_accuracy: 0.2645\n",
            "Epoch 136/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.4429 - accuracy: 0.6483 - val_loss: 12.6280 - val_accuracy: 0.2641\n",
            "Epoch 137/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 1.4274 - accuracy: 0.6512 - val_loss: 12.7275 - val_accuracy: 0.2674\n",
            "Epoch 138/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.4123 - accuracy: 0.6530 - val_loss: 12.6854 - val_accuracy: 0.2667\n",
            "Epoch 139/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 1.4007 - accuracy: 0.6554 - val_loss: 12.8051 - val_accuracy: 0.2683\n",
            "Epoch 140/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.3823 - accuracy: 0.6610 - val_loss: 12.8211 - val_accuracy: 0.2684\n",
            "Epoch 141/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.3708 - accuracy: 0.6616 - val_loss: 12.9514 - val_accuracy: 0.2702\n",
            "Epoch 142/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.3609 - accuracy: 0.6646 - val_loss: 12.9473 - val_accuracy: 0.2700\n",
            "Epoch 143/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 1.3440 - accuracy: 0.6679 - val_loss: 13.0604 - val_accuracy: 0.2712\n",
            "Epoch 144/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.3291 - accuracy: 0.6698 - val_loss: 13.1110 - val_accuracy: 0.2733\n",
            "Epoch 145/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.3209 - accuracy: 0.6730 - val_loss: 13.1750 - val_accuracy: 0.2727\n",
            "Epoch 146/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.3009 - accuracy: 0.6763 - val_loss: 13.2780 - val_accuracy: 0.2743\n",
            "Epoch 147/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.2899 - accuracy: 0.6784 - val_loss: 13.3155 - val_accuracy: 0.2754\n",
            "Epoch 148/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.2808 - accuracy: 0.6796 - val_loss: 13.3773 - val_accuracy: 0.2751\n",
            "Epoch 149/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.2679 - accuracy: 0.6845 - val_loss: 13.4752 - val_accuracy: 0.2748\n",
            "Epoch 150/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 1.2513 - accuracy: 0.6878 - val_loss: 13.4867 - val_accuracy: 0.2775\n",
            "Epoch 151/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.2434 - accuracy: 0.6884 - val_loss: 13.5976 - val_accuracy: 0.2767\n",
            "Epoch 152/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.2311 - accuracy: 0.6910 - val_loss: 13.5999 - val_accuracy: 0.2793\n",
            "Epoch 153/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.2153 - accuracy: 0.6953 - val_loss: 13.6743 - val_accuracy: 0.2790\n",
            "Epoch 154/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.2075 - accuracy: 0.6960 - val_loss: 13.8231 - val_accuracy: 0.2788\n",
            "Epoch 155/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 1.1935 - accuracy: 0.6994 - val_loss: 13.7414 - val_accuracy: 0.2816\n",
            "Epoch 156/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.1797 - accuracy: 0.7016 - val_loss: 13.8885 - val_accuracy: 0.2823\n",
            "Epoch 157/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.1677 - accuracy: 0.7043 - val_loss: 13.8854 - val_accuracy: 0.2838\n",
            "Epoch 158/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.1595 - accuracy: 0.7079 - val_loss: 13.9533 - val_accuracy: 0.2835\n",
            "Epoch 159/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.1504 - accuracy: 0.7077 - val_loss: 14.0562 - val_accuracy: 0.2849\n",
            "Epoch 160/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.1369 - accuracy: 0.7119 - val_loss: 13.9997 - val_accuracy: 0.2843\n",
            "Epoch 161/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.1265 - accuracy: 0.7131 - val_loss: 14.0998 - val_accuracy: 0.2847\n",
            "Epoch 162/500\n",
            "79/79 [==============================] - 9s 111ms/step - loss: 1.1154 - accuracy: 0.7148 - val_loss: 14.2106 - val_accuracy: 0.2867\n",
            "Epoch 163/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.1017 - accuracy: 0.7180 - val_loss: 14.2599 - val_accuracy: 0.2867\n",
            "Epoch 164/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.0994 - accuracy: 0.7197 - val_loss: 14.2589 - val_accuracy: 0.2889\n",
            "Epoch 165/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.0842 - accuracy: 0.7227 - val_loss: 14.4578 - val_accuracy: 0.2867\n",
            "Epoch 166/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0694 - accuracy: 0.7257 - val_loss: 14.3945 - val_accuracy: 0.2877\n",
            "Epoch 167/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.0610 - accuracy: 0.7280 - val_loss: 14.4798 - val_accuracy: 0.2905\n",
            "Epoch 168/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.0533 - accuracy: 0.7293 - val_loss: 14.5505 - val_accuracy: 0.2897\n",
            "Epoch 169/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.0396 - accuracy: 0.7327 - val_loss: 14.6074 - val_accuracy: 0.2912\n",
            "Epoch 170/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.0284 - accuracy: 0.7354 - val_loss: 14.5867 - val_accuracy: 0.2910\n",
            "Epoch 171/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.0179 - accuracy: 0.7382 - val_loss: 14.7266 - val_accuracy: 0.2932\n",
            "Epoch 172/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0114 - accuracy: 0.7391 - val_loss: 14.7500 - val_accuracy: 0.2930\n",
            "Epoch 173/500\n",
            "79/79 [==============================] - 9s 112ms/step - loss: 0.9996 - accuracy: 0.7413 - val_loss: 14.8238 - val_accuracy: 0.2939\n",
            "Epoch 174/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.9892 - accuracy: 0.7435 - val_loss: 14.8328 - val_accuracy: 0.2952\n",
            "Epoch 175/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.9840 - accuracy: 0.7449 - val_loss: 14.9749 - val_accuracy: 0.2963\n",
            "Epoch 176/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.9741 - accuracy: 0.7476 - val_loss: 15.0519 - val_accuracy: 0.2963\n",
            "Epoch 177/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.9611 - accuracy: 0.7498 - val_loss: 14.9943 - val_accuracy: 0.2954\n",
            "Epoch 178/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.9554 - accuracy: 0.7518 - val_loss: 15.0379 - val_accuracy: 0.2973\n",
            "Epoch 179/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.9480 - accuracy: 0.7515 - val_loss: 15.2093 - val_accuracy: 0.2970\n",
            "Epoch 180/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.9367 - accuracy: 0.7547 - val_loss: 15.2191 - val_accuracy: 0.2994\n",
            "Epoch 181/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.9256 - accuracy: 0.7571 - val_loss: 15.3822 - val_accuracy: 0.2989\n",
            "Epoch 182/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 0.9247 - accuracy: 0.7574 - val_loss: 15.3153 - val_accuracy: 0.2996\n",
            "Epoch 183/500\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 0.9093 - accuracy: 0.7607 - val_loss: 15.3879 - val_accuracy: 0.3011\n",
            "Epoch 184/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.9014 - accuracy: 0.7642 - val_loss: 15.5534 - val_accuracy: 0.3011\n",
            "Epoch 185/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.8951 - accuracy: 0.7642 - val_loss: 15.4794 - val_accuracy: 0.3016\n",
            "Epoch 186/500\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 0.8882 - accuracy: 0.7660 - val_loss: 15.5793 - val_accuracy: 0.3028\n",
            "Epoch 187/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.8771 - accuracy: 0.7678 - val_loss: 15.6833 - val_accuracy: 0.3025\n",
            "Epoch 188/500\n",
            "79/79 [==============================] - 8s 104ms/step - loss: 0.8717 - accuracy: 0.7691 - val_loss: 15.6331 - val_accuracy: 0.3041\n",
            "Epoch 189/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.8582 - accuracy: 0.7731 - val_loss: 15.7440 - val_accuracy: 0.3057\n",
            "Epoch 190/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.8523 - accuracy: 0.7747 - val_loss: 15.6667 - val_accuracy: 0.3032\n",
            "Epoch 191/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.8484 - accuracy: 0.7756 - val_loss: 15.8633 - val_accuracy: 0.3049\n",
            "Epoch 192/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.8398 - accuracy: 0.7763 - val_loss: 15.9586 - val_accuracy: 0.3030\n",
            "Epoch 193/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.8272 - accuracy: 0.7802 - val_loss: 15.9226 - val_accuracy: 0.3072\n",
            "Epoch 194/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.8230 - accuracy: 0.7806 - val_loss: 15.9995 - val_accuracy: 0.3064\n",
            "Epoch 195/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.8170 - accuracy: 0.7817 - val_loss: 16.0324 - val_accuracy: 0.3066\n",
            "Epoch 196/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.8108 - accuracy: 0.7840 - val_loss: 16.0633 - val_accuracy: 0.3090\n",
            "Epoch 197/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.8040 - accuracy: 0.7859 - val_loss: 16.1493 - val_accuracy: 0.3092\n",
            "Epoch 198/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.7931 - accuracy: 0.7879 - val_loss: 16.1692 - val_accuracy: 0.3086\n",
            "Epoch 199/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.7908 - accuracy: 0.7877 - val_loss: 16.3046 - val_accuracy: 0.3092\n",
            "Epoch 200/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.7781 - accuracy: 0.7911 - val_loss: 16.2718 - val_accuracy: 0.3108\n",
            "Epoch 201/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.7706 - accuracy: 0.7937 - val_loss: 16.3202 - val_accuracy: 0.3108\n",
            "Epoch 202/500\n",
            "79/79 [==============================] - 9s 120ms/step - loss: 0.7643 - accuracy: 0.7941 - val_loss: 16.4546 - val_accuracy: 0.3124\n",
            "Epoch 203/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.7590 - accuracy: 0.7954 - val_loss: 16.5079 - val_accuracy: 0.3109\n",
            "Epoch 204/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 0.7525 - accuracy: 0.7974 - val_loss: 16.5316 - val_accuracy: 0.3134\n",
            "Epoch 205/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7446 - accuracy: 0.7995 - val_loss: 16.5251 - val_accuracy: 0.3127\n",
            "Epoch 206/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7395 - accuracy: 0.8006 - val_loss: 16.6952 - val_accuracy: 0.3122\n",
            "Epoch 207/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7351 - accuracy: 0.7990 - val_loss: 16.6390 - val_accuracy: 0.3118\n",
            "Epoch 208/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.7270 - accuracy: 0.8032 - val_loss: 16.8068 - val_accuracy: 0.3145\n",
            "Epoch 209/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.7186 - accuracy: 0.8048 - val_loss: 16.7616 - val_accuracy: 0.3136\n",
            "Epoch 210/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 0.7110 - accuracy: 0.8075 - val_loss: 16.8869 - val_accuracy: 0.3157\n",
            "Epoch 211/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.7072 - accuracy: 0.8083 - val_loss: 16.9494 - val_accuracy: 0.3140\n",
            "Epoch 212/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.7028 - accuracy: 0.8084 - val_loss: 16.8849 - val_accuracy: 0.3149\n",
            "Epoch 213/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.6952 - accuracy: 0.8108 - val_loss: 17.0668 - val_accuracy: 0.3143\n",
            "Epoch 214/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.6938 - accuracy: 0.8116 - val_loss: 16.9920 - val_accuracy: 0.3159\n",
            "Epoch 215/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.6869 - accuracy: 0.8129 - val_loss: 17.1235 - val_accuracy: 0.3157\n",
            "Epoch 216/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.6804 - accuracy: 0.8145 - val_loss: 17.1520 - val_accuracy: 0.3172\n",
            "Epoch 217/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.6668 - accuracy: 0.8176 - val_loss: 17.1568 - val_accuracy: 0.3162\n",
            "Epoch 218/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.6691 - accuracy: 0.8174 - val_loss: 17.2624 - val_accuracy: 0.3164\n",
            "Epoch 219/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.6624 - accuracy: 0.8181 - val_loss: 17.2912 - val_accuracy: 0.3181\n",
            "Epoch 220/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6590 - accuracy: 0.8179 - val_loss: 17.4018 - val_accuracy: 0.3174\n",
            "Epoch 221/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.6493 - accuracy: 0.8217 - val_loss: 17.4747 - val_accuracy: 0.3177\n",
            "Epoch 222/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6506 - accuracy: 0.8219 - val_loss: 17.5603 - val_accuracy: 0.3171\n",
            "Epoch 223/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.6416 - accuracy: 0.8235 - val_loss: 17.5257 - val_accuracy: 0.3190\n",
            "Epoch 224/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.6365 - accuracy: 0.8256 - val_loss: 17.6537 - val_accuracy: 0.3196\n",
            "Epoch 225/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.6311 - accuracy: 0.8260 - val_loss: 17.4620 - val_accuracy: 0.3197\n",
            "Epoch 226/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.6329 - accuracy: 0.8251 - val_loss: 17.6453 - val_accuracy: 0.3199\n",
            "Epoch 227/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.6230 - accuracy: 0.8273 - val_loss: 17.6066 - val_accuracy: 0.3214\n",
            "Epoch 228/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.6117 - accuracy: 0.8299 - val_loss: 17.7506 - val_accuracy: 0.3216\n",
            "Epoch 229/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.6057 - accuracy: 0.8319 - val_loss: 17.8257 - val_accuracy: 0.3218\n",
            "Epoch 230/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6011 - accuracy: 0.8333 - val_loss: 17.8701 - val_accuracy: 0.3197\n",
            "Epoch 231/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 0.6029 - accuracy: 0.8327 - val_loss: 17.8800 - val_accuracy: 0.3224\n",
            "Epoch 232/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.5929 - accuracy: 0.8359 - val_loss: 17.9504 - val_accuracy: 0.3225\n",
            "Epoch 233/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.5846 - accuracy: 0.8373 - val_loss: 17.9739 - val_accuracy: 0.3229\n",
            "Epoch 234/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5840 - accuracy: 0.8367 - val_loss: 17.9529 - val_accuracy: 0.3216\n",
            "Epoch 235/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.5748 - accuracy: 0.8400 - val_loss: 18.1753 - val_accuracy: 0.3231\n",
            "Epoch 236/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.5747 - accuracy: 0.8404 - val_loss: 18.1516 - val_accuracy: 0.3240\n",
            "Epoch 237/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5733 - accuracy: 0.8396 - val_loss: 18.1447 - val_accuracy: 0.3231\n",
            "Epoch 238/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5730 - accuracy: 0.8395 - val_loss: 18.2678 - val_accuracy: 0.3237\n",
            "Epoch 239/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5657 - accuracy: 0.8424 - val_loss: 18.2048 - val_accuracy: 0.3226\n",
            "Epoch 240/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 0.5590 - accuracy: 0.8437 - val_loss: 18.2925 - val_accuracy: 0.3244\n",
            "Epoch 241/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 0.5555 - accuracy: 0.8443 - val_loss: 18.3730 - val_accuracy: 0.3248\n",
            "Epoch 242/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.5469 - accuracy: 0.8458 - val_loss: 18.3374 - val_accuracy: 0.3256\n",
            "Epoch 243/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5524 - accuracy: 0.8447 - val_loss: 18.4055 - val_accuracy: 0.3241\n",
            "Epoch 244/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5498 - accuracy: 0.8457 - val_loss: 18.5021 - val_accuracy: 0.3243\n",
            "Epoch 245/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5377 - accuracy: 0.8496 - val_loss: 18.6197 - val_accuracy: 0.3252\n",
            "Epoch 246/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5316 - accuracy: 0.8500 - val_loss: 18.5590 - val_accuracy: 0.3254\n",
            "Epoch 247/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.5312 - accuracy: 0.8505 - val_loss: 18.6614 - val_accuracy: 0.3270\n",
            "Epoch 248/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5266 - accuracy: 0.8513 - val_loss: 18.6060 - val_accuracy: 0.3262\n",
            "Epoch 249/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5242 - accuracy: 0.8522 - val_loss: 18.6255 - val_accuracy: 0.3253\n",
            "Epoch 250/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5212 - accuracy: 0.8522 - val_loss: 18.8088 - val_accuracy: 0.3264\n",
            "Epoch 251/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5207 - accuracy: 0.8527 - val_loss: 18.7903 - val_accuracy: 0.3267\n",
            "Epoch 252/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5114 - accuracy: 0.8560 - val_loss: 18.8739 - val_accuracy: 0.3269\n",
            "Epoch 253/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.5050 - accuracy: 0.8572 - val_loss: 18.9075 - val_accuracy: 0.3272\n",
            "Epoch 254/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.5076 - accuracy: 0.8562 - val_loss: 18.9739 - val_accuracy: 0.3275\n",
            "Epoch 255/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5014 - accuracy: 0.8587 - val_loss: 18.9172 - val_accuracy: 0.3265\n",
            "Epoch 256/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 0.4974 - accuracy: 0.8591 - val_loss: 19.0553 - val_accuracy: 0.3286\n",
            "Epoch 257/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4956 - accuracy: 0.8586 - val_loss: 19.1003 - val_accuracy: 0.3280\n",
            "Epoch 258/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4867 - accuracy: 0.8612 - val_loss: 19.1060 - val_accuracy: 0.3280\n",
            "Epoch 259/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4869 - accuracy: 0.8613 - val_loss: 19.0711 - val_accuracy: 0.3269\n",
            "Epoch 260/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4902 - accuracy: 0.8615 - val_loss: 19.2174 - val_accuracy: 0.3285\n",
            "Epoch 261/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.4823 - accuracy: 0.8624 - val_loss: 19.2550 - val_accuracy: 0.3299\n",
            "Epoch 262/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.4757 - accuracy: 0.8642 - val_loss: 19.3221 - val_accuracy: 0.3288\n",
            "Epoch 263/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.4741 - accuracy: 0.8635 - val_loss: 19.2456 - val_accuracy: 0.3305\n",
            "Epoch 264/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4736 - accuracy: 0.8648 - val_loss: 19.3574 - val_accuracy: 0.3299\n",
            "Epoch 265/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.4641 - accuracy: 0.8672 - val_loss: 19.4544 - val_accuracy: 0.3303\n",
            "Epoch 266/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4655 - accuracy: 0.8670 - val_loss: 19.4317 - val_accuracy: 0.3296\n",
            "Epoch 267/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.4637 - accuracy: 0.8659 - val_loss: 19.5635 - val_accuracy: 0.3308\n",
            "Epoch 268/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.4550 - accuracy: 0.8706 - val_loss: 19.4420 - val_accuracy: 0.3312\n",
            "Epoch 269/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.4541 - accuracy: 0.8700 - val_loss: 19.5446 - val_accuracy: 0.3314\n",
            "Epoch 270/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.4526 - accuracy: 0.8701 - val_loss: 19.6389 - val_accuracy: 0.3305\n",
            "Epoch 271/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4470 - accuracy: 0.8720 - val_loss: 19.6272 - val_accuracy: 0.3302\n",
            "Epoch 272/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.4488 - accuracy: 0.8706 - val_loss: 19.6374 - val_accuracy: 0.3314\n",
            "Epoch 273/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4469 - accuracy: 0.8719 - val_loss: 19.5546 - val_accuracy: 0.3309\n",
            "Epoch 274/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.4391 - accuracy: 0.8736 - val_loss: 19.7582 - val_accuracy: 0.3325\n",
            "Epoch 275/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4355 - accuracy: 0.8749 - val_loss: 19.8366 - val_accuracy: 0.3311\n",
            "Epoch 276/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.4309 - accuracy: 0.8754 - val_loss: 19.8010 - val_accuracy: 0.3315\n",
            "Epoch 277/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.4318 - accuracy: 0.8753 - val_loss: 19.8461 - val_accuracy: 0.3313\n",
            "Epoch 278/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.4227 - accuracy: 0.8776 - val_loss: 19.8407 - val_accuracy: 0.3314\n",
            "Epoch 279/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.4239 - accuracy: 0.8780 - val_loss: 19.9553 - val_accuracy: 0.3326\n",
            "Epoch 280/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4197 - accuracy: 0.8788 - val_loss: 20.1020 - val_accuracy: 0.3321\n",
            "Epoch 281/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.4247 - accuracy: 0.8774 - val_loss: 19.9845 - val_accuracy: 0.3322\n",
            "Epoch 282/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4152 - accuracy: 0.8796 - val_loss: 20.0765 - val_accuracy: 0.3324\n",
            "Epoch 283/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4149 - accuracy: 0.8797 - val_loss: 20.1466 - val_accuracy: 0.3323\n",
            "Epoch 284/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.4094 - accuracy: 0.8811 - val_loss: 20.1194 - val_accuracy: 0.3329\n",
            "Epoch 285/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4070 - accuracy: 0.8820 - val_loss: 20.2023 - val_accuracy: 0.3324\n",
            "Epoch 286/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4051 - accuracy: 0.8837 - val_loss: 20.1459 - val_accuracy: 0.3326\n",
            "Epoch 287/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.4080 - accuracy: 0.8820 - val_loss: 20.2148 - val_accuracy: 0.3329\n",
            "Epoch 288/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.4034 - accuracy: 0.8822 - val_loss: 20.1750 - val_accuracy: 0.3328\n",
            "Epoch 289/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 0.4069 - accuracy: 0.8822 - val_loss: 20.4838 - val_accuracy: 0.3335\n",
            "Epoch 290/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.4001 - accuracy: 0.8833 - val_loss: 20.3670 - val_accuracy: 0.3335\n",
            "Epoch 291/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3937 - accuracy: 0.8855 - val_loss: 20.3122 - val_accuracy: 0.3331\n",
            "Epoch 292/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.3908 - accuracy: 0.8853 - val_loss: 20.4874 - val_accuracy: 0.3337\n",
            "Epoch 293/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.3879 - accuracy: 0.8864 - val_loss: 20.6038 - val_accuracy: 0.3344\n",
            "Epoch 294/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.3839 - accuracy: 0.8878 - val_loss: 20.6756 - val_accuracy: 0.3340\n",
            "Epoch 295/500\n",
            "79/79 [==============================] - 9s 112ms/step - loss: 0.3892 - accuracy: 0.8876 - val_loss: 20.5400 - val_accuracy: 0.3348\n",
            "Epoch 296/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.3899 - accuracy: 0.8866 - val_loss: 20.5669 - val_accuracy: 0.3352\n",
            "Epoch 297/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.3874 - accuracy: 0.8873 - val_loss: 20.5756 - val_accuracy: 0.3344\n",
            "Epoch 298/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.3813 - accuracy: 0.8882 - val_loss: 20.6407 - val_accuracy: 0.3355\n",
            "Epoch 299/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.3810 - accuracy: 0.8879 - val_loss: 20.7790 - val_accuracy: 0.3358\n",
            "Epoch 300/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.3752 - accuracy: 0.8906 - val_loss: 20.6978 - val_accuracy: 0.3351\n",
            "Epoch 301/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.3725 - accuracy: 0.8910 - val_loss: 20.8508 - val_accuracy: 0.3342\n",
            "Epoch 302/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3716 - accuracy: 0.8914 - val_loss: 20.8003 - val_accuracy: 0.3345\n",
            "Epoch 303/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3772 - accuracy: 0.8890 - val_loss: 20.7880 - val_accuracy: 0.3347\n",
            "Epoch 304/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 0.3708 - accuracy: 0.8923 - val_loss: 20.9410 - val_accuracy: 0.3360\n",
            "Epoch 305/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.3670 - accuracy: 0.8923 - val_loss: 20.8579 - val_accuracy: 0.3366\n",
            "Epoch 306/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3655 - accuracy: 0.8928 - val_loss: 20.8067 - val_accuracy: 0.3362\n",
            "Epoch 307/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3639 - accuracy: 0.8928 - val_loss: 21.0568 - val_accuracy: 0.3365\n",
            "Epoch 308/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3594 - accuracy: 0.8943 - val_loss: 20.9410 - val_accuracy: 0.3353\n",
            "Epoch 309/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3592 - accuracy: 0.8949 - val_loss: 21.0353 - val_accuracy: 0.3357\n",
            "Epoch 310/500\n",
            "79/79 [==============================] - 8s 105ms/step - loss: 0.3555 - accuracy: 0.8960 - val_loss: 21.1086 - val_accuracy: 0.3379\n",
            "Epoch 311/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3505 - accuracy: 0.8975 - val_loss: 21.1556 - val_accuracy: 0.3367\n",
            "Epoch 312/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.3525 - accuracy: 0.8974 - val_loss: 20.9756 - val_accuracy: 0.3368\n",
            "Epoch 313/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3514 - accuracy: 0.8962 - val_loss: 21.1067 - val_accuracy: 0.3354\n",
            "Epoch 314/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3434 - accuracy: 0.8981 - val_loss: 21.1709 - val_accuracy: 0.3366\n",
            "Epoch 315/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3433 - accuracy: 0.8988 - val_loss: 21.2364 - val_accuracy: 0.3368\n",
            "Epoch 316/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3378 - accuracy: 0.9004 - val_loss: 21.2132 - val_accuracy: 0.3370\n",
            "Epoch 317/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3417 - accuracy: 0.8991 - val_loss: 21.2818 - val_accuracy: 0.3361\n",
            "Epoch 318/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3415 - accuracy: 0.8983 - val_loss: 21.4922 - val_accuracy: 0.3373\n",
            "Epoch 319/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3394 - accuracy: 0.8999 - val_loss: 21.3703 - val_accuracy: 0.3355\n",
            "Epoch 320/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3372 - accuracy: 0.9003 - val_loss: 21.4055 - val_accuracy: 0.3370\n",
            "Epoch 321/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3331 - accuracy: 0.9013 - val_loss: 21.5015 - val_accuracy: 0.3364\n",
            "Epoch 322/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3291 - accuracy: 0.9029 - val_loss: 21.4397 - val_accuracy: 0.3362\n",
            "Epoch 323/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.3309 - accuracy: 0.9014 - val_loss: 21.4908 - val_accuracy: 0.3374\n",
            "Epoch 324/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3309 - accuracy: 0.9013 - val_loss: 21.6001 - val_accuracy: 0.3374\n",
            "Epoch 325/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.3314 - accuracy: 0.9020 - val_loss: 21.5159 - val_accuracy: 0.3381\n",
            "Epoch 326/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3295 - accuracy: 0.9022 - val_loss: 21.6064 - val_accuracy: 0.3381\n",
            "Epoch 327/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3243 - accuracy: 0.9037 - val_loss: 21.6562 - val_accuracy: 0.3375\n",
            "Epoch 328/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3237 - accuracy: 0.9040 - val_loss: 21.6300 - val_accuracy: 0.3367\n",
            "Epoch 329/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3252 - accuracy: 0.9035 - val_loss: 21.6854 - val_accuracy: 0.3377\n",
            "Epoch 330/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.3250 - accuracy: 0.9033 - val_loss: 21.7273 - val_accuracy: 0.3369\n",
            "Epoch 331/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.3235 - accuracy: 0.9044 - val_loss: 21.7626 - val_accuracy: 0.3378\n",
            "Epoch 332/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.3210 - accuracy: 0.9044 - val_loss: 21.8357 - val_accuracy: 0.3386\n",
            "Epoch 333/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.3235 - accuracy: 0.9035 - val_loss: 21.7938 - val_accuracy: 0.3374\n",
            "Epoch 334/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3131 - accuracy: 0.9064 - val_loss: 21.9367 - val_accuracy: 0.3369\n",
            "Epoch 335/500\n",
            "79/79 [==============================] - 8s 96ms/step - loss: 0.3115 - accuracy: 0.9074 - val_loss: 21.8365 - val_accuracy: 0.3378\n",
            "Epoch 336/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3108 - accuracy: 0.9076 - val_loss: 21.9203 - val_accuracy: 0.3385\n",
            "Epoch 337/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.3067 - accuracy: 0.9084 - val_loss: 21.9990 - val_accuracy: 0.3388\n",
            "Epoch 338/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.3093 - accuracy: 0.9081 - val_loss: 21.9197 - val_accuracy: 0.3380\n",
            "Epoch 339/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.3071 - accuracy: 0.9085 - val_loss: 21.9891 - val_accuracy: 0.3390\n",
            "Epoch 340/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.3032 - accuracy: 0.9099 - val_loss: 22.1307 - val_accuracy: 0.3394\n",
            "Epoch 341/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3080 - accuracy: 0.9085 - val_loss: 21.9096 - val_accuracy: 0.3377\n",
            "Epoch 342/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3053 - accuracy: 0.9084 - val_loss: 22.1402 - val_accuracy: 0.3378\n",
            "Epoch 343/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.2978 - accuracy: 0.9115 - val_loss: 22.1695 - val_accuracy: 0.3391\n",
            "Epoch 344/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3048 - accuracy: 0.9089 - val_loss: 22.2394 - val_accuracy: 0.3389\n",
            "Epoch 345/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3101 - accuracy: 0.9076 - val_loss: 22.2478 - val_accuracy: 0.3386\n",
            "Epoch 346/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.3062 - accuracy: 0.9088 - val_loss: 21.9914 - val_accuracy: 0.3381\n",
            "Epoch 347/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.3008 - accuracy: 0.9104 - val_loss: 22.2300 - val_accuracy: 0.3387\n",
            "Epoch 348/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.2949 - accuracy: 0.9110 - val_loss: 22.2283 - val_accuracy: 0.3390\n",
            "Epoch 349/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2942 - accuracy: 0.9118 - val_loss: 22.1779 - val_accuracy: 0.3370\n",
            "Epoch 350/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2977 - accuracy: 0.9107 - val_loss: 22.2835 - val_accuracy: 0.3390\n",
            "Epoch 351/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2900 - accuracy: 0.9132 - val_loss: 22.1897 - val_accuracy: 0.3375\n",
            "Epoch 352/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2895 - accuracy: 0.9132 - val_loss: 22.4951 - val_accuracy: 0.3394\n",
            "Epoch 353/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2869 - accuracy: 0.9141 - val_loss: 22.4399 - val_accuracy: 0.3391\n",
            "Epoch 354/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2867 - accuracy: 0.9141 - val_loss: 22.3462 - val_accuracy: 0.3385\n",
            "Epoch 355/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.2828 - accuracy: 0.9150 - val_loss: 22.5027 - val_accuracy: 0.3380\n",
            "Epoch 356/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.2835 - accuracy: 0.9151 - val_loss: 22.4066 - val_accuracy: 0.3376\n",
            "Epoch 357/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.2887 - accuracy: 0.9136 - val_loss: 22.4799 - val_accuracy: 0.3387\n",
            "Epoch 358/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.2852 - accuracy: 0.9143 - val_loss: 22.3991 - val_accuracy: 0.3379\n",
            "Epoch 359/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2811 - accuracy: 0.9153 - val_loss: 22.5159 - val_accuracy: 0.3393\n",
            "Epoch 360/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2750 - accuracy: 0.9172 - val_loss: 22.5754 - val_accuracy: 0.3378\n",
            "Epoch 361/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.2792 - accuracy: 0.9157 - val_loss: 22.7123 - val_accuracy: 0.3379\n",
            "Epoch 362/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2755 - accuracy: 0.9172 - val_loss: 22.6086 - val_accuracy: 0.3387\n",
            "Epoch 363/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.2803 - accuracy: 0.9157 - val_loss: 22.5446 - val_accuracy: 0.3391\n",
            "Epoch 364/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2794 - accuracy: 0.9159 - val_loss: 22.8389 - val_accuracy: 0.3383\n",
            "Epoch 365/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.2798 - accuracy: 0.9167 - val_loss: 22.5922 - val_accuracy: 0.3373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoP-_Ot7AO4Z",
        "colab_type": "text"
      },
      "source": [
        "## V3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK14bGSjeOwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(    \n",
        "    Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=embedding_matrix.shape[1],\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=True)\n",
        ")\n",
        "\n",
        "model.add(LSTM(256))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(num_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZeVf9SAnCmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15167bb6-79db-4160-f646-ddc401ffcb78"
      },
      "source": [
        "# model_filename = f'{DATASET}-custom-3.h5'\n",
        "# model_filepath = os.path.join(MODELS_DIR, model_filename)\n",
        "# print(model_filepath)\n",
        "# # model = load_model(model_filepath)\n",
        "\n",
        "# callbacks = [\n",
        "#     EarlyStopping(monitor='val_accuracy', patience=25),\n",
        "#     ModelCheckpoint(f'{model_filepath}', save_best_only=True, save_weights_only=False, monitor='val_accuracy')\n",
        "# ]\n",
        "\n",
        "# EPOCHS = 500\n",
        "\n",
        "# history = model.fit(\n",
        "#     X_train, \n",
        "#     y_train, \n",
        "#     epochs=EPOCHS, \n",
        "#     batch_size=2048, \n",
        "#     validation_data=(X_test, y_test), \n",
        "#     verbose=1,\n",
        "#     callbacks=callbacks\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/models/BBC-TECH-custom-3.h5\n",
            "Epoch 1/500\n",
            "79/79 [==============================] - 7s 95ms/step - loss: 7.4937 - accuracy: 0.0480 - val_loss: 7.0589 - val_accuracy: 0.0571\n",
            "Epoch 2/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 6.9637 - accuracy: 0.0578 - val_loss: 6.9842 - val_accuracy: 0.0571\n",
            "Epoch 3/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 6.8810 - accuracy: 0.0588 - val_loss: 6.9417 - val_accuracy: 0.0665\n",
            "Epoch 4/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 6.7796 - accuracy: 0.0672 - val_loss: 6.8369 - val_accuracy: 0.0706\n",
            "Epoch 5/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 6.6399 - accuracy: 0.0761 - val_loss: 6.7480 - val_accuracy: 0.0845\n",
            "Epoch 6/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 6.5218 - accuracy: 0.0874 - val_loss: 6.6856 - val_accuracy: 0.0904\n",
            "Epoch 7/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 6.4213 - accuracy: 0.0950 - val_loss: 6.6291 - val_accuracy: 0.0963\n",
            "Epoch 8/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 6.3205 - accuracy: 0.1004 - val_loss: 6.5736 - val_accuracy: 0.1002\n",
            "Epoch 9/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 6.2157 - accuracy: 0.1072 - val_loss: 6.5220 - val_accuracy: 0.1045\n",
            "Epoch 10/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 6.1174 - accuracy: 0.1129 - val_loss: 6.4844 - val_accuracy: 0.1100\n",
            "Epoch 11/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 6.0244 - accuracy: 0.1178 - val_loss: 6.4474 - val_accuracy: 0.1140\n",
            "Epoch 12/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.9375 - accuracy: 0.1226 - val_loss: 6.4265 - val_accuracy: 0.1178\n",
            "Epoch 13/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 5.8503 - accuracy: 0.1275 - val_loss: 6.3982 - val_accuracy: 0.1211\n",
            "Epoch 14/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 5.7704 - accuracy: 0.1324 - val_loss: 6.3835 - val_accuracy: 0.1249\n",
            "Epoch 15/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 5.6899 - accuracy: 0.1363 - val_loss: 6.3741 - val_accuracy: 0.1270\n",
            "Epoch 16/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 5.6153 - accuracy: 0.1409 - val_loss: 6.3671 - val_accuracy: 0.1318\n",
            "Epoch 17/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.5441 - accuracy: 0.1447 - val_loss: 6.3634 - val_accuracy: 0.1326\n",
            "Epoch 18/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.4763 - accuracy: 0.1481 - val_loss: 6.3623 - val_accuracy: 0.1347\n",
            "Epoch 19/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 5.4093 - accuracy: 0.1510 - val_loss: 6.3756 - val_accuracy: 0.1367\n",
            "Epoch 20/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.3474 - accuracy: 0.1541 - val_loss: 6.3778 - val_accuracy: 0.1373\n",
            "Epoch 21/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.2880 - accuracy: 0.1565 - val_loss: 6.3831 - val_accuracy: 0.1399\n",
            "Epoch 22/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.2276 - accuracy: 0.1590 - val_loss: 6.3988 - val_accuracy: 0.1414\n",
            "Epoch 23/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.1712 - accuracy: 0.1621 - val_loss: 6.4130 - val_accuracy: 0.1430\n",
            "Epoch 24/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.1148 - accuracy: 0.1641 - val_loss: 6.4289 - val_accuracy: 0.1433\n",
            "Epoch 25/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.0607 - accuracy: 0.1671 - val_loss: 6.4342 - val_accuracy: 0.1458\n",
            "Epoch 26/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 5.0085 - accuracy: 0.1694 - val_loss: 6.4510 - val_accuracy: 0.1466\n",
            "Epoch 27/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.9559 - accuracy: 0.1712 - val_loss: 6.4751 - val_accuracy: 0.1471\n",
            "Epoch 28/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.9026 - accuracy: 0.1761 - val_loss: 6.4994 - val_accuracy: 0.1501\n",
            "Epoch 29/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 4.8545 - accuracy: 0.1772 - val_loss: 6.5017 - val_accuracy: 0.1514\n",
            "Epoch 30/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.8048 - accuracy: 0.1811 - val_loss: 6.5337 - val_accuracy: 0.1529\n",
            "Epoch 31/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.7528 - accuracy: 0.1842 - val_loss: 6.5507 - val_accuracy: 0.1532\n",
            "Epoch 32/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.7051 - accuracy: 0.1865 - val_loss: 6.5721 - val_accuracy: 0.1552\n",
            "Epoch 33/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 4.6557 - accuracy: 0.1904 - val_loss: 6.6016 - val_accuracy: 0.1555\n",
            "Epoch 34/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.6106 - accuracy: 0.1932 - val_loss: 6.6094 - val_accuracy: 0.1555\n",
            "Epoch 35/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 4.5651 - accuracy: 0.1964 - val_loss: 6.6454 - val_accuracy: 0.1599\n",
            "Epoch 36/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.5212 - accuracy: 0.1987 - val_loss: 6.6668 - val_accuracy: 0.1600\n",
            "Epoch 37/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 4.4759 - accuracy: 0.2028 - val_loss: 6.7048 - val_accuracy: 0.1594\n",
            "Epoch 38/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 4.4338 - accuracy: 0.2065 - val_loss: 6.7284 - val_accuracy: 0.1627\n",
            "Epoch 39/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 4.3959 - accuracy: 0.2083 - val_loss: 6.7518 - val_accuracy: 0.1611\n",
            "Epoch 40/500\n",
            "79/79 [==============================] - 8s 106ms/step - loss: 4.3514 - accuracy: 0.2125 - val_loss: 6.7766 - val_accuracy: 0.1638\n",
            "Epoch 41/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.3093 - accuracy: 0.2156 - val_loss: 6.7929 - val_accuracy: 0.1646\n",
            "Epoch 42/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 4.2685 - accuracy: 0.2188 - val_loss: 6.8242 - val_accuracy: 0.1644\n",
            "Epoch 43/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.2355 - accuracy: 0.2213 - val_loss: 6.8467 - val_accuracy: 0.1652\n",
            "Epoch 44/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 4.1940 - accuracy: 0.2251 - val_loss: 6.8666 - val_accuracy: 0.1669\n",
            "Epoch 45/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 4.1577 - accuracy: 0.2278 - val_loss: 6.8900 - val_accuracy: 0.1677\n",
            "Epoch 46/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.1203 - accuracy: 0.2320 - val_loss: 6.9353 - val_accuracy: 0.1695\n",
            "Epoch 47/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.0830 - accuracy: 0.2359 - val_loss: 6.9660 - val_accuracy: 0.1691\n",
            "Epoch 48/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 4.0445 - accuracy: 0.2387 - val_loss: 6.9968 - val_accuracy: 0.1702\n",
            "Epoch 49/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 4.0176 - accuracy: 0.2400 - val_loss: 7.0320 - val_accuracy: 0.1707\n",
            "Epoch 50/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 3.9819 - accuracy: 0.2456 - val_loss: 7.0707 - val_accuracy: 0.1724\n",
            "Epoch 51/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.9502 - accuracy: 0.2476 - val_loss: 7.0892 - val_accuracy: 0.1743\n",
            "Epoch 52/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 3.9160 - accuracy: 0.2515 - val_loss: 7.1206 - val_accuracy: 0.1732\n",
            "Epoch 53/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 3.8847 - accuracy: 0.2535 - val_loss: 7.1424 - val_accuracy: 0.1736\n",
            "Epoch 54/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 3.8477 - accuracy: 0.2574 - val_loss: 7.1842 - val_accuracy: 0.1749\n",
            "Epoch 55/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.8174 - accuracy: 0.2599 - val_loss: 7.2138 - val_accuracy: 0.1759\n",
            "Epoch 56/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 3.7873 - accuracy: 0.2637 - val_loss: 7.2315 - val_accuracy: 0.1765\n",
            "Epoch 57/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.7600 - accuracy: 0.2661 - val_loss: 7.2607 - val_accuracy: 0.1789\n",
            "Epoch 58/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.7295 - accuracy: 0.2704 - val_loss: 7.3197 - val_accuracy: 0.1775\n",
            "Epoch 59/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 3.6967 - accuracy: 0.2741 - val_loss: 7.3422 - val_accuracy: 0.1802\n",
            "Epoch 60/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 3.6695 - accuracy: 0.2767 - val_loss: 7.3464 - val_accuracy: 0.1797\n",
            "Epoch 61/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.6411 - accuracy: 0.2797 - val_loss: 7.3760 - val_accuracy: 0.1785\n",
            "Epoch 62/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 3.6054 - accuracy: 0.2844 - val_loss: 7.4122 - val_accuracy: 0.1822\n",
            "Epoch 63/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.5783 - accuracy: 0.2864 - val_loss: 7.4413 - val_accuracy: 0.1844\n",
            "Epoch 64/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.5547 - accuracy: 0.2905 - val_loss: 7.4717 - val_accuracy: 0.1839\n",
            "Epoch 65/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.5271 - accuracy: 0.2925 - val_loss: 7.5213 - val_accuracy: 0.1836\n",
            "Epoch 66/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 3.5025 - accuracy: 0.2967 - val_loss: 7.5663 - val_accuracy: 0.1848\n",
            "Epoch 67/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 3.4700 - accuracy: 0.3010 - val_loss: 7.6040 - val_accuracy: 0.1829\n",
            "Epoch 68/500\n",
            "79/79 [==============================] - 8s 107ms/step - loss: 3.4497 - accuracy: 0.3034 - val_loss: 7.6042 - val_accuracy: 0.1858\n",
            "Epoch 69/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.4193 - accuracy: 0.3064 - val_loss: 7.6661 - val_accuracy: 0.1865\n",
            "Epoch 70/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 3.3923 - accuracy: 0.3099 - val_loss: 7.6761 - val_accuracy: 0.1875\n",
            "Epoch 71/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.3677 - accuracy: 0.3132 - val_loss: 7.7379 - val_accuracy: 0.1891\n",
            "Epoch 72/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.3413 - accuracy: 0.3155 - val_loss: 7.7450 - val_accuracy: 0.1882\n",
            "Epoch 73/500\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 3.3194 - accuracy: 0.3192 - val_loss: 7.7809 - val_accuracy: 0.1897\n",
            "Epoch 74/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 3.2904 - accuracy: 0.3218 - val_loss: 7.8324 - val_accuracy: 0.1896\n",
            "Epoch 75/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 3.2720 - accuracy: 0.3248 - val_loss: 7.8604 - val_accuracy: 0.1909\n",
            "Epoch 76/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.2440 - accuracy: 0.3285 - val_loss: 7.8991 - val_accuracy: 0.1906\n",
            "Epoch 77/500\n",
            "79/79 [==============================] - 9s 112ms/step - loss: 3.2170 - accuracy: 0.3325 - val_loss: 7.9335 - val_accuracy: 0.1913\n",
            "Epoch 78/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.1978 - accuracy: 0.3347 - val_loss: 7.9456 - val_accuracy: 0.1919\n",
            "Epoch 79/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 3.1662 - accuracy: 0.3379 - val_loss: 8.0072 - val_accuracy: 0.1943\n",
            "Epoch 80/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.1488 - accuracy: 0.3413 - val_loss: 8.0314 - val_accuracy: 0.1960\n",
            "Epoch 81/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.1279 - accuracy: 0.3436 - val_loss: 8.0825 - val_accuracy: 0.1954\n",
            "Epoch 82/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.1054 - accuracy: 0.3464 - val_loss: 8.1347 - val_accuracy: 0.1958\n",
            "Epoch 83/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 3.0840 - accuracy: 0.3496 - val_loss: 8.1441 - val_accuracy: 0.1968\n",
            "Epoch 84/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 3.0612 - accuracy: 0.3536 - val_loss: 8.1880 - val_accuracy: 0.1989\n",
            "Epoch 85/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 3.0400 - accuracy: 0.3563 - val_loss: 8.1970 - val_accuracy: 0.1993\n",
            "Epoch 86/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 3.0199 - accuracy: 0.3584 - val_loss: 8.2335 - val_accuracy: 0.1991\n",
            "Epoch 87/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 2.9937 - accuracy: 0.3615 - val_loss: 8.3005 - val_accuracy: 0.2010\n",
            "Epoch 88/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 2.9742 - accuracy: 0.3652 - val_loss: 8.3311 - val_accuracy: 0.2007\n",
            "Epoch 89/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 2.9539 - accuracy: 0.3679 - val_loss: 8.3671 - val_accuracy: 0.2018\n",
            "Epoch 90/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.9334 - accuracy: 0.3717 - val_loss: 8.4039 - val_accuracy: 0.2018\n",
            "Epoch 91/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.9094 - accuracy: 0.3753 - val_loss: 8.4541 - val_accuracy: 0.2031\n",
            "Epoch 92/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.8913 - accuracy: 0.3766 - val_loss: 8.4666 - val_accuracy: 0.2050\n",
            "Epoch 93/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.8644 - accuracy: 0.3799 - val_loss: 8.5237 - val_accuracy: 0.2045\n",
            "Epoch 94/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 2.8538 - accuracy: 0.3825 - val_loss: 8.5570 - val_accuracy: 0.2053\n",
            "Epoch 95/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.8371 - accuracy: 0.3851 - val_loss: 8.5623 - val_accuracy: 0.2067\n",
            "Epoch 96/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.8096 - accuracy: 0.3893 - val_loss: 8.6289 - val_accuracy: 0.2078\n",
            "Epoch 97/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.7903 - accuracy: 0.3911 - val_loss: 8.6941 - val_accuracy: 0.2077\n",
            "Epoch 98/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 2.7685 - accuracy: 0.3954 - val_loss: 8.7206 - val_accuracy: 0.2088\n",
            "Epoch 99/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.7534 - accuracy: 0.3955 - val_loss: 8.7579 - val_accuracy: 0.2105\n",
            "Epoch 100/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 2.7304 - accuracy: 0.3996 - val_loss: 8.7560 - val_accuracy: 0.2103\n",
            "Epoch 101/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 2.7121 - accuracy: 0.4031 - val_loss: 8.8027 - val_accuracy: 0.2123\n",
            "Epoch 102/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.6945 - accuracy: 0.4050 - val_loss: 8.9056 - val_accuracy: 0.2123\n",
            "Epoch 103/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.6785 - accuracy: 0.4067 - val_loss: 8.8977 - val_accuracy: 0.2117\n",
            "Epoch 104/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 2.6629 - accuracy: 0.4100 - val_loss: 8.9298 - val_accuracy: 0.2137\n",
            "Epoch 105/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.6391 - accuracy: 0.4143 - val_loss: 8.9546 - val_accuracy: 0.2153\n",
            "Epoch 106/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.6243 - accuracy: 0.4163 - val_loss: 9.0097 - val_accuracy: 0.2140\n",
            "Epoch 107/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 2.5992 - accuracy: 0.4205 - val_loss: 9.0520 - val_accuracy: 0.2161\n",
            "Epoch 108/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.5816 - accuracy: 0.4246 - val_loss: 9.0570 - val_accuracy: 0.2175\n",
            "Epoch 109/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 2.5594 - accuracy: 0.4262 - val_loss: 9.1144 - val_accuracy: 0.2185\n",
            "Epoch 110/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.5521 - accuracy: 0.4280 - val_loss: 9.1671 - val_accuracy: 0.2176\n",
            "Epoch 111/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.5273 - accuracy: 0.4314 - val_loss: 9.1922 - val_accuracy: 0.2185\n",
            "Epoch 112/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 2.5131 - accuracy: 0.4343 - val_loss: 9.2696 - val_accuracy: 0.2203\n",
            "Epoch 113/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.4959 - accuracy: 0.4371 - val_loss: 9.3065 - val_accuracy: 0.2210\n",
            "Epoch 114/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.4826 - accuracy: 0.4380 - val_loss: 9.3490 - val_accuracy: 0.2236\n",
            "Epoch 115/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.4619 - accuracy: 0.4426 - val_loss: 9.3949 - val_accuracy: 0.2220\n",
            "Epoch 116/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.4408 - accuracy: 0.4463 - val_loss: 9.3976 - val_accuracy: 0.2219\n",
            "Epoch 117/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 2.4228 - accuracy: 0.4501 - val_loss: 9.4359 - val_accuracy: 0.2242\n",
            "Epoch 118/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.4102 - accuracy: 0.4514 - val_loss: 9.5149 - val_accuracy: 0.2244\n",
            "Epoch 119/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.3968 - accuracy: 0.4523 - val_loss: 9.5044 - val_accuracy: 0.2256\n",
            "Epoch 120/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.3810 - accuracy: 0.4557 - val_loss: 9.4979 - val_accuracy: 0.2244\n",
            "Epoch 121/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 2.3699 - accuracy: 0.4575 - val_loss: 9.5548 - val_accuracy: 0.2274\n",
            "Epoch 122/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.3475 - accuracy: 0.4616 - val_loss: 9.6470 - val_accuracy: 0.2292\n",
            "Epoch 123/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.3326 - accuracy: 0.4640 - val_loss: 9.7039 - val_accuracy: 0.2299\n",
            "Epoch 124/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.3154 - accuracy: 0.4661 - val_loss: 9.7224 - val_accuracy: 0.2295\n",
            "Epoch 125/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 2.3010 - accuracy: 0.4697 - val_loss: 9.7382 - val_accuracy: 0.2306\n",
            "Epoch 126/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.2839 - accuracy: 0.4720 - val_loss: 9.7801 - val_accuracy: 0.2314\n",
            "Epoch 127/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.2680 - accuracy: 0.4750 - val_loss: 9.8491 - val_accuracy: 0.2331\n",
            "Epoch 128/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.2501 - accuracy: 0.4784 - val_loss: 9.8534 - val_accuracy: 0.2326\n",
            "Epoch 129/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.2403 - accuracy: 0.4793 - val_loss: 9.9095 - val_accuracy: 0.2329\n",
            "Epoch 130/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 2.2223 - accuracy: 0.4842 - val_loss: 9.9595 - val_accuracy: 0.2343\n",
            "Epoch 131/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.2071 - accuracy: 0.4855 - val_loss: 9.9397 - val_accuracy: 0.2346\n",
            "Epoch 132/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.1945 - accuracy: 0.4885 - val_loss: 10.0633 - val_accuracy: 0.2361\n",
            "Epoch 133/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.1706 - accuracy: 0.4929 - val_loss: 10.1076 - val_accuracy: 0.2367\n",
            "Epoch 134/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.1659 - accuracy: 0.4917 - val_loss: 10.1309 - val_accuracy: 0.2374\n",
            "Epoch 135/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 2.1499 - accuracy: 0.4946 - val_loss: 10.0877 - val_accuracy: 0.2396\n",
            "Epoch 136/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.1327 - accuracy: 0.4991 - val_loss: 10.1750 - val_accuracy: 0.2392\n",
            "Epoch 137/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.1275 - accuracy: 0.4999 - val_loss: 10.1001 - val_accuracy: 0.2390\n",
            "Epoch 138/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 2.1108 - accuracy: 0.5024 - val_loss: 10.2359 - val_accuracy: 0.2414\n",
            "Epoch 139/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 2.0920 - accuracy: 0.5059 - val_loss: 10.2400 - val_accuracy: 0.2401\n",
            "Epoch 140/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.0749 - accuracy: 0.5089 - val_loss: 10.3422 - val_accuracy: 0.2410\n",
            "Epoch 141/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 2.0642 - accuracy: 0.5118 - val_loss: 10.3045 - val_accuracy: 0.2424\n",
            "Epoch 142/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 2.0501 - accuracy: 0.5137 - val_loss: 10.3876 - val_accuracy: 0.2454\n",
            "Epoch 143/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.0386 - accuracy: 0.5154 - val_loss: 10.4545 - val_accuracy: 0.2438\n",
            "Epoch 144/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 2.0232 - accuracy: 0.5175 - val_loss: 10.5027 - val_accuracy: 0.2460\n",
            "Epoch 145/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 2.0146 - accuracy: 0.5206 - val_loss: 10.4740 - val_accuracy: 0.2452\n",
            "Epoch 146/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 1.9955 - accuracy: 0.5255 - val_loss: 10.5944 - val_accuracy: 0.2474\n",
            "Epoch 147/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.9813 - accuracy: 0.5263 - val_loss: 10.6094 - val_accuracy: 0.2462\n",
            "Epoch 148/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 1.9742 - accuracy: 0.5274 - val_loss: 10.5839 - val_accuracy: 0.2480\n",
            "Epoch 149/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.9585 - accuracy: 0.5317 - val_loss: 10.7136 - val_accuracy: 0.2483\n",
            "Epoch 150/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.9421 - accuracy: 0.5332 - val_loss: 10.7658 - val_accuracy: 0.2516\n",
            "Epoch 151/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.9330 - accuracy: 0.5347 - val_loss: 10.7759 - val_accuracy: 0.2500\n",
            "Epoch 152/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.9215 - accuracy: 0.5385 - val_loss: 10.7644 - val_accuracy: 0.2504\n",
            "Epoch 153/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.9008 - accuracy: 0.5426 - val_loss: 10.7879 - val_accuracy: 0.2522\n",
            "Epoch 154/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.8914 - accuracy: 0.5430 - val_loss: 10.9404 - val_accuracy: 0.2526\n",
            "Epoch 155/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.8818 - accuracy: 0.5454 - val_loss: 10.9579 - val_accuracy: 0.2548\n",
            "Epoch 156/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.8727 - accuracy: 0.5470 - val_loss: 10.9172 - val_accuracy: 0.2555\n",
            "Epoch 157/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.8611 - accuracy: 0.5505 - val_loss: 11.0343 - val_accuracy: 0.2551\n",
            "Epoch 158/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.8492 - accuracy: 0.5509 - val_loss: 11.0247 - val_accuracy: 0.2559\n",
            "Epoch 159/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.8360 - accuracy: 0.5528 - val_loss: 11.0461 - val_accuracy: 0.2567\n",
            "Epoch 160/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.8233 - accuracy: 0.5560 - val_loss: 11.1573 - val_accuracy: 0.2568\n",
            "Epoch 161/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.8089 - accuracy: 0.5593 - val_loss: 11.1516 - val_accuracy: 0.2553\n",
            "Epoch 162/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 1.7987 - accuracy: 0.5605 - val_loss: 11.2308 - val_accuracy: 0.2590\n",
            "Epoch 163/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.7929 - accuracy: 0.5639 - val_loss: 11.1695 - val_accuracy: 0.2589\n",
            "Epoch 164/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.7779 - accuracy: 0.5649 - val_loss: 11.1917 - val_accuracy: 0.2592\n",
            "Epoch 165/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.7631 - accuracy: 0.5678 - val_loss: 11.3111 - val_accuracy: 0.2610\n",
            "Epoch 166/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.7577 - accuracy: 0.5691 - val_loss: 11.3323 - val_accuracy: 0.2618\n",
            "Epoch 167/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.7453 - accuracy: 0.5722 - val_loss: 11.3167 - val_accuracy: 0.2614\n",
            "Epoch 168/500\n",
            "79/79 [==============================] - 16s 201ms/step - loss: 1.7318 - accuracy: 0.5747 - val_loss: 11.4400 - val_accuracy: 0.2636\n",
            "Epoch 169/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.7260 - accuracy: 0.5752 - val_loss: 11.4551 - val_accuracy: 0.2609\n",
            "Epoch 170/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.7172 - accuracy: 0.5782 - val_loss: 11.5060 - val_accuracy: 0.2645\n",
            "Epoch 171/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.7099 - accuracy: 0.5780 - val_loss: 11.4783 - val_accuracy: 0.2643\n",
            "Epoch 172/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.6917 - accuracy: 0.5839 - val_loss: 11.5215 - val_accuracy: 0.2647\n",
            "Epoch 173/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.6807 - accuracy: 0.5835 - val_loss: 11.4892 - val_accuracy: 0.2650\n",
            "Epoch 174/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.6723 - accuracy: 0.5852 - val_loss: 11.6663 - val_accuracy: 0.2650\n",
            "Epoch 175/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.6602 - accuracy: 0.5876 - val_loss: 11.7333 - val_accuracy: 0.2675\n",
            "Epoch 176/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.6528 - accuracy: 0.5894 - val_loss: 11.7012 - val_accuracy: 0.2668\n",
            "Epoch 177/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 1.6453 - accuracy: 0.5922 - val_loss: 11.7591 - val_accuracy: 0.2675\n",
            "Epoch 178/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 1.6315 - accuracy: 0.5939 - val_loss: 11.8043 - val_accuracy: 0.2679\n",
            "Epoch 179/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.6233 - accuracy: 0.5959 - val_loss: 11.8465 - val_accuracy: 0.2692\n",
            "Epoch 180/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.6100 - accuracy: 0.5986 - val_loss: 11.8281 - val_accuracy: 0.2686\n",
            "Epoch 181/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.6019 - accuracy: 0.6000 - val_loss: 11.9346 - val_accuracy: 0.2715\n",
            "Epoch 182/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.5882 - accuracy: 0.6027 - val_loss: 11.9918 - val_accuracy: 0.2700\n",
            "Epoch 183/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.5872 - accuracy: 0.6031 - val_loss: 12.0052 - val_accuracy: 0.2693\n",
            "Epoch 184/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.5711 - accuracy: 0.6058 - val_loss: 11.9773 - val_accuracy: 0.2724\n",
            "Epoch 185/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.5662 - accuracy: 0.6076 - val_loss: 12.0282 - val_accuracy: 0.2717\n",
            "Epoch 186/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 1.5580 - accuracy: 0.6101 - val_loss: 12.1014 - val_accuracy: 0.2737\n",
            "Epoch 187/500\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 1.5445 - accuracy: 0.6115 - val_loss: 12.1969 - val_accuracy: 0.2744\n",
            "Epoch 188/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.5397 - accuracy: 0.6125 - val_loss: 12.0747 - val_accuracy: 0.2722\n",
            "Epoch 189/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.5269 - accuracy: 0.6140 - val_loss: 12.0763 - val_accuracy: 0.2751\n",
            "Epoch 190/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.5128 - accuracy: 0.6188 - val_loss: 12.1250 - val_accuracy: 0.2764\n",
            "Epoch 191/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.5087 - accuracy: 0.6208 - val_loss: 12.2359 - val_accuracy: 0.2772\n",
            "Epoch 192/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.5012 - accuracy: 0.6201 - val_loss: 12.1767 - val_accuracy: 0.2769\n",
            "Epoch 193/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.4884 - accuracy: 0.6244 - val_loss: 12.2376 - val_accuracy: 0.2779\n",
            "Epoch 194/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.4782 - accuracy: 0.6252 - val_loss: 12.3467 - val_accuracy: 0.2769\n",
            "Epoch 195/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.4709 - accuracy: 0.6268 - val_loss: 12.3985 - val_accuracy: 0.2784\n",
            "Epoch 196/500\n",
            "79/79 [==============================] - 7s 92ms/step - loss: 1.4644 - accuracy: 0.6291 - val_loss: 12.4129 - val_accuracy: 0.2784\n",
            "Epoch 197/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.4617 - accuracy: 0.6281 - val_loss: 12.4764 - val_accuracy: 0.2788\n",
            "Epoch 198/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.4420 - accuracy: 0.6320 - val_loss: 12.5119 - val_accuracy: 0.2810\n",
            "Epoch 199/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.4404 - accuracy: 0.6327 - val_loss: 12.5784 - val_accuracy: 0.2819\n",
            "Epoch 200/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.4326 - accuracy: 0.6365 - val_loss: 12.5833 - val_accuracy: 0.2806\n",
            "Epoch 201/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.4252 - accuracy: 0.6365 - val_loss: 12.5552 - val_accuracy: 0.2814\n",
            "Epoch 202/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.4190 - accuracy: 0.6378 - val_loss: 12.6749 - val_accuracy: 0.2823\n",
            "Epoch 203/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.4133 - accuracy: 0.6398 - val_loss: 12.6466 - val_accuracy: 0.2840\n",
            "Epoch 204/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.4058 - accuracy: 0.6411 - val_loss: 12.7851 - val_accuracy: 0.2831\n",
            "Epoch 205/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.3970 - accuracy: 0.6440 - val_loss: 12.6829 - val_accuracy: 0.2832\n",
            "Epoch 206/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.3882 - accuracy: 0.6450 - val_loss: 12.7868 - val_accuracy: 0.2809\n",
            "Epoch 207/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.3838 - accuracy: 0.6461 - val_loss: 12.7773 - val_accuracy: 0.2839\n",
            "Epoch 208/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.3825 - accuracy: 0.6460 - val_loss: 12.8782 - val_accuracy: 0.2848\n",
            "Epoch 209/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.3665 - accuracy: 0.6494 - val_loss: 12.8704 - val_accuracy: 0.2856\n",
            "Epoch 210/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.3534 - accuracy: 0.6524 - val_loss: 12.8958 - val_accuracy: 0.2860\n",
            "Epoch 211/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.3480 - accuracy: 0.6534 - val_loss: 13.0054 - val_accuracy: 0.2855\n",
            "Epoch 212/500\n",
            "79/79 [==============================] - 8s 98ms/step - loss: 1.3431 - accuracy: 0.6534 - val_loss: 12.9808 - val_accuracy: 0.2870\n",
            "Epoch 213/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.3367 - accuracy: 0.6557 - val_loss: 12.9375 - val_accuracy: 0.2876\n",
            "Epoch 214/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.3323 - accuracy: 0.6551 - val_loss: 12.9978 - val_accuracy: 0.2860\n",
            "Epoch 215/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.3213 - accuracy: 0.6588 - val_loss: 13.0397 - val_accuracy: 0.2893\n",
            "Epoch 216/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.3161 - accuracy: 0.6617 - val_loss: 13.1560 - val_accuracy: 0.2891\n",
            "Epoch 217/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.3067 - accuracy: 0.6613 - val_loss: 13.1949 - val_accuracy: 0.2907\n",
            "Epoch 218/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.3032 - accuracy: 0.6642 - val_loss: 13.0681 - val_accuracy: 0.2895\n",
            "Epoch 219/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.2953 - accuracy: 0.6651 - val_loss: 13.2183 - val_accuracy: 0.2904\n",
            "Epoch 220/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.2917 - accuracy: 0.6655 - val_loss: 13.2657 - val_accuracy: 0.2903\n",
            "Epoch 221/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.2826 - accuracy: 0.6684 - val_loss: 13.3355 - val_accuracy: 0.2910\n",
            "Epoch 222/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.2773 - accuracy: 0.6684 - val_loss: 13.3090 - val_accuracy: 0.2921\n",
            "Epoch 223/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.2611 - accuracy: 0.6727 - val_loss: 13.3886 - val_accuracy: 0.2924\n",
            "Epoch 224/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.2602 - accuracy: 0.6716 - val_loss: 13.3159 - val_accuracy: 0.2919\n",
            "Epoch 225/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 1.2491 - accuracy: 0.6752 - val_loss: 13.3824 - val_accuracy: 0.2927\n",
            "Epoch 226/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.2473 - accuracy: 0.6749 - val_loss: 13.4550 - val_accuracy: 0.2933\n",
            "Epoch 227/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.2537 - accuracy: 0.6742 - val_loss: 13.5561 - val_accuracy: 0.2919\n",
            "Epoch 228/500\n",
            "79/79 [==============================] - 9s 109ms/step - loss: 1.2395 - accuracy: 0.6772 - val_loss: 13.5505 - val_accuracy: 0.2947\n",
            "Epoch 229/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.2294 - accuracy: 0.6791 - val_loss: 13.5377 - val_accuracy: 0.2938\n",
            "Epoch 230/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 1.2218 - accuracy: 0.6800 - val_loss: 13.6242 - val_accuracy: 0.2948\n",
            "Epoch 231/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.2199 - accuracy: 0.6814 - val_loss: 13.5669 - val_accuracy: 0.2968\n",
            "Epoch 232/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.2191 - accuracy: 0.6821 - val_loss: 13.6049 - val_accuracy: 0.2943\n",
            "Epoch 233/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.2084 - accuracy: 0.6850 - val_loss: 13.7133 - val_accuracy: 0.2956\n",
            "Epoch 234/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.1979 - accuracy: 0.6864 - val_loss: 13.6642 - val_accuracy: 0.2955\n",
            "Epoch 235/500\n",
            "79/79 [==============================] - 8s 105ms/step - loss: 1.1954 - accuracy: 0.6854 - val_loss: 13.6737 - val_accuracy: 0.2968\n",
            "Epoch 236/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.1826 - accuracy: 0.6892 - val_loss: 13.8042 - val_accuracy: 0.2972\n",
            "Epoch 237/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.1825 - accuracy: 0.6896 - val_loss: 13.7477 - val_accuracy: 0.2973\n",
            "Epoch 238/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.1746 - accuracy: 0.6906 - val_loss: 13.7736 - val_accuracy: 0.2986\n",
            "Epoch 239/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.1688 - accuracy: 0.6919 - val_loss: 13.8597 - val_accuracy: 0.2976\n",
            "Epoch 240/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 1.1613 - accuracy: 0.6933 - val_loss: 13.8682 - val_accuracy: 0.3007\n",
            "Epoch 241/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 1.1600 - accuracy: 0.6951 - val_loss: 13.9416 - val_accuracy: 0.3003\n",
            "Epoch 242/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.1596 - accuracy: 0.6945 - val_loss: 13.9494 - val_accuracy: 0.2982\n",
            "Epoch 243/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.1487 - accuracy: 0.6990 - val_loss: 13.9835 - val_accuracy: 0.2983\n",
            "Epoch 244/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 1.1489 - accuracy: 0.6964 - val_loss: 14.1148 - val_accuracy: 0.3001\n",
            "Epoch 245/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 1.1346 - accuracy: 0.7013 - val_loss: 14.0796 - val_accuracy: 0.2994\n",
            "Epoch 246/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 1.1334 - accuracy: 0.7006 - val_loss: 14.0768 - val_accuracy: 0.2998\n",
            "Epoch 247/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.1343 - accuracy: 0.7003 - val_loss: 14.0846 - val_accuracy: 0.3002\n",
            "Epoch 248/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.1232 - accuracy: 0.7034 - val_loss: 14.1231 - val_accuracy: 0.3015\n",
            "Epoch 249/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.1119 - accuracy: 0.7052 - val_loss: 14.2294 - val_accuracy: 0.3033\n",
            "Epoch 250/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.1082 - accuracy: 0.7064 - val_loss: 14.0803 - val_accuracy: 0.3011\n",
            "Epoch 251/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.1117 - accuracy: 0.7059 - val_loss: 14.1685 - val_accuracy: 0.3032\n",
            "Epoch 252/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0996 - accuracy: 0.7079 - val_loss: 14.2276 - val_accuracy: 0.3030\n",
            "Epoch 253/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.1002 - accuracy: 0.7073 - val_loss: 14.2964 - val_accuracy: 0.3035\n",
            "Epoch 254/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0830 - accuracy: 0.7122 - val_loss: 14.3151 - val_accuracy: 0.3034\n",
            "Epoch 255/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.0854 - accuracy: 0.7117 - val_loss: 14.3652 - val_accuracy: 0.3040\n",
            "Epoch 256/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 1.0773 - accuracy: 0.7131 - val_loss: 14.3537 - val_accuracy: 0.3055\n",
            "Epoch 257/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0704 - accuracy: 0.7158 - val_loss: 14.3586 - val_accuracy: 0.3048\n",
            "Epoch 258/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0695 - accuracy: 0.7149 - val_loss: 14.4316 - val_accuracy: 0.3054\n",
            "Epoch 259/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0693 - accuracy: 0.7151 - val_loss: 14.3815 - val_accuracy: 0.3048\n",
            "Epoch 260/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.0635 - accuracy: 0.7166 - val_loss: 14.4886 - val_accuracy: 0.3057\n",
            "Epoch 261/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0511 - accuracy: 0.7185 - val_loss: 14.4042 - val_accuracy: 0.3040\n",
            "Epoch 262/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 1.0488 - accuracy: 0.7186 - val_loss: 14.4627 - val_accuracy: 0.3059\n",
            "Epoch 263/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.0452 - accuracy: 0.7217 - val_loss: 14.5622 - val_accuracy: 0.3082\n",
            "Epoch 264/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.0425 - accuracy: 0.7207 - val_loss: 14.6458 - val_accuracy: 0.3057\n",
            "Epoch 265/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0430 - accuracy: 0.7217 - val_loss: 14.5841 - val_accuracy: 0.3060\n",
            "Epoch 266/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 1.0319 - accuracy: 0.7231 - val_loss: 14.6319 - val_accuracy: 0.3068\n",
            "Epoch 267/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0302 - accuracy: 0.7245 - val_loss: 14.6857 - val_accuracy: 0.3072\n",
            "Epoch 268/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 1.0252 - accuracy: 0.7266 - val_loss: 14.7528 - val_accuracy: 0.3064\n",
            "Epoch 269/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 1.0199 - accuracy: 0.7275 - val_loss: 14.7568 - val_accuracy: 0.3091\n",
            "Epoch 270/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.0125 - accuracy: 0.7284 - val_loss: 14.7304 - val_accuracy: 0.3091\n",
            "Epoch 271/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 1.0114 - accuracy: 0.7281 - val_loss: 14.7167 - val_accuracy: 0.3075\n",
            "Epoch 272/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0033 - accuracy: 0.7311 - val_loss: 14.8855 - val_accuracy: 0.3078\n",
            "Epoch 273/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0082 - accuracy: 0.7299 - val_loss: 14.7529 - val_accuracy: 0.3090\n",
            "Epoch 274/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.9975 - accuracy: 0.7322 - val_loss: 14.7589 - val_accuracy: 0.3059\n",
            "Epoch 275/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 1.0050 - accuracy: 0.7294 - val_loss: 14.8917 - val_accuracy: 0.3085\n",
            "Epoch 276/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9898 - accuracy: 0.7334 - val_loss: 14.8644 - val_accuracy: 0.3087\n",
            "Epoch 277/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.9795 - accuracy: 0.7353 - val_loss: 14.8448 - val_accuracy: 0.3083\n",
            "Epoch 278/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.9826 - accuracy: 0.7358 - val_loss: 14.9455 - val_accuracy: 0.3108\n",
            "Epoch 279/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9857 - accuracy: 0.7338 - val_loss: 15.0235 - val_accuracy: 0.3102\n",
            "Epoch 280/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9737 - accuracy: 0.7383 - val_loss: 15.0245 - val_accuracy: 0.3107\n",
            "Epoch 281/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9672 - accuracy: 0.7383 - val_loss: 15.0100 - val_accuracy: 0.3108\n",
            "Epoch 282/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9550 - accuracy: 0.7421 - val_loss: 14.9446 - val_accuracy: 0.3103\n",
            "Epoch 283/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9655 - accuracy: 0.7401 - val_loss: 15.0753 - val_accuracy: 0.3105\n",
            "Epoch 284/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.9522 - accuracy: 0.7414 - val_loss: 15.1002 - val_accuracy: 0.3122\n",
            "Epoch 285/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9520 - accuracy: 0.7434 - val_loss: 15.2693 - val_accuracy: 0.3111\n",
            "Epoch 286/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 0.9454 - accuracy: 0.7440 - val_loss: 15.1691 - val_accuracy: 0.3127\n",
            "Epoch 287/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9468 - accuracy: 0.7426 - val_loss: 15.2032 - val_accuracy: 0.3119\n",
            "Epoch 288/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.9398 - accuracy: 0.7448 - val_loss: 15.2909 - val_accuracy: 0.3136\n",
            "Epoch 289/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9376 - accuracy: 0.7457 - val_loss: 15.2114 - val_accuracy: 0.3136\n",
            "Epoch 290/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.9360 - accuracy: 0.7457 - val_loss: 15.1805 - val_accuracy: 0.3107\n",
            "Epoch 291/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.9392 - accuracy: 0.7453 - val_loss: 15.2511 - val_accuracy: 0.3126\n",
            "Epoch 292/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.9318 - accuracy: 0.7459 - val_loss: 15.2864 - val_accuracy: 0.3109\n",
            "Epoch 293/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9299 - accuracy: 0.7487 - val_loss: 15.2840 - val_accuracy: 0.3132\n",
            "Epoch 294/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.9281 - accuracy: 0.7481 - val_loss: 15.2989 - val_accuracy: 0.3131\n",
            "Epoch 295/500\n",
            "79/79 [==============================] - 8s 104ms/step - loss: 0.9202 - accuracy: 0.7495 - val_loss: 15.3357 - val_accuracy: 0.3140\n",
            "Epoch 296/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9131 - accuracy: 0.7517 - val_loss: 15.3729 - val_accuracy: 0.3135\n",
            "Epoch 297/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.9090 - accuracy: 0.7520 - val_loss: 15.4733 - val_accuracy: 0.3130\n",
            "Epoch 298/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.9104 - accuracy: 0.7528 - val_loss: 15.5013 - val_accuracy: 0.3141\n",
            "Epoch 299/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.9016 - accuracy: 0.7533 - val_loss: 15.4714 - val_accuracy: 0.3151\n",
            "Epoch 300/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.9011 - accuracy: 0.7540 - val_loss: 15.4745 - val_accuracy: 0.3142\n",
            "Epoch 301/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.8933 - accuracy: 0.7563 - val_loss: 15.6098 - val_accuracy: 0.3142\n",
            "Epoch 302/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.8913 - accuracy: 0.7562 - val_loss: 15.6647 - val_accuracy: 0.3164\n",
            "Epoch 303/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8906 - accuracy: 0.7568 - val_loss: 15.5458 - val_accuracy: 0.3157\n",
            "Epoch 304/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8846 - accuracy: 0.7579 - val_loss: 15.6589 - val_accuracy: 0.3157\n",
            "Epoch 305/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8795 - accuracy: 0.7601 - val_loss: 15.6234 - val_accuracy: 0.3154\n",
            "Epoch 306/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8856 - accuracy: 0.7585 - val_loss: 15.6203 - val_accuracy: 0.3156\n",
            "Epoch 307/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8810 - accuracy: 0.7595 - val_loss: 15.6318 - val_accuracy: 0.3159\n",
            "Epoch 308/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8754 - accuracy: 0.7606 - val_loss: 15.6838 - val_accuracy: 0.3162\n",
            "Epoch 309/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8746 - accuracy: 0.7614 - val_loss: 15.7803 - val_accuracy: 0.3157\n",
            "Epoch 310/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8736 - accuracy: 0.7613 - val_loss: 15.6806 - val_accuracy: 0.3161\n",
            "Epoch 311/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8682 - accuracy: 0.7637 - val_loss: 15.6299 - val_accuracy: 0.3157\n",
            "Epoch 312/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8634 - accuracy: 0.7617 - val_loss: 15.7512 - val_accuracy: 0.3159\n",
            "Epoch 313/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.8548 - accuracy: 0.7653 - val_loss: 15.6832 - val_accuracy: 0.3168\n",
            "Epoch 314/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.8521 - accuracy: 0.7660 - val_loss: 15.7760 - val_accuracy: 0.3189\n",
            "Epoch 315/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8476 - accuracy: 0.7681 - val_loss: 15.8101 - val_accuracy: 0.3184\n",
            "Epoch 316/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.8489 - accuracy: 0.7672 - val_loss: 15.9203 - val_accuracy: 0.3182\n",
            "Epoch 317/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8417 - accuracy: 0.7690 - val_loss: 15.8387 - val_accuracy: 0.3177\n",
            "Epoch 318/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8395 - accuracy: 0.7691 - val_loss: 15.9618 - val_accuracy: 0.3188\n",
            "Epoch 319/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.8391 - accuracy: 0.7698 - val_loss: 15.9265 - val_accuracy: 0.3170\n",
            "Epoch 320/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.8404 - accuracy: 0.7689 - val_loss: 15.9341 - val_accuracy: 0.3181\n",
            "Epoch 321/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.8328 - accuracy: 0.7703 - val_loss: 15.9619 - val_accuracy: 0.3183\n",
            "Epoch 322/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.8243 - accuracy: 0.7726 - val_loss: 15.9164 - val_accuracy: 0.3180\n",
            "Epoch 323/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8225 - accuracy: 0.7732 - val_loss: 16.1983 - val_accuracy: 0.3174\n",
            "Epoch 324/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.8243 - accuracy: 0.7729 - val_loss: 16.0535 - val_accuracy: 0.3198\n",
            "Epoch 325/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.8171 - accuracy: 0.7741 - val_loss: 16.0993 - val_accuracy: 0.3200\n",
            "Epoch 326/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8177 - accuracy: 0.7747 - val_loss: 16.1098 - val_accuracy: 0.3187\n",
            "Epoch 327/500\n",
            "79/79 [==============================] - 8s 105ms/step - loss: 0.8176 - accuracy: 0.7741 - val_loss: 16.1434 - val_accuracy: 0.3215\n",
            "Epoch 328/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8124 - accuracy: 0.7758 - val_loss: 16.1243 - val_accuracy: 0.3208\n",
            "Epoch 329/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8019 - accuracy: 0.7778 - val_loss: 16.2688 - val_accuracy: 0.3202\n",
            "Epoch 330/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8075 - accuracy: 0.7770 - val_loss: 16.2643 - val_accuracy: 0.3200\n",
            "Epoch 331/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8140 - accuracy: 0.7748 - val_loss: 16.1860 - val_accuracy: 0.3204\n",
            "Epoch 332/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.8091 - accuracy: 0.7776 - val_loss: 16.1765 - val_accuracy: 0.3208\n",
            "Epoch 333/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.7937 - accuracy: 0.7814 - val_loss: 16.2775 - val_accuracy: 0.3214\n",
            "Epoch 334/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7969 - accuracy: 0.7792 - val_loss: 16.2729 - val_accuracy: 0.3203\n",
            "Epoch 335/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.7855 - accuracy: 0.7822 - val_loss: 16.1602 - val_accuracy: 0.3216\n",
            "Epoch 336/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7900 - accuracy: 0.7819 - val_loss: 16.3238 - val_accuracy: 0.3212\n",
            "Epoch 337/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7873 - accuracy: 0.7813 - val_loss: 16.2838 - val_accuracy: 0.3211\n",
            "Epoch 338/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7835 - accuracy: 0.7826 - val_loss: 16.3948 - val_accuracy: 0.3202\n",
            "Epoch 339/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7796 - accuracy: 0.7843 - val_loss: 16.2430 - val_accuracy: 0.3216\n",
            "Epoch 340/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7809 - accuracy: 0.7840 - val_loss: 16.3520 - val_accuracy: 0.3215\n",
            "Epoch 341/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.7716 - accuracy: 0.7863 - val_loss: 16.5376 - val_accuracy: 0.3219\n",
            "Epoch 342/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7791 - accuracy: 0.7845 - val_loss: 16.4903 - val_accuracy: 0.3210\n",
            "Epoch 343/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.7706 - accuracy: 0.7859 - val_loss: 16.4493 - val_accuracy: 0.3220\n",
            "Epoch 344/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.7766 - accuracy: 0.7853 - val_loss: 16.5222 - val_accuracy: 0.3226\n",
            "Epoch 345/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7720 - accuracy: 0.7863 - val_loss: 16.5451 - val_accuracy: 0.3213\n",
            "Epoch 346/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7626 - accuracy: 0.7892 - val_loss: 16.5472 - val_accuracy: 0.3222\n",
            "Epoch 347/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7616 - accuracy: 0.7879 - val_loss: 16.5091 - val_accuracy: 0.3221\n",
            "Epoch 348/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.7625 - accuracy: 0.7878 - val_loss: 16.5411 - val_accuracy: 0.3216\n",
            "Epoch 349/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.7564 - accuracy: 0.7899 - val_loss: 16.6023 - val_accuracy: 0.3235\n",
            "Epoch 350/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7551 - accuracy: 0.7891 - val_loss: 16.6553 - val_accuracy: 0.3229\n",
            "Epoch 351/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7474 - accuracy: 0.7918 - val_loss: 16.7664 - val_accuracy: 0.3212\n",
            "Epoch 352/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7499 - accuracy: 0.7904 - val_loss: 16.5621 - val_accuracy: 0.3220\n",
            "Epoch 353/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.7397 - accuracy: 0.7930 - val_loss: 16.5343 - val_accuracy: 0.3247\n",
            "Epoch 354/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7449 - accuracy: 0.7931 - val_loss: 16.6407 - val_accuracy: 0.3225\n",
            "Epoch 355/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7484 - accuracy: 0.7923 - val_loss: 16.6703 - val_accuracy: 0.3227\n",
            "Epoch 356/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7410 - accuracy: 0.7936 - val_loss: 16.6769 - val_accuracy: 0.3221\n",
            "Epoch 357/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.7436 - accuracy: 0.7935 - val_loss: 16.6951 - val_accuracy: 0.3231\n",
            "Epoch 358/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.7349 - accuracy: 0.7954 - val_loss: 16.7651 - val_accuracy: 0.3228\n",
            "Epoch 359/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7268 - accuracy: 0.7962 - val_loss: 16.6607 - val_accuracy: 0.3232\n",
            "Epoch 360/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7331 - accuracy: 0.7949 - val_loss: 16.8882 - val_accuracy: 0.3230\n",
            "Epoch 361/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7225 - accuracy: 0.7979 - val_loss: 16.8335 - val_accuracy: 0.3243\n",
            "Epoch 362/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.7285 - accuracy: 0.7983 - val_loss: 16.9152 - val_accuracy: 0.3220\n",
            "Epoch 363/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.7263 - accuracy: 0.7968 - val_loss: 16.9301 - val_accuracy: 0.3233\n",
            "Epoch 364/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7266 - accuracy: 0.7962 - val_loss: 16.8879 - val_accuracy: 0.3243\n",
            "Epoch 365/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.7171 - accuracy: 0.7989 - val_loss: 16.9090 - val_accuracy: 0.3247\n",
            "Epoch 366/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.7196 - accuracy: 0.7986 - val_loss: 16.9149 - val_accuracy: 0.3248\n",
            "Epoch 367/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7167 - accuracy: 0.7985 - val_loss: 17.0427 - val_accuracy: 0.3240\n",
            "Epoch 368/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.7070 - accuracy: 0.8023 - val_loss: 16.9393 - val_accuracy: 0.3255\n",
            "Epoch 369/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7113 - accuracy: 0.8005 - val_loss: 16.8276 - val_accuracy: 0.3252\n",
            "Epoch 370/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7063 - accuracy: 0.8021 - val_loss: 17.0098 - val_accuracy: 0.3246\n",
            "Epoch 371/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.7095 - accuracy: 0.8016 - val_loss: 17.0563 - val_accuracy: 0.3253\n",
            "Epoch 372/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7155 - accuracy: 0.7998 - val_loss: 17.0389 - val_accuracy: 0.3251\n",
            "Epoch 373/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7099 - accuracy: 0.8015 - val_loss: 16.9362 - val_accuracy: 0.3241\n",
            "Epoch 374/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6979 - accuracy: 0.8042 - val_loss: 17.0300 - val_accuracy: 0.3242\n",
            "Epoch 375/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.7002 - accuracy: 0.8033 - val_loss: 17.1841 - val_accuracy: 0.3245\n",
            "Epoch 376/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6999 - accuracy: 0.8047 - val_loss: 16.9958 - val_accuracy: 0.3251\n",
            "Epoch 377/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.6983 - accuracy: 0.8034 - val_loss: 17.0461 - val_accuracy: 0.3256\n",
            "Epoch 378/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.6860 - accuracy: 0.8070 - val_loss: 17.1539 - val_accuracy: 0.3261\n",
            "Epoch 379/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6866 - accuracy: 0.8066 - val_loss: 17.0409 - val_accuracy: 0.3250\n",
            "Epoch 380/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6910 - accuracy: 0.8066 - val_loss: 17.1061 - val_accuracy: 0.3252\n",
            "Epoch 381/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6874 - accuracy: 0.8067 - val_loss: 17.2044 - val_accuracy: 0.3253\n",
            "Epoch 382/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.6872 - accuracy: 0.8084 - val_loss: 17.1434 - val_accuracy: 0.3264\n",
            "Epoch 383/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6805 - accuracy: 0.8086 - val_loss: 17.2267 - val_accuracy: 0.3263\n",
            "Epoch 384/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6804 - accuracy: 0.8085 - val_loss: 17.0709 - val_accuracy: 0.3260\n",
            "Epoch 385/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6765 - accuracy: 0.8094 - val_loss: 17.1944 - val_accuracy: 0.3263\n",
            "Epoch 386/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6778 - accuracy: 0.8097 - val_loss: 17.3048 - val_accuracy: 0.3247\n",
            "Epoch 387/500\n",
            "79/79 [==============================] - 8s 100ms/step - loss: 0.6779 - accuracy: 0.8090 - val_loss: 17.2637 - val_accuracy: 0.3270\n",
            "Epoch 388/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6749 - accuracy: 0.8104 - val_loss: 17.1922 - val_accuracy: 0.3263\n",
            "Epoch 389/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6726 - accuracy: 0.8106 - val_loss: 17.4035 - val_accuracy: 0.3257\n",
            "Epoch 390/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6731 - accuracy: 0.8108 - val_loss: 17.2081 - val_accuracy: 0.3264\n",
            "Epoch 391/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6619 - accuracy: 0.8128 - val_loss: 17.2927 - val_accuracy: 0.3262\n",
            "Epoch 392/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6623 - accuracy: 0.8143 - val_loss: 17.2962 - val_accuracy: 0.3270\n",
            "Epoch 393/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6660 - accuracy: 0.8117 - val_loss: 17.2858 - val_accuracy: 0.3262\n",
            "Epoch 394/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6612 - accuracy: 0.8142 - val_loss: 17.3336 - val_accuracy: 0.3251\n",
            "Epoch 395/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6590 - accuracy: 0.8142 - val_loss: 17.3338 - val_accuracy: 0.3264\n",
            "Epoch 396/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.6523 - accuracy: 0.8167 - val_loss: 17.4281 - val_accuracy: 0.3283\n",
            "Epoch 397/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6572 - accuracy: 0.8149 - val_loss: 17.3129 - val_accuracy: 0.3271\n",
            "Epoch 398/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6562 - accuracy: 0.8149 - val_loss: 17.4734 - val_accuracy: 0.3258\n",
            "Epoch 399/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6630 - accuracy: 0.8133 - val_loss: 17.4065 - val_accuracy: 0.3264\n",
            "Epoch 400/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6522 - accuracy: 0.8169 - val_loss: 17.3845 - val_accuracy: 0.3272\n",
            "Epoch 401/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6472 - accuracy: 0.8175 - val_loss: 17.4155 - val_accuracy: 0.3264\n",
            "Epoch 402/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6492 - accuracy: 0.8168 - val_loss: 17.3421 - val_accuracy: 0.3263\n",
            "Epoch 403/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6445 - accuracy: 0.8186 - val_loss: 17.5848 - val_accuracy: 0.3266\n",
            "Epoch 404/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6402 - accuracy: 0.8193 - val_loss: 17.4017 - val_accuracy: 0.3261\n",
            "Epoch 405/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6383 - accuracy: 0.8195 - val_loss: 17.5397 - val_accuracy: 0.3265\n",
            "Epoch 406/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6382 - accuracy: 0.8200 - val_loss: 17.6412 - val_accuracy: 0.3262\n",
            "Epoch 407/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6322 - accuracy: 0.8210 - val_loss: 17.6116 - val_accuracy: 0.3280\n",
            "Epoch 408/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6303 - accuracy: 0.8208 - val_loss: 17.6117 - val_accuracy: 0.3270\n",
            "Epoch 409/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6326 - accuracy: 0.8209 - val_loss: 17.5130 - val_accuracy: 0.3270\n",
            "Epoch 410/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6352 - accuracy: 0.8211 - val_loss: 17.5847 - val_accuracy: 0.3278\n",
            "Epoch 411/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6364 - accuracy: 0.8204 - val_loss: 17.5965 - val_accuracy: 0.3280\n",
            "Epoch 412/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6347 - accuracy: 0.8200 - val_loss: 17.6747 - val_accuracy: 0.3278\n",
            "Epoch 413/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6333 - accuracy: 0.8208 - val_loss: 17.6545 - val_accuracy: 0.3273\n",
            "Epoch 414/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.6315 - accuracy: 0.8227 - val_loss: 17.6777 - val_accuracy: 0.3284\n",
            "Epoch 415/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6261 - accuracy: 0.8223 - val_loss: 17.6293 - val_accuracy: 0.3271\n",
            "Epoch 416/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6262 - accuracy: 0.8224 - val_loss: 17.7468 - val_accuracy: 0.3280\n",
            "Epoch 417/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 0.6276 - accuracy: 0.8224 - val_loss: 17.6344 - val_accuracy: 0.3285\n",
            "Epoch 418/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.6214 - accuracy: 0.8248 - val_loss: 17.7152 - val_accuracy: 0.3286\n",
            "Epoch 419/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.6160 - accuracy: 0.8249 - val_loss: 17.7908 - val_accuracy: 0.3291\n",
            "Epoch 420/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6205 - accuracy: 0.8233 - val_loss: 17.7894 - val_accuracy: 0.3283\n",
            "Epoch 421/500\n",
            "79/79 [==============================] - 8s 102ms/step - loss: 0.6176 - accuracy: 0.8250 - val_loss: 17.7739 - val_accuracy: 0.3293\n",
            "Epoch 422/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.6128 - accuracy: 0.8271 - val_loss: 17.6843 - val_accuracy: 0.3293\n",
            "Epoch 423/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6071 - accuracy: 0.8271 - val_loss: 17.6913 - val_accuracy: 0.3290\n",
            "Epoch 424/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6128 - accuracy: 0.8288 - val_loss: 17.7009 - val_accuracy: 0.3283\n",
            "Epoch 425/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.6079 - accuracy: 0.8271 - val_loss: 17.7819 - val_accuracy: 0.3296\n",
            "Epoch 426/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6061 - accuracy: 0.8271 - val_loss: 17.7648 - val_accuracy: 0.3270\n",
            "Epoch 427/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6073 - accuracy: 0.8276 - val_loss: 17.9917 - val_accuracy: 0.3291\n",
            "Epoch 428/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6120 - accuracy: 0.8262 - val_loss: 17.7741 - val_accuracy: 0.3276\n",
            "Epoch 429/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6012 - accuracy: 0.8285 - val_loss: 17.9115 - val_accuracy: 0.3276\n",
            "Epoch 430/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.6017 - accuracy: 0.8288 - val_loss: 17.9679 - val_accuracy: 0.3295\n",
            "Epoch 431/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5985 - accuracy: 0.8293 - val_loss: 17.8538 - val_accuracy: 0.3286\n",
            "Epoch 432/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5975 - accuracy: 0.8298 - val_loss: 17.8699 - val_accuracy: 0.3290\n",
            "Epoch 433/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.6003 - accuracy: 0.8289 - val_loss: 17.9313 - val_accuracy: 0.3284\n",
            "Epoch 434/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5981 - accuracy: 0.8284 - val_loss: 17.9166 - val_accuracy: 0.3281\n",
            "Epoch 435/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5930 - accuracy: 0.8316 - val_loss: 17.9832 - val_accuracy: 0.3285\n",
            "Epoch 436/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5922 - accuracy: 0.8315 - val_loss: 18.0264 - val_accuracy: 0.3287\n",
            "Epoch 437/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5947 - accuracy: 0.8299 - val_loss: 17.9966 - val_accuracy: 0.3291\n",
            "Epoch 438/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.5953 - accuracy: 0.8304 - val_loss: 18.0980 - val_accuracy: 0.3300\n",
            "Epoch 439/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5905 - accuracy: 0.8318 - val_loss: 17.9350 - val_accuracy: 0.3281\n",
            "Epoch 440/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5884 - accuracy: 0.8320 - val_loss: 17.9760 - val_accuracy: 0.3294\n",
            "Epoch 441/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5875 - accuracy: 0.8338 - val_loss: 18.0229 - val_accuracy: 0.3299\n",
            "Epoch 442/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5737 - accuracy: 0.8358 - val_loss: 18.0642 - val_accuracy: 0.3292\n",
            "Epoch 443/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5762 - accuracy: 0.8351 - val_loss: 18.1214 - val_accuracy: 0.3299\n",
            "Epoch 444/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5812 - accuracy: 0.8351 - val_loss: 18.0672 - val_accuracy: 0.3291\n",
            "Epoch 445/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.5770 - accuracy: 0.8363 - val_loss: 18.1468 - val_accuracy: 0.3303\n",
            "Epoch 446/500\n",
            "79/79 [==============================] - 7s 91ms/step - loss: 0.5763 - accuracy: 0.8359 - val_loss: 18.1185 - val_accuracy: 0.3309\n",
            "Epoch 447/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5795 - accuracy: 0.8361 - val_loss: 18.0253 - val_accuracy: 0.3299\n",
            "Epoch 448/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5823 - accuracy: 0.8343 - val_loss: 18.1048 - val_accuracy: 0.3298\n",
            "Epoch 449/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5758 - accuracy: 0.8351 - val_loss: 18.2283 - val_accuracy: 0.3298\n",
            "Epoch 450/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5760 - accuracy: 0.8360 - val_loss: 18.1892 - val_accuracy: 0.3295\n",
            "Epoch 451/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5757 - accuracy: 0.8363 - val_loss: 18.0982 - val_accuracy: 0.3308\n",
            "Epoch 452/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5717 - accuracy: 0.8378 - val_loss: 18.1510 - val_accuracy: 0.3303\n",
            "Epoch 453/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5743 - accuracy: 0.8362 - val_loss: 18.1303 - val_accuracy: 0.3309\n",
            "Epoch 454/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5662 - accuracy: 0.8379 - val_loss: 18.1603 - val_accuracy: 0.3298\n",
            "Epoch 455/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5698 - accuracy: 0.8384 - val_loss: 18.3829 - val_accuracy: 0.3298\n",
            "Epoch 456/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5643 - accuracy: 0.8382 - val_loss: 18.2760 - val_accuracy: 0.3296\n",
            "Epoch 457/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5681 - accuracy: 0.8377 - val_loss: 18.0841 - val_accuracy: 0.3302\n",
            "Epoch 458/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5682 - accuracy: 0.8383 - val_loss: 18.2369 - val_accuracy: 0.3307\n",
            "Epoch 459/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5633 - accuracy: 0.8382 - val_loss: 18.2553 - val_accuracy: 0.3293\n",
            "Epoch 460/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5608 - accuracy: 0.8400 - val_loss: 18.3494 - val_accuracy: 0.3303\n",
            "Epoch 461/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5539 - accuracy: 0.8420 - val_loss: 18.1978 - val_accuracy: 0.3302\n",
            "Epoch 462/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.5588 - accuracy: 0.8398 - val_loss: 18.3340 - val_accuracy: 0.3315\n",
            "Epoch 463/500\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.5562 - accuracy: 0.8420 - val_loss: 18.4487 - val_accuracy: 0.3318\n",
            "Epoch 464/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5545 - accuracy: 0.8423 - val_loss: 18.2344 - val_accuracy: 0.3300\n",
            "Epoch 465/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5525 - accuracy: 0.8408 - val_loss: 18.4379 - val_accuracy: 0.3311\n",
            "Epoch 466/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5534 - accuracy: 0.8421 - val_loss: 18.4014 - val_accuracy: 0.3302\n",
            "Epoch 467/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5553 - accuracy: 0.8403 - val_loss: 18.3927 - val_accuracy: 0.3308\n",
            "Epoch 468/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5553 - accuracy: 0.8410 - val_loss: 18.4092 - val_accuracy: 0.3304\n",
            "Epoch 469/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5517 - accuracy: 0.8415 - val_loss: 18.4481 - val_accuracy: 0.3313\n",
            "Epoch 470/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5478 - accuracy: 0.8438 - val_loss: 18.3359 - val_accuracy: 0.3311\n",
            "Epoch 471/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5428 - accuracy: 0.8437 - val_loss: 18.4383 - val_accuracy: 0.3304\n",
            "Epoch 472/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5453 - accuracy: 0.8438 - val_loss: 18.4017 - val_accuracy: 0.3289\n",
            "Epoch 473/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5429 - accuracy: 0.8441 - val_loss: 18.4056 - val_accuracy: 0.3309\n",
            "Epoch 474/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5384 - accuracy: 0.8458 - val_loss: 18.2658 - val_accuracy: 0.3304\n",
            "Epoch 475/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5410 - accuracy: 0.8453 - val_loss: 18.3253 - val_accuracy: 0.3301\n",
            "Epoch 476/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5436 - accuracy: 0.8439 - val_loss: 18.5807 - val_accuracy: 0.3313\n",
            "Epoch 477/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5385 - accuracy: 0.8458 - val_loss: 18.4880 - val_accuracy: 0.3302\n",
            "Epoch 478/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5398 - accuracy: 0.8447 - val_loss: 18.5161 - val_accuracy: 0.3304\n",
            "Epoch 479/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5363 - accuracy: 0.8466 - val_loss: 18.4857 - val_accuracy: 0.3306\n",
            "Epoch 480/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5354 - accuracy: 0.8470 - val_loss: 18.5136 - val_accuracy: 0.3305\n",
            "Epoch 481/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5335 - accuracy: 0.8471 - val_loss: 18.4375 - val_accuracy: 0.3308\n",
            "Epoch 482/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5374 - accuracy: 0.8466 - val_loss: 18.4482 - val_accuracy: 0.3302\n",
            "Epoch 483/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5316 - accuracy: 0.8478 - val_loss: 18.5701 - val_accuracy: 0.3312\n",
            "Epoch 484/500\n",
            "79/79 [==============================] - 8s 99ms/step - loss: 0.5307 - accuracy: 0.8477 - val_loss: 18.6111 - val_accuracy: 0.3320\n",
            "Epoch 485/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5328 - accuracy: 0.8464 - val_loss: 18.5404 - val_accuracy: 0.3304\n",
            "Epoch 486/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5297 - accuracy: 0.8476 - val_loss: 18.5022 - val_accuracy: 0.3294\n",
            "Epoch 487/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5303 - accuracy: 0.8476 - val_loss: 18.5268 - val_accuracy: 0.3313\n",
            "Epoch 488/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5303 - accuracy: 0.8485 - val_loss: 18.5393 - val_accuracy: 0.3310\n",
            "Epoch 489/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5305 - accuracy: 0.8482 - val_loss: 18.5367 - val_accuracy: 0.3315\n",
            "Epoch 490/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5237 - accuracy: 0.8494 - val_loss: 18.5664 - val_accuracy: 0.3313\n",
            "Epoch 491/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5223 - accuracy: 0.8505 - val_loss: 18.5641 - val_accuracy: 0.3312\n",
            "Epoch 492/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.5271 - accuracy: 0.8488 - val_loss: 18.6689 - val_accuracy: 0.3326\n",
            "Epoch 493/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5233 - accuracy: 0.8508 - val_loss: 18.6422 - val_accuracy: 0.3319\n",
            "Epoch 494/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5197 - accuracy: 0.8506 - val_loss: 18.6260 - val_accuracy: 0.3317\n",
            "Epoch 495/500\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.5256 - accuracy: 0.8490 - val_loss: 18.5870 - val_accuracy: 0.3333\n",
            "Epoch 496/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5187 - accuracy: 0.8520 - val_loss: 18.7482 - val_accuracy: 0.3330\n",
            "Epoch 497/500\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.5155 - accuracy: 0.8513 - val_loss: 18.7784 - val_accuracy: 0.3328\n",
            "Epoch 498/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5177 - accuracy: 0.8509 - val_loss: 18.7243 - val_accuracy: 0.3325\n",
            "Epoch 499/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5175 - accuracy: 0.8506 - val_loss: 18.7145 - val_accuracy: 0.3318\n",
            "Epoch 500/500\n",
            "79/79 [==============================] - 7s 88ms/step - loss: 0.5195 - accuracy: 0.8501 - val_loss: 18.8511 - val_accuracy: 0.3329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_8icpaa_4IP",
        "colab_type": "text"
      },
      "source": [
        "## V4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDo87F7AnUdd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5c143a1a-05d5-4f4d-d9b8-1fa9eff074be"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(    \n",
        "    Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=embedding_matrix.shape[1],\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=True)\n",
        ")\n",
        "\n",
        "model.add(LSTM(64, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(64))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(num_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaybHfIeq1ls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fe35e55-bd14-4f78-aa83-3b1d366aa4b4"
      },
      "source": [
        "# model_filename = f'{DATASET}-custom-4.h5'\n",
        "# model_filepath = os.path.join(MODELS_DIR, model_filename)\n",
        "# print(model_filepath)\n",
        "# # model = load_model(model_filepath)\n",
        "\n",
        "# callbacks = [\n",
        "#     EarlyStopping(monitor='val_accuracy', patience=25),\n",
        "#     ModelCheckpoint(f'{model_filepath}', save_best_only=True, save_weights_only=False, monitor='val_accuracy')\n",
        "# ]\n",
        "\n",
        "# EPOCHS = 500\n",
        "\n",
        "# history = model.fit(\n",
        "#     X_train, \n",
        "#     y_train, \n",
        "#     epochs=EPOCHS, \n",
        "#     batch_size=2048, \n",
        "#     validation_data=(X_test, y_test), \n",
        "#     verbose=1,\n",
        "#     callbacks=callbacks\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/models/BBC-TECH-custom-4.h5\n",
            "Epoch 1/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 7.6853 - accuracy: 0.0408 - val_loss: 7.0727 - val_accuracy: 0.0571\n",
            "Epoch 2/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 7.0305 - accuracy: 0.0578 - val_loss: 7.1292 - val_accuracy: 0.0571\n",
            "Epoch 3/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 7.0051 - accuracy: 0.0578 - val_loss: 7.1321 - val_accuracy: 0.0571\n",
            "Epoch 4/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 6.9359 - accuracy: 0.0578 - val_loss: 7.0189 - val_accuracy: 0.0571\n",
            "Epoch 5/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 6.8722 - accuracy: 0.0589 - val_loss: 7.0050 - val_accuracy: 0.0663\n",
            "Epoch 6/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 6.8118 - accuracy: 0.0633 - val_loss: 6.9531 - val_accuracy: 0.0651\n",
            "Epoch 7/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 6.7580 - accuracy: 0.0659 - val_loss: 6.9265 - val_accuracy: 0.0659\n",
            "Epoch 8/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 6.7095 - accuracy: 0.0681 - val_loss: 6.9094 - val_accuracy: 0.0704\n",
            "Epoch 9/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 6.6570 - accuracy: 0.0703 - val_loss: 6.8776 - val_accuracy: 0.0681\n",
            "Epoch 10/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 6.6014 - accuracy: 0.0740 - val_loss: 6.8146 - val_accuracy: 0.0780\n",
            "Epoch 11/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 6.5431 - accuracy: 0.0788 - val_loss: 6.7913 - val_accuracy: 0.0832\n",
            "Epoch 12/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 6.4867 - accuracy: 0.0830 - val_loss: 6.7683 - val_accuracy: 0.0860\n",
            "Epoch 13/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 6.4372 - accuracy: 0.0873 - val_loss: 6.7442 - val_accuracy: 0.0891\n",
            "Epoch 14/500\n",
            "79/79 [==============================] - 10s 129ms/step - loss: 6.3911 - accuracy: 0.0908 - val_loss: 6.7314 - val_accuracy: 0.0919\n",
            "Epoch 15/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 6.3484 - accuracy: 0.0944 - val_loss: 6.7134 - val_accuracy: 0.0931\n",
            "Epoch 16/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 6.3079 - accuracy: 0.0969 - val_loss: 6.7023 - val_accuracy: 0.0940\n",
            "Epoch 17/500\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 6.2692 - accuracy: 0.0994 - val_loss: 6.6865 - val_accuracy: 0.0959\n",
            "Epoch 18/500\n",
            "79/79 [==============================] - 10s 129ms/step - loss: 6.2306 - accuracy: 0.1011 - val_loss: 6.6689 - val_accuracy: 0.0966\n",
            "Epoch 19/500\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 6.1888 - accuracy: 0.1026 - val_loss: 6.6587 - val_accuracy: 0.0978\n",
            "Epoch 20/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 6.1455 - accuracy: 0.1041 - val_loss: 6.6329 - val_accuracy: 0.1021\n",
            "Epoch 21/500\n",
            "79/79 [==============================] - 11s 133ms/step - loss: 6.0993 - accuracy: 0.1071 - val_loss: 6.6144 - val_accuracy: 0.1036\n",
            "Epoch 22/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 6.0496 - accuracy: 0.1102 - val_loss: 6.5868 - val_accuracy: 0.1069\n",
            "Epoch 23/500\n",
            "79/79 [==============================] - 10s 130ms/step - loss: 5.9978 - accuracy: 0.1129 - val_loss: 6.5687 - val_accuracy: 0.1084\n",
            "Epoch 24/500\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 5.9469 - accuracy: 0.1156 - val_loss: 6.5462 - val_accuracy: 0.1097\n",
            "Epoch 25/500\n",
            "79/79 [==============================] - 10s 129ms/step - loss: 5.8982 - accuracy: 0.1172 - val_loss: 6.5381 - val_accuracy: 0.1111\n",
            "Epoch 26/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 5.8516 - accuracy: 0.1202 - val_loss: 6.5185 - val_accuracy: 0.1124\n",
            "Epoch 27/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 5.8069 - accuracy: 0.1218 - val_loss: 6.5127 - val_accuracy: 0.1141\n",
            "Epoch 28/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 5.7661 - accuracy: 0.1236 - val_loss: 6.5069 - val_accuracy: 0.1151\n",
            "Epoch 29/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 5.7262 - accuracy: 0.1255 - val_loss: 6.5086 - val_accuracy: 0.1158\n",
            "Epoch 30/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 5.6876 - accuracy: 0.1276 - val_loss: 6.5048 - val_accuracy: 0.1172\n",
            "Epoch 31/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 5.6467 - accuracy: 0.1288 - val_loss: 6.5090 - val_accuracy: 0.1176\n",
            "Epoch 32/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 5.6114 - accuracy: 0.1309 - val_loss: 6.5043 - val_accuracy: 0.1180\n",
            "Epoch 33/500\n",
            "79/79 [==============================] - 11s 138ms/step - loss: 5.5816 - accuracy: 0.1315 - val_loss: 6.5084 - val_accuracy: 0.1195\n",
            "Epoch 34/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 5.5456 - accuracy: 0.1335 - val_loss: 6.5126 - val_accuracy: 0.1188\n",
            "Epoch 35/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 5.5154 - accuracy: 0.1343 - val_loss: 6.5103 - val_accuracy: 0.1215\n",
            "Epoch 36/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 5.4836 - accuracy: 0.1355 - val_loss: 6.5294 - val_accuracy: 0.1197\n",
            "Epoch 37/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 5.4577 - accuracy: 0.1367 - val_loss: 6.5221 - val_accuracy: 0.1208\n",
            "Epoch 38/500\n",
            "79/79 [==============================] - 11s 136ms/step - loss: 5.4271 - accuracy: 0.1386 - val_loss: 6.5299 - val_accuracy: 0.1217\n",
            "Epoch 39/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 5.3966 - accuracy: 0.1396 - val_loss: 6.5407 - val_accuracy: 0.1231\n",
            "Epoch 40/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 5.3701 - accuracy: 0.1399 - val_loss: 6.5475 - val_accuracy: 0.1233\n",
            "Epoch 41/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 5.3444 - accuracy: 0.1412 - val_loss: 6.5448 - val_accuracy: 0.1237\n",
            "Epoch 42/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 5.3172 - accuracy: 0.1422 - val_loss: 6.5472 - val_accuracy: 0.1237\n",
            "Epoch 43/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 5.2917 - accuracy: 0.1440 - val_loss: 6.5645 - val_accuracy: 0.1247\n",
            "Epoch 44/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 5.2690 - accuracy: 0.1450 - val_loss: 6.5583 - val_accuracy: 0.1260\n",
            "Epoch 45/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 5.2400 - accuracy: 0.1453 - val_loss: 6.5728 - val_accuracy: 0.1257\n",
            "Epoch 46/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 5.2112 - accuracy: 0.1468 - val_loss: 6.5790 - val_accuracy: 0.1270\n",
            "Epoch 47/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 5.1915 - accuracy: 0.1474 - val_loss: 6.5749 - val_accuracy: 0.1275\n",
            "Epoch 48/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 5.1687 - accuracy: 0.1494 - val_loss: 6.5743 - val_accuracy: 0.1265\n",
            "Epoch 49/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 5.1432 - accuracy: 0.1505 - val_loss: 6.5879 - val_accuracy: 0.1289\n",
            "Epoch 50/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 5.1250 - accuracy: 0.1506 - val_loss: 6.5956 - val_accuracy: 0.1279\n",
            "Epoch 51/500\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 5.0973 - accuracy: 0.1530 - val_loss: 6.6046 - val_accuracy: 0.1290\n",
            "Epoch 52/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 5.0791 - accuracy: 0.1534 - val_loss: 6.6042 - val_accuracy: 0.1298\n",
            "Epoch 53/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 5.0570 - accuracy: 0.1535 - val_loss: 6.6295 - val_accuracy: 0.1289\n",
            "Epoch 54/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 5.0383 - accuracy: 0.1546 - val_loss: 6.6275 - val_accuracy: 0.1305\n",
            "Epoch 55/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 5.0145 - accuracy: 0.1562 - val_loss: 6.6444 - val_accuracy: 0.1323\n",
            "Epoch 56/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 4.9991 - accuracy: 0.1568 - val_loss: 6.6521 - val_accuracy: 0.1314\n",
            "Epoch 57/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 4.9750 - accuracy: 0.1576 - val_loss: 6.6450 - val_accuracy: 0.1334\n",
            "Epoch 58/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.9553 - accuracy: 0.1581 - val_loss: 6.6621 - val_accuracy: 0.1326\n",
            "Epoch 59/500\n",
            "79/79 [==============================] - 10s 123ms/step - loss: 4.9364 - accuracy: 0.1605 - val_loss: 6.6607 - val_accuracy: 0.1337\n",
            "Epoch 60/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.9179 - accuracy: 0.1601 - val_loss: 6.6724 - val_accuracy: 0.1347\n",
            "Epoch 61/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 4.8943 - accuracy: 0.1617 - val_loss: 6.6734 - val_accuracy: 0.1343\n",
            "Epoch 62/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 4.8780 - accuracy: 0.1623 - val_loss: 6.6921 - val_accuracy: 0.1352\n",
            "Epoch 63/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.8591 - accuracy: 0.1641 - val_loss: 6.6966 - val_accuracy: 0.1363\n",
            "Epoch 64/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 4.8398 - accuracy: 0.1651 - val_loss: 6.7061 - val_accuracy: 0.1376\n",
            "Epoch 65/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 4.8262 - accuracy: 0.1654 - val_loss: 6.7259 - val_accuracy: 0.1371\n",
            "Epoch 66/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 4.8070 - accuracy: 0.1658 - val_loss: 6.7044 - val_accuracy: 0.1367\n",
            "Epoch 67/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 4.7880 - accuracy: 0.1681 - val_loss: 6.7367 - val_accuracy: 0.1370\n",
            "Epoch 68/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 4.7711 - accuracy: 0.1687 - val_loss: 6.7305 - val_accuracy: 0.1384\n",
            "Epoch 69/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.7546 - accuracy: 0.1695 - val_loss: 6.7309 - val_accuracy: 0.1379\n",
            "Epoch 70/500\n",
            "79/79 [==============================] - 10s 129ms/step - loss: 4.7424 - accuracy: 0.1704 - val_loss: 6.7580 - val_accuracy: 0.1388\n",
            "Epoch 71/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.7288 - accuracy: 0.1707 - val_loss: 6.7596 - val_accuracy: 0.1391\n",
            "Epoch 72/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.7085 - accuracy: 0.1712 - val_loss: 6.7667 - val_accuracy: 0.1387\n",
            "Epoch 73/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 4.6945 - accuracy: 0.1723 - val_loss: 6.7764 - val_accuracy: 0.1410\n",
            "Epoch 74/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 4.6808 - accuracy: 0.1735 - val_loss: 6.7705 - val_accuracy: 0.1409\n",
            "Epoch 75/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 4.6716 - accuracy: 0.1736 - val_loss: 6.7787 - val_accuracy: 0.1405\n",
            "Epoch 76/500\n",
            "79/79 [==============================] - 10s 123ms/step - loss: 4.6504 - accuracy: 0.1756 - val_loss: 6.7767 - val_accuracy: 0.1415\n",
            "Epoch 77/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 4.6376 - accuracy: 0.1753 - val_loss: 6.8025 - val_accuracy: 0.1404\n",
            "Epoch 78/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 4.6220 - accuracy: 0.1773 - val_loss: 6.8179 - val_accuracy: 0.1435\n",
            "Epoch 79/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 4.6090 - accuracy: 0.1779 - val_loss: 6.8238 - val_accuracy: 0.1439\n",
            "Epoch 80/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 4.5985 - accuracy: 0.1790 - val_loss: 6.8365 - val_accuracy: 0.1442\n",
            "Epoch 81/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 4.5855 - accuracy: 0.1793 - val_loss: 6.8474 - val_accuracy: 0.1445\n",
            "Epoch 82/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.5730 - accuracy: 0.1802 - val_loss: 6.8615 - val_accuracy: 0.1445\n",
            "Epoch 83/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 4.5617 - accuracy: 0.1811 - val_loss: 6.8520 - val_accuracy: 0.1450\n",
            "Epoch 84/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 4.5474 - accuracy: 0.1818 - val_loss: 6.8536 - val_accuracy: 0.1447\n",
            "Epoch 85/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 4.5347 - accuracy: 0.1840 - val_loss: 6.8621 - val_accuracy: 0.1465\n",
            "Epoch 86/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 4.5213 - accuracy: 0.1845 - val_loss: 6.8870 - val_accuracy: 0.1454\n",
            "Epoch 87/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 4.5085 - accuracy: 0.1844 - val_loss: 6.8878 - val_accuracy: 0.1479\n",
            "Epoch 88/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 4.5022 - accuracy: 0.1853 - val_loss: 6.8954 - val_accuracy: 0.1477\n",
            "Epoch 89/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 4.4886 - accuracy: 0.1852 - val_loss: 6.8834 - val_accuracy: 0.1482\n",
            "Epoch 90/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.4717 - accuracy: 0.1872 - val_loss: 6.8954 - val_accuracy: 0.1461\n",
            "Epoch 91/500\n",
            "79/79 [==============================] - 11s 137ms/step - loss: 4.4647 - accuracy: 0.1879 - val_loss: 6.9022 - val_accuracy: 0.1486\n",
            "Epoch 92/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 4.4460 - accuracy: 0.1885 - val_loss: 6.8968 - val_accuracy: 0.1494\n",
            "Epoch 93/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.4419 - accuracy: 0.1882 - val_loss: 6.9314 - val_accuracy: 0.1490\n",
            "Epoch 94/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 4.4293 - accuracy: 0.1903 - val_loss: 6.9283 - val_accuracy: 0.1496\n",
            "Epoch 95/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 4.4184 - accuracy: 0.1914 - val_loss: 6.9531 - val_accuracy: 0.1493\n",
            "Epoch 96/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 4.4122 - accuracy: 0.1909 - val_loss: 6.9467 - val_accuracy: 0.1499\n",
            "Epoch 97/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 4.4004 - accuracy: 0.1928 - val_loss: 6.9473 - val_accuracy: 0.1500\n",
            "Epoch 98/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 4.3912 - accuracy: 0.1939 - val_loss: 6.9447 - val_accuracy: 0.1505\n",
            "Epoch 99/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 4.3855 - accuracy: 0.1930 - val_loss: 6.9557 - val_accuracy: 0.1512\n",
            "Epoch 100/500\n",
            "79/79 [==============================] - 11s 138ms/step - loss: 4.3718 - accuracy: 0.1938 - val_loss: 6.9504 - val_accuracy: 0.1515\n",
            "Epoch 101/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 4.3588 - accuracy: 0.1954 - val_loss: 6.9821 - val_accuracy: 0.1513\n",
            "Epoch 102/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 4.3508 - accuracy: 0.1953 - val_loss: 6.9987 - val_accuracy: 0.1524\n",
            "Epoch 103/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 4.3369 - accuracy: 0.1982 - val_loss: 6.9843 - val_accuracy: 0.1513\n",
            "Epoch 104/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 4.3302 - accuracy: 0.1975 - val_loss: 6.9898 - val_accuracy: 0.1537\n",
            "Epoch 105/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 4.3214 - accuracy: 0.1981 - val_loss: 7.0238 - val_accuracy: 0.1544\n",
            "Epoch 106/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 4.3144 - accuracy: 0.1972 - val_loss: 7.0230 - val_accuracy: 0.1538\n",
            "Epoch 107/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 4.3086 - accuracy: 0.1993 - val_loss: 7.0105 - val_accuracy: 0.1544\n",
            "Epoch 108/500\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 4.2927 - accuracy: 0.2008 - val_loss: 7.0188 - val_accuracy: 0.1549\n",
            "Epoch 109/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 4.2840 - accuracy: 0.2013 - val_loss: 7.0271 - val_accuracy: 0.1558\n",
            "Epoch 110/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 4.2807 - accuracy: 0.2021 - val_loss: 7.0205 - val_accuracy: 0.1553\n",
            "Epoch 111/500\n",
            "79/79 [==============================] - 10s 129ms/step - loss: 4.2692 - accuracy: 0.2021 - val_loss: 7.0491 - val_accuracy: 0.1564\n",
            "Epoch 112/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 4.2626 - accuracy: 0.2033 - val_loss: 7.0304 - val_accuracy: 0.1557\n",
            "Epoch 113/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 4.2501 - accuracy: 0.2045 - val_loss: 7.0711 - val_accuracy: 0.1558\n",
            "Epoch 114/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.2454 - accuracy: 0.2049 - val_loss: 7.0696 - val_accuracy: 0.1542\n",
            "Epoch 115/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 4.2365 - accuracy: 0.2056 - val_loss: 7.0640 - val_accuracy: 0.1563\n",
            "Epoch 116/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 4.2282 - accuracy: 0.2062 - val_loss: 7.0843 - val_accuracy: 0.1557\n",
            "Epoch 117/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 4.2193 - accuracy: 0.2066 - val_loss: 7.0937 - val_accuracy: 0.1581\n",
            "Epoch 118/500\n",
            "79/79 [==============================] - 9s 120ms/step - loss: 4.2081 - accuracy: 0.2086 - val_loss: 7.0937 - val_accuracy: 0.1584\n",
            "Epoch 119/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.2041 - accuracy: 0.2077 - val_loss: 7.0985 - val_accuracy: 0.1584\n",
            "Epoch 120/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 4.1932 - accuracy: 0.2092 - val_loss: 7.1116 - val_accuracy: 0.1582\n",
            "Epoch 121/500\n",
            "79/79 [==============================] - 11s 136ms/step - loss: 4.1858 - accuracy: 0.2102 - val_loss: 7.0999 - val_accuracy: 0.1603\n",
            "Epoch 122/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 4.1794 - accuracy: 0.2104 - val_loss: 7.1175 - val_accuracy: 0.1573\n",
            "Epoch 123/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 4.1659 - accuracy: 0.2115 - val_loss: 7.1304 - val_accuracy: 0.1595\n",
            "Epoch 124/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 4.1620 - accuracy: 0.2115 - val_loss: 7.1578 - val_accuracy: 0.1591\n",
            "Epoch 125/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 4.1558 - accuracy: 0.2135 - val_loss: 7.1430 - val_accuracy: 0.1604\n",
            "Epoch 126/500\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 4.1445 - accuracy: 0.2135 - val_loss: 7.1516 - val_accuracy: 0.1608\n",
            "Epoch 127/500\n",
            "79/79 [==============================] - 10s 132ms/step - loss: 4.1391 - accuracy: 0.2139 - val_loss: 7.1520 - val_accuracy: 0.1614\n",
            "Epoch 128/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 4.1317 - accuracy: 0.2138 - val_loss: 7.1766 - val_accuracy: 0.1599\n",
            "Epoch 129/500\n",
            "79/79 [==============================] - 9s 120ms/step - loss: 4.1273 - accuracy: 0.2150 - val_loss: 7.1997 - val_accuracy: 0.1596\n",
            "Epoch 130/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 4.1177 - accuracy: 0.2160 - val_loss: 7.1827 - val_accuracy: 0.1605\n",
            "Epoch 131/500\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 4.1074 - accuracy: 0.2170 - val_loss: 7.1950 - val_accuracy: 0.1611\n",
            "Epoch 132/500\n",
            "79/79 [==============================] - 10s 130ms/step - loss: 4.1029 - accuracy: 0.2169 - val_loss: 7.2126 - val_accuracy: 0.1638\n",
            "Epoch 133/500\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 4.0958 - accuracy: 0.2173 - val_loss: 7.2270 - val_accuracy: 0.1619\n",
            "Epoch 134/500\n",
            "79/79 [==============================] - 10s 120ms/step - loss: 4.0912 - accuracy: 0.2184 - val_loss: 7.2077 - val_accuracy: 0.1629\n",
            "Epoch 135/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 4.0844 - accuracy: 0.2189 - val_loss: 7.2235 - val_accuracy: 0.1634\n",
            "Epoch 136/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 4.0715 - accuracy: 0.2195 - val_loss: 7.2307 - val_accuracy: 0.1636\n",
            "Epoch 137/500\n",
            "79/79 [==============================] - 10s 121ms/step - loss: 4.0696 - accuracy: 0.2210 - val_loss: 7.2500 - val_accuracy: 0.1630\n",
            "Epoch 138/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 4.0617 - accuracy: 0.2216 - val_loss: 7.2266 - val_accuracy: 0.1644\n",
            "Epoch 139/500\n",
            "79/79 [==============================] - 9s 120ms/step - loss: 4.0528 - accuracy: 0.2228 - val_loss: 7.2580 - val_accuracy: 0.1645\n",
            "Epoch 140/500\n",
            "79/79 [==============================] - 10s 121ms/step - loss: 4.0487 - accuracy: 0.2223 - val_loss: 7.2776 - val_accuracy: 0.1623\n",
            "Epoch 141/500\n",
            "79/79 [==============================] - 11s 134ms/step - loss: 4.0455 - accuracy: 0.2227 - val_loss: 7.2655 - val_accuracy: 0.1650\n",
            "Epoch 142/500\n",
            "79/79 [==============================] - 10s 120ms/step - loss: 4.0323 - accuracy: 0.2243 - val_loss: 7.2841 - val_accuracy: 0.1656\n",
            "Epoch 143/500\n",
            "79/79 [==============================] - 10s 133ms/step - loss: 4.0248 - accuracy: 0.2251 - val_loss: 7.2665 - val_accuracy: 0.1658\n",
            "Epoch 144/500\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 4.0186 - accuracy: 0.2256 - val_loss: 7.2708 - val_accuracy: 0.1658\n",
            "Epoch 145/500\n",
            "79/79 [==============================] - 10s 132ms/step - loss: 4.0139 - accuracy: 0.2268 - val_loss: 7.2672 - val_accuracy: 0.1659\n",
            "Epoch 146/500\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 4.0041 - accuracy: 0.2269 - val_loss: 7.3051 - val_accuracy: 0.1658\n",
            "Epoch 147/500\n",
            "79/79 [==============================] - 10s 132ms/step - loss: 4.0007 - accuracy: 0.2266 - val_loss: 7.3386 - val_accuracy: 0.1665\n",
            "Epoch 148/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.9952 - accuracy: 0.2279 - val_loss: 7.3247 - val_accuracy: 0.1663\n",
            "Epoch 149/500\n",
            "79/79 [==============================] - 10s 132ms/step - loss: 3.9903 - accuracy: 0.2278 - val_loss: 7.3308 - val_accuracy: 0.1678\n",
            "Epoch 150/500\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 3.9849 - accuracy: 0.2289 - val_loss: 7.3415 - val_accuracy: 0.1674\n",
            "Epoch 151/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.9783 - accuracy: 0.2288 - val_loss: 7.3188 - val_accuracy: 0.1668\n",
            "Epoch 152/500\n",
            "79/79 [==============================] - 10s 129ms/step - loss: 3.9749 - accuracy: 0.2289 - val_loss: 7.3436 - val_accuracy: 0.1683\n",
            "Epoch 153/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.9710 - accuracy: 0.2298 - val_loss: 7.3266 - val_accuracy: 0.1677\n",
            "Epoch 154/500\n",
            "79/79 [==============================] - 10s 123ms/step - loss: 3.9550 - accuracy: 0.2313 - val_loss: 7.3658 - val_accuracy: 0.1689\n",
            "Epoch 155/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 3.9515 - accuracy: 0.2323 - val_loss: 7.3538 - val_accuracy: 0.1690\n",
            "Epoch 156/500\n",
            "79/79 [==============================] - 10s 121ms/step - loss: 3.9459 - accuracy: 0.2318 - val_loss: 7.3553 - val_accuracy: 0.1691\n",
            "Epoch 157/500\n",
            "79/79 [==============================] - 10s 121ms/step - loss: 3.9423 - accuracy: 0.2327 - val_loss: 7.3640 - val_accuracy: 0.1689\n",
            "Epoch 158/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.9357 - accuracy: 0.2341 - val_loss: 7.3872 - val_accuracy: 0.1680\n",
            "Epoch 159/500\n",
            "79/79 [==============================] - 10s 131ms/step - loss: 3.9316 - accuracy: 0.2342 - val_loss: 7.3660 - val_accuracy: 0.1695\n",
            "Epoch 160/500\n",
            "79/79 [==============================] - 10s 122ms/step - loss: 3.9252 - accuracy: 0.2340 - val_loss: 7.4040 - val_accuracy: 0.1709\n",
            "Epoch 161/500\n",
            "79/79 [==============================] - 9s 120ms/step - loss: 3.9181 - accuracy: 0.2355 - val_loss: 7.4078 - val_accuracy: 0.1709\n",
            "Epoch 162/500\n",
            "79/79 [==============================] - 9s 119ms/step - loss: 3.9163 - accuracy: 0.2354 - val_loss: 7.3908 - val_accuracy: 0.1713\n",
            "Epoch 163/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.9051 - accuracy: 0.2362 - val_loss: 7.4247 - val_accuracy: 0.1698\n",
            "Epoch 164/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.9040 - accuracy: 0.2370 - val_loss: 7.4292 - val_accuracy: 0.1700\n",
            "Epoch 165/500\n",
            "79/79 [==============================] - 10s 130ms/step - loss: 3.8924 - accuracy: 0.2379 - val_loss: 7.4176 - val_accuracy: 0.1730\n",
            "Epoch 166/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.8834 - accuracy: 0.2382 - val_loss: 7.4571 - val_accuracy: 0.1716\n",
            "Epoch 167/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.8790 - accuracy: 0.2393 - val_loss: 7.4485 - val_accuracy: 0.1712\n",
            "Epoch 168/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.8804 - accuracy: 0.2383 - val_loss: 7.4284 - val_accuracy: 0.1718\n",
            "Epoch 169/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.8729 - accuracy: 0.2396 - val_loss: 7.4588 - val_accuracy: 0.1717\n",
            "Epoch 170/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.8724 - accuracy: 0.2415 - val_loss: 7.4784 - val_accuracy: 0.1729\n",
            "Epoch 171/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.8591 - accuracy: 0.2420 - val_loss: 7.4582 - val_accuracy: 0.1737\n",
            "Epoch 172/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.8589 - accuracy: 0.2408 - val_loss: 7.4806 - val_accuracy: 0.1729\n",
            "Epoch 173/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.8515 - accuracy: 0.2430 - val_loss: 7.4691 - val_accuracy: 0.1721\n",
            "Epoch 174/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.8447 - accuracy: 0.2426 - val_loss: 7.5082 - val_accuracy: 0.1743\n",
            "Epoch 175/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.8470 - accuracy: 0.2418 - val_loss: 7.4855 - val_accuracy: 0.1745\n",
            "Epoch 176/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.8373 - accuracy: 0.2435 - val_loss: 7.4900 - val_accuracy: 0.1739\n",
            "Epoch 177/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.8305 - accuracy: 0.2441 - val_loss: 7.5182 - val_accuracy: 0.1743\n",
            "Epoch 178/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.8280 - accuracy: 0.2453 - val_loss: 7.4994 - val_accuracy: 0.1743\n",
            "Epoch 179/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.8212 - accuracy: 0.2471 - val_loss: 7.4943 - val_accuracy: 0.1753\n",
            "Epoch 180/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.8195 - accuracy: 0.2453 - val_loss: 7.5173 - val_accuracy: 0.1749\n",
            "Epoch 181/500\n",
            "79/79 [==============================] - 11s 134ms/step - loss: 3.8099 - accuracy: 0.2475 - val_loss: 7.5261 - val_accuracy: 0.1759\n",
            "Epoch 182/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.8015 - accuracy: 0.2478 - val_loss: 7.5408 - val_accuracy: 0.1743\n",
            "Epoch 183/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 3.8026 - accuracy: 0.2477 - val_loss: 7.5231 - val_accuracy: 0.1760\n",
            "Epoch 184/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.7960 - accuracy: 0.2483 - val_loss: 7.5557 - val_accuracy: 0.1761\n",
            "Epoch 185/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.7904 - accuracy: 0.2495 - val_loss: 7.5350 - val_accuracy: 0.1758\n",
            "Epoch 186/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.7869 - accuracy: 0.2493 - val_loss: 7.5545 - val_accuracy: 0.1754\n",
            "Epoch 187/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.7862 - accuracy: 0.2489 - val_loss: 7.5645 - val_accuracy: 0.1770\n",
            "Epoch 188/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.7763 - accuracy: 0.2502 - val_loss: 7.5824 - val_accuracy: 0.1761\n",
            "Epoch 189/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.7719 - accuracy: 0.2504 - val_loss: 7.5582 - val_accuracy: 0.1776\n",
            "Epoch 190/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.7674 - accuracy: 0.2509 - val_loss: 7.5805 - val_accuracy: 0.1774\n",
            "Epoch 191/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.7598 - accuracy: 0.2527 - val_loss: 7.5841 - val_accuracy: 0.1775\n",
            "Epoch 192/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.7590 - accuracy: 0.2536 - val_loss: 7.5965 - val_accuracy: 0.1769\n",
            "Epoch 193/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.7481 - accuracy: 0.2551 - val_loss: 7.6034 - val_accuracy: 0.1764\n",
            "Epoch 194/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.7488 - accuracy: 0.2529 - val_loss: 7.6035 - val_accuracy: 0.1769\n",
            "Epoch 195/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.7402 - accuracy: 0.2544 - val_loss: 7.6455 - val_accuracy: 0.1788\n",
            "Epoch 196/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.7332 - accuracy: 0.2556 - val_loss: 7.6268 - val_accuracy: 0.1774\n",
            "Epoch 197/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.7261 - accuracy: 0.2549 - val_loss: 7.6737 - val_accuracy: 0.1788\n",
            "Epoch 198/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.7288 - accuracy: 0.2569 - val_loss: 7.6254 - val_accuracy: 0.1790\n",
            "Epoch 199/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 3.7264 - accuracy: 0.2561 - val_loss: 7.6092 - val_accuracy: 0.1791\n",
            "Epoch 200/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.7197 - accuracy: 0.2586 - val_loss: 7.6259 - val_accuracy: 0.1795\n",
            "Epoch 201/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.7072 - accuracy: 0.2568 - val_loss: 7.6735 - val_accuracy: 0.1818\n",
            "Epoch 202/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.7108 - accuracy: 0.2586 - val_loss: 7.6488 - val_accuracy: 0.1799\n",
            "Epoch 203/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.7068 - accuracy: 0.2590 - val_loss: 7.6423 - val_accuracy: 0.1787\n",
            "Epoch 204/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.7021 - accuracy: 0.2582 - val_loss: 7.6718 - val_accuracy: 0.1811\n",
            "Epoch 205/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.6942 - accuracy: 0.2600 - val_loss: 7.6394 - val_accuracy: 0.1811\n",
            "Epoch 206/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.6864 - accuracy: 0.2606 - val_loss: 7.6917 - val_accuracy: 0.1803\n",
            "Epoch 207/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.6890 - accuracy: 0.2604 - val_loss: 7.6967 - val_accuracy: 0.1805\n",
            "Epoch 208/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.6852 - accuracy: 0.2603 - val_loss: 7.6971 - val_accuracy: 0.1811\n",
            "Epoch 209/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.6782 - accuracy: 0.2626 - val_loss: 7.7069 - val_accuracy: 0.1831\n",
            "Epoch 210/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.6758 - accuracy: 0.2616 - val_loss: 7.7019 - val_accuracy: 0.1819\n",
            "Epoch 211/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.6709 - accuracy: 0.2626 - val_loss: 7.7480 - val_accuracy: 0.1827\n",
            "Epoch 212/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.6679 - accuracy: 0.2637 - val_loss: 7.7038 - val_accuracy: 0.1820\n",
            "Epoch 213/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.6620 - accuracy: 0.2632 - val_loss: 7.7115 - val_accuracy: 0.1833\n",
            "Epoch 214/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.6571 - accuracy: 0.2639 - val_loss: 7.7293 - val_accuracy: 0.1838\n",
            "Epoch 215/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.6564 - accuracy: 0.2637 - val_loss: 7.7129 - val_accuracy: 0.1834\n",
            "Epoch 216/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.6515 - accuracy: 0.2655 - val_loss: 7.7165 - val_accuracy: 0.1836\n",
            "Epoch 217/500\n",
            "79/79 [==============================] - 10s 129ms/step - loss: 3.6504 - accuracy: 0.2651 - val_loss: 7.7607 - val_accuracy: 0.1847\n",
            "Epoch 218/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.6399 - accuracy: 0.2664 - val_loss: 7.7430 - val_accuracy: 0.1840\n",
            "Epoch 219/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.6330 - accuracy: 0.2677 - val_loss: 7.7789 - val_accuracy: 0.1839\n",
            "Epoch 220/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.6353 - accuracy: 0.2669 - val_loss: 7.7683 - val_accuracy: 0.1860\n",
            "Epoch 221/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.6359 - accuracy: 0.2662 - val_loss: 7.7374 - val_accuracy: 0.1843\n",
            "Epoch 222/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.6253 - accuracy: 0.2675 - val_loss: 7.7663 - val_accuracy: 0.1838\n",
            "Epoch 223/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.6232 - accuracy: 0.2693 - val_loss: 7.7826 - val_accuracy: 0.1851\n",
            "Epoch 224/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.6212 - accuracy: 0.2678 - val_loss: 7.7627 - val_accuracy: 0.1850\n",
            "Epoch 225/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.6181 - accuracy: 0.2690 - val_loss: 7.8020 - val_accuracy: 0.1852\n",
            "Epoch 226/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.6070 - accuracy: 0.2709 - val_loss: 7.7892 - val_accuracy: 0.1857\n",
            "Epoch 227/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.6047 - accuracy: 0.2703 - val_loss: 7.8029 - val_accuracy: 0.1853\n",
            "Epoch 228/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.6048 - accuracy: 0.2708 - val_loss: 7.7948 - val_accuracy: 0.1858\n",
            "Epoch 229/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.5979 - accuracy: 0.2702 - val_loss: 7.8211 - val_accuracy: 0.1856\n",
            "Epoch 230/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.5899 - accuracy: 0.2722 - val_loss: 7.8082 - val_accuracy: 0.1859\n",
            "Epoch 231/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.5931 - accuracy: 0.2723 - val_loss: 7.8274 - val_accuracy: 0.1875\n",
            "Epoch 232/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.5851 - accuracy: 0.2737 - val_loss: 7.8473 - val_accuracy: 0.1864\n",
            "Epoch 233/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.5841 - accuracy: 0.2725 - val_loss: 7.8455 - val_accuracy: 0.1883\n",
            "Epoch 234/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.5733 - accuracy: 0.2750 - val_loss: 7.8484 - val_accuracy: 0.1876\n",
            "Epoch 235/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.5738 - accuracy: 0.2748 - val_loss: 7.8376 - val_accuracy: 0.1883\n",
            "Epoch 236/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.5684 - accuracy: 0.2742 - val_loss: 7.8570 - val_accuracy: 0.1853\n",
            "Epoch 237/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.5689 - accuracy: 0.2748 - val_loss: 7.8950 - val_accuracy: 0.1862\n",
            "Epoch 238/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.5634 - accuracy: 0.2759 - val_loss: 7.8855 - val_accuracy: 0.1860\n",
            "Epoch 239/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.5516 - accuracy: 0.2764 - val_loss: 7.8977 - val_accuracy: 0.1872\n",
            "Epoch 240/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.5561 - accuracy: 0.2771 - val_loss: 7.8698 - val_accuracy: 0.1870\n",
            "Epoch 241/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.5528 - accuracy: 0.2767 - val_loss: 7.8701 - val_accuracy: 0.1864\n",
            "Epoch 242/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.5492 - accuracy: 0.2775 - val_loss: 7.8958 - val_accuracy: 0.1889\n",
            "Epoch 243/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.5500 - accuracy: 0.2772 - val_loss: 7.8852 - val_accuracy: 0.1878\n",
            "Epoch 244/500\n",
            "79/79 [==============================] - 10s 132ms/step - loss: 3.5405 - accuracy: 0.2790 - val_loss: 7.8914 - val_accuracy: 0.1892\n",
            "Epoch 245/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.5396 - accuracy: 0.2782 - val_loss: 7.8628 - val_accuracy: 0.1892\n",
            "Epoch 246/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.5335 - accuracy: 0.2792 - val_loss: 7.8866 - val_accuracy: 0.1878\n",
            "Epoch 247/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.5229 - accuracy: 0.2812 - val_loss: 7.8846 - val_accuracy: 0.1904\n",
            "Epoch 248/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.5249 - accuracy: 0.2802 - val_loss: 7.8900 - val_accuracy: 0.1878\n",
            "Epoch 249/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.5228 - accuracy: 0.2801 - val_loss: 7.9215 - val_accuracy: 0.1891\n",
            "Epoch 250/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.5276 - accuracy: 0.2808 - val_loss: 7.9186 - val_accuracy: 0.1895\n",
            "Epoch 251/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 3.5166 - accuracy: 0.2816 - val_loss: 7.9249 - val_accuracy: 0.1906\n",
            "Epoch 252/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.5136 - accuracy: 0.2811 - val_loss: 7.9580 - val_accuracy: 0.1896\n",
            "Epoch 253/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.5131 - accuracy: 0.2821 - val_loss: 7.9233 - val_accuracy: 0.1911\n",
            "Epoch 254/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.5069 - accuracy: 0.2823 - val_loss: 7.9274 - val_accuracy: 0.1901\n",
            "Epoch 255/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.5097 - accuracy: 0.2834 - val_loss: 7.9452 - val_accuracy: 0.1915\n",
            "Epoch 256/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.5027 - accuracy: 0.2843 - val_loss: 7.9614 - val_accuracy: 0.1925\n",
            "Epoch 257/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.4954 - accuracy: 0.2837 - val_loss: 7.9423 - val_accuracy: 0.1919\n",
            "Epoch 258/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.4938 - accuracy: 0.2852 - val_loss: 7.9408 - val_accuracy: 0.1925\n",
            "Epoch 259/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.4867 - accuracy: 0.2859 - val_loss: 7.9501 - val_accuracy: 0.1930\n",
            "Epoch 260/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.4904 - accuracy: 0.2858 - val_loss: 7.9636 - val_accuracy: 0.1921\n",
            "Epoch 261/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.4866 - accuracy: 0.2859 - val_loss: 7.9908 - val_accuracy: 0.1936\n",
            "Epoch 262/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.4822 - accuracy: 0.2868 - val_loss: 7.9794 - val_accuracy: 0.1938\n",
            "Epoch 263/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.4843 - accuracy: 0.2852 - val_loss: 7.9565 - val_accuracy: 0.1932\n",
            "Epoch 264/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.4770 - accuracy: 0.2868 - val_loss: 7.9863 - val_accuracy: 0.1924\n",
            "Epoch 265/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.4733 - accuracy: 0.2879 - val_loss: 8.0129 - val_accuracy: 0.1915\n",
            "Epoch 266/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.4654 - accuracy: 0.2895 - val_loss: 7.9805 - val_accuracy: 0.1936\n",
            "Epoch 267/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.4644 - accuracy: 0.2874 - val_loss: 8.0143 - val_accuracy: 0.1931\n",
            "Epoch 268/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.4647 - accuracy: 0.2875 - val_loss: 8.0100 - val_accuracy: 0.1952\n",
            "Epoch 269/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.4593 - accuracy: 0.2882 - val_loss: 8.0453 - val_accuracy: 0.1934\n",
            "Epoch 270/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.4554 - accuracy: 0.2890 - val_loss: 8.0476 - val_accuracy: 0.1937\n",
            "Epoch 271/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.4577 - accuracy: 0.2896 - val_loss: 8.0458 - val_accuracy: 0.1927\n",
            "Epoch 272/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.4450 - accuracy: 0.2911 - val_loss: 8.0139 - val_accuracy: 0.1937\n",
            "Epoch 273/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.4463 - accuracy: 0.2912 - val_loss: 8.0304 - val_accuracy: 0.1937\n",
            "Epoch 274/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.4405 - accuracy: 0.2915 - val_loss: 8.0618 - val_accuracy: 0.1936\n",
            "Epoch 275/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.4387 - accuracy: 0.2909 - val_loss: 8.0417 - val_accuracy: 0.1941\n",
            "Epoch 276/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.4371 - accuracy: 0.2919 - val_loss: 8.0299 - val_accuracy: 0.1946\n",
            "Epoch 277/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.4358 - accuracy: 0.2925 - val_loss: 8.0308 - val_accuracy: 0.1935\n",
            "Epoch 278/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.4306 - accuracy: 0.2925 - val_loss: 8.0472 - val_accuracy: 0.1956\n",
            "Epoch 279/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.4348 - accuracy: 0.2924 - val_loss: 8.0308 - val_accuracy: 0.1971\n",
            "Epoch 280/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.4292 - accuracy: 0.2938 - val_loss: 8.0527 - val_accuracy: 0.1969\n",
            "Epoch 281/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.4302 - accuracy: 0.2931 - val_loss: 8.0448 - val_accuracy: 0.1940\n",
            "Epoch 282/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.4198 - accuracy: 0.2949 - val_loss: 8.0834 - val_accuracy: 0.1957\n",
            "Epoch 283/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.4207 - accuracy: 0.2956 - val_loss: 8.0679 - val_accuracy: 0.1950\n",
            "Epoch 284/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.4132 - accuracy: 0.2954 - val_loss: 8.0712 - val_accuracy: 0.1960\n",
            "Epoch 285/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.4109 - accuracy: 0.2963 - val_loss: 8.0681 - val_accuracy: 0.1964\n",
            "Epoch 286/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.4109 - accuracy: 0.2952 - val_loss: 8.1042 - val_accuracy: 0.1967\n",
            "Epoch 287/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.4103 - accuracy: 0.2957 - val_loss: 8.0948 - val_accuracy: 0.1980\n",
            "Epoch 288/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.4018 - accuracy: 0.2963 - val_loss: 8.0970 - val_accuracy: 0.1956\n",
            "Epoch 289/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.4002 - accuracy: 0.2972 - val_loss: 8.0901 - val_accuracy: 0.1968\n",
            "Epoch 290/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.3971 - accuracy: 0.2969 - val_loss: 8.0984 - val_accuracy: 0.1971\n",
            "Epoch 291/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.3976 - accuracy: 0.2976 - val_loss: 8.0914 - val_accuracy: 0.1974\n",
            "Epoch 292/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.3919 - accuracy: 0.2973 - val_loss: 8.0784 - val_accuracy: 0.1981\n",
            "Epoch 293/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.3947 - accuracy: 0.2990 - val_loss: 8.0801 - val_accuracy: 0.1973\n",
            "Epoch 294/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.3933 - accuracy: 0.2975 - val_loss: 8.1191 - val_accuracy: 0.1978\n",
            "Epoch 295/500\n",
            "79/79 [==============================] - 9s 112ms/step - loss: 3.3840 - accuracy: 0.3000 - val_loss: 8.1190 - val_accuracy: 0.1979\n",
            "Epoch 296/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.3836 - accuracy: 0.2992 - val_loss: 8.1224 - val_accuracy: 0.1970\n",
            "Epoch 297/500\n",
            "79/79 [==============================] - 11s 134ms/step - loss: 3.3825 - accuracy: 0.2993 - val_loss: 8.0891 - val_accuracy: 0.1987\n",
            "Epoch 298/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.3695 - accuracy: 0.3010 - val_loss: 8.1588 - val_accuracy: 0.1979\n",
            "Epoch 299/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.3688 - accuracy: 0.3013 - val_loss: 8.1442 - val_accuracy: 0.1986\n",
            "Epoch 300/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.3772 - accuracy: 0.2998 - val_loss: 8.1465 - val_accuracy: 0.1984\n",
            "Epoch 301/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.3738 - accuracy: 0.3007 - val_loss: 8.1570 - val_accuracy: 0.1987\n",
            "Epoch 302/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.3671 - accuracy: 0.3016 - val_loss: 8.1595 - val_accuracy: 0.1996\n",
            "Epoch 303/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.3623 - accuracy: 0.3027 - val_loss: 8.1759 - val_accuracy: 0.1991\n",
            "Epoch 304/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.3661 - accuracy: 0.3019 - val_loss: 8.1582 - val_accuracy: 0.1992\n",
            "Epoch 305/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.3590 - accuracy: 0.3026 - val_loss: 8.1774 - val_accuracy: 0.1996\n",
            "Epoch 306/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.3572 - accuracy: 0.3022 - val_loss: 8.1553 - val_accuracy: 0.1998\n",
            "Epoch 307/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.3460 - accuracy: 0.3039 - val_loss: 8.1712 - val_accuracy: 0.2006\n",
            "Epoch 308/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.3450 - accuracy: 0.3051 - val_loss: 8.1855 - val_accuracy: 0.1986\n",
            "Epoch 309/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 3.3485 - accuracy: 0.3035 - val_loss: 8.1999 - val_accuracy: 0.2009\n",
            "Epoch 310/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.3463 - accuracy: 0.3047 - val_loss: 8.1575 - val_accuracy: 0.2000\n",
            "Epoch 311/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 3.3456 - accuracy: 0.3043 - val_loss: 8.1745 - val_accuracy: 0.2013\n",
            "Epoch 312/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.3433 - accuracy: 0.3040 - val_loss: 8.1820 - val_accuracy: 0.2012\n",
            "Epoch 313/500\n",
            "79/79 [==============================] - 10s 130ms/step - loss: 3.3344 - accuracy: 0.3054 - val_loss: 8.2192 - val_accuracy: 0.2015\n",
            "Epoch 314/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.3310 - accuracy: 0.3059 - val_loss: 8.1690 - val_accuracy: 0.2012\n",
            "Epoch 315/500\n",
            "79/79 [==============================] - 11s 140ms/step - loss: 3.3323 - accuracy: 0.3073 - val_loss: 8.2147 - val_accuracy: 0.2027\n",
            "Epoch 316/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.3312 - accuracy: 0.3071 - val_loss: 8.1962 - val_accuracy: 0.2015\n",
            "Epoch 317/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 3.3295 - accuracy: 0.3073 - val_loss: 8.1877 - val_accuracy: 0.2028\n",
            "Epoch 318/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.3244 - accuracy: 0.3082 - val_loss: 8.2052 - val_accuracy: 0.2015\n",
            "Epoch 319/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.3246 - accuracy: 0.3082 - val_loss: 8.1989 - val_accuracy: 0.2019\n",
            "Epoch 320/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.3215 - accuracy: 0.3067 - val_loss: 8.2188 - val_accuracy: 0.2007\n",
            "Epoch 321/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.3227 - accuracy: 0.3078 - val_loss: 8.2286 - val_accuracy: 0.2031\n",
            "Epoch 322/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.3119 - accuracy: 0.3103 - val_loss: 8.2327 - val_accuracy: 0.2036\n",
            "Epoch 323/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.3111 - accuracy: 0.3095 - val_loss: 8.2418 - val_accuracy: 0.2033\n",
            "Epoch 324/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.3097 - accuracy: 0.3090 - val_loss: 8.2942 - val_accuracy: 0.2024\n",
            "Epoch 325/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.3078 - accuracy: 0.3095 - val_loss: 8.2405 - val_accuracy: 0.2032\n",
            "Epoch 326/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.3060 - accuracy: 0.3104 - val_loss: 8.2624 - val_accuracy: 0.2029\n",
            "Epoch 327/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.3093 - accuracy: 0.3092 - val_loss: 8.2303 - val_accuracy: 0.2030\n",
            "Epoch 328/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.3030 - accuracy: 0.3104 - val_loss: 8.2533 - val_accuracy: 0.2030\n",
            "Epoch 329/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2953 - accuracy: 0.3116 - val_loss: 8.2803 - val_accuracy: 0.2031\n",
            "Epoch 330/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.2959 - accuracy: 0.3119 - val_loss: 8.2983 - val_accuracy: 0.2042\n",
            "Epoch 331/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2903 - accuracy: 0.3125 - val_loss: 8.2555 - val_accuracy: 0.2030\n",
            "Epoch 332/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.3030 - accuracy: 0.3096 - val_loss: 8.3027 - val_accuracy: 0.2044\n",
            "Epoch 333/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2880 - accuracy: 0.3120 - val_loss: 8.3153 - val_accuracy: 0.2041\n",
            "Epoch 334/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2879 - accuracy: 0.3136 - val_loss: 8.3060 - val_accuracy: 0.2035\n",
            "Epoch 335/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.2830 - accuracy: 0.3140 - val_loss: 8.3044 - val_accuracy: 0.2027\n",
            "Epoch 336/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2770 - accuracy: 0.3152 - val_loss: 8.2770 - val_accuracy: 0.2042\n",
            "Epoch 337/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.2812 - accuracy: 0.3144 - val_loss: 8.2685 - val_accuracy: 0.2037\n",
            "Epoch 338/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.2817 - accuracy: 0.3134 - val_loss: 8.3069 - val_accuracy: 0.2051\n",
            "Epoch 339/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.2829 - accuracy: 0.3130 - val_loss: 8.3028 - val_accuracy: 0.2044\n",
            "Epoch 340/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2762 - accuracy: 0.3143 - val_loss: 8.2878 - val_accuracy: 0.2048\n",
            "Epoch 341/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2696 - accuracy: 0.3154 - val_loss: 8.3485 - val_accuracy: 0.2040\n",
            "Epoch 342/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.2643 - accuracy: 0.3154 - val_loss: 8.3481 - val_accuracy: 0.2054\n",
            "Epoch 343/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.2670 - accuracy: 0.3167 - val_loss: 8.3356 - val_accuracy: 0.2058\n",
            "Epoch 344/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.2654 - accuracy: 0.3154 - val_loss: 8.3350 - val_accuracy: 0.2053\n",
            "Epoch 345/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2737 - accuracy: 0.3144 - val_loss: 8.3286 - val_accuracy: 0.2048\n",
            "Epoch 346/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2626 - accuracy: 0.3160 - val_loss: 8.3341 - val_accuracy: 0.2045\n",
            "Epoch 347/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.2515 - accuracy: 0.3182 - val_loss: 8.3144 - val_accuracy: 0.2049\n",
            "Epoch 348/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2561 - accuracy: 0.3166 - val_loss: 8.3299 - val_accuracy: 0.2043\n",
            "Epoch 349/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.2606 - accuracy: 0.3178 - val_loss: 8.3551 - val_accuracy: 0.2061\n",
            "Epoch 350/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2467 - accuracy: 0.3184 - val_loss: 8.3670 - val_accuracy: 0.2053\n",
            "Epoch 351/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.2515 - accuracy: 0.3174 - val_loss: 8.3533 - val_accuracy: 0.2055\n",
            "Epoch 352/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2475 - accuracy: 0.3177 - val_loss: 8.3817 - val_accuracy: 0.2054\n",
            "Epoch 353/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.2416 - accuracy: 0.3192 - val_loss: 8.3853 - val_accuracy: 0.2070\n",
            "Epoch 354/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.2437 - accuracy: 0.3187 - val_loss: 8.3747 - val_accuracy: 0.2047\n",
            "Epoch 355/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.2409 - accuracy: 0.3193 - val_loss: 8.3478 - val_accuracy: 0.2051\n",
            "Epoch 356/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.2359 - accuracy: 0.3206 - val_loss: 8.3902 - val_accuracy: 0.2060\n",
            "Epoch 357/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2366 - accuracy: 0.3201 - val_loss: 8.3788 - val_accuracy: 0.2068\n",
            "Epoch 358/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.2312 - accuracy: 0.3216 - val_loss: 8.3660 - val_accuracy: 0.2056\n",
            "Epoch 359/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.2312 - accuracy: 0.3212 - val_loss: 8.3709 - val_accuracy: 0.2076\n",
            "Epoch 360/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2331 - accuracy: 0.3215 - val_loss: 8.3710 - val_accuracy: 0.2057\n",
            "Epoch 361/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.2261 - accuracy: 0.3226 - val_loss: 8.3863 - val_accuracy: 0.2064\n",
            "Epoch 362/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.2224 - accuracy: 0.3195 - val_loss: 8.3726 - val_accuracy: 0.2062\n",
            "Epoch 363/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2228 - accuracy: 0.3222 - val_loss: 8.4081 - val_accuracy: 0.2067\n",
            "Epoch 364/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2219 - accuracy: 0.3213 - val_loss: 8.4117 - val_accuracy: 0.2067\n",
            "Epoch 365/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.2169 - accuracy: 0.3215 - val_loss: 8.4260 - val_accuracy: 0.2067\n",
            "Epoch 366/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.2167 - accuracy: 0.3233 - val_loss: 8.4371 - val_accuracy: 0.2065\n",
            "Epoch 367/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2100 - accuracy: 0.3243 - val_loss: 8.4547 - val_accuracy: 0.2066\n",
            "Epoch 368/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.2149 - accuracy: 0.3220 - val_loss: 8.4300 - val_accuracy: 0.2084\n",
            "Epoch 369/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.2124 - accuracy: 0.3240 - val_loss: 8.4638 - val_accuracy: 0.2069\n",
            "Epoch 370/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.2084 - accuracy: 0.3228 - val_loss: 8.4275 - val_accuracy: 0.2081\n",
            "Epoch 371/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2113 - accuracy: 0.3228 - val_loss: 8.4370 - val_accuracy: 0.2070\n",
            "Epoch 372/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2087 - accuracy: 0.3224 - val_loss: 8.4017 - val_accuracy: 0.2076\n",
            "Epoch 373/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.2039 - accuracy: 0.3244 - val_loss: 8.4232 - val_accuracy: 0.2072\n",
            "Epoch 374/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.2001 - accuracy: 0.3249 - val_loss: 8.4150 - val_accuracy: 0.2080\n",
            "Epoch 375/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.2029 - accuracy: 0.3250 - val_loss: 8.4112 - val_accuracy: 0.2080\n",
            "Epoch 376/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1989 - accuracy: 0.3272 - val_loss: 8.4592 - val_accuracy: 0.2080\n",
            "Epoch 377/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.1944 - accuracy: 0.3253 - val_loss: 8.4605 - val_accuracy: 0.2087\n",
            "Epoch 378/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.1913 - accuracy: 0.3270 - val_loss: 8.4701 - val_accuracy: 0.2090\n",
            "Epoch 379/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 3.1894 - accuracy: 0.3267 - val_loss: 8.4449 - val_accuracy: 0.2090\n",
            "Epoch 380/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.1856 - accuracy: 0.3282 - val_loss: 8.4464 - val_accuracy: 0.2099\n",
            "Epoch 381/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.1831 - accuracy: 0.3284 - val_loss: 8.4786 - val_accuracy: 0.2099\n",
            "Epoch 382/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1872 - accuracy: 0.3273 - val_loss: 8.4617 - val_accuracy: 0.2094\n",
            "Epoch 383/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1859 - accuracy: 0.3267 - val_loss: 8.4427 - val_accuracy: 0.2086\n",
            "Epoch 384/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.1779 - accuracy: 0.3270 - val_loss: 8.4846 - val_accuracy: 0.2099\n",
            "Epoch 385/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.1782 - accuracy: 0.3280 - val_loss: 8.5047 - val_accuracy: 0.2095\n",
            "Epoch 386/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.1856 - accuracy: 0.3266 - val_loss: 8.4634 - val_accuracy: 0.2108\n",
            "Epoch 387/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1697 - accuracy: 0.3314 - val_loss: 8.5149 - val_accuracy: 0.2080\n",
            "Epoch 388/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.1737 - accuracy: 0.3297 - val_loss: 8.4998 - val_accuracy: 0.2097\n",
            "Epoch 389/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.1677 - accuracy: 0.3296 - val_loss: 8.4764 - val_accuracy: 0.2107\n",
            "Epoch 390/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.1795 - accuracy: 0.3298 - val_loss: 8.5478 - val_accuracy: 0.2099\n",
            "Epoch 391/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.1672 - accuracy: 0.3296 - val_loss: 8.5284 - val_accuracy: 0.2099\n",
            "Epoch 392/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.1677 - accuracy: 0.3312 - val_loss: 8.5046 - val_accuracy: 0.2117\n",
            "Epoch 393/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1609 - accuracy: 0.3315 - val_loss: 8.5230 - val_accuracy: 0.2110\n",
            "Epoch 394/500\n",
            "79/79 [==============================] - 11s 137ms/step - loss: 3.1598 - accuracy: 0.3302 - val_loss: 8.5460 - val_accuracy: 0.2117\n",
            "Epoch 395/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1609 - accuracy: 0.3319 - val_loss: 8.4930 - val_accuracy: 0.2104\n",
            "Epoch 396/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1496 - accuracy: 0.3331 - val_loss: 8.5567 - val_accuracy: 0.2107\n",
            "Epoch 397/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.1458 - accuracy: 0.3332 - val_loss: 8.5644 - val_accuracy: 0.2113\n",
            "Epoch 398/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1548 - accuracy: 0.3323 - val_loss: 8.5362 - val_accuracy: 0.2105\n",
            "Epoch 399/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.1501 - accuracy: 0.3332 - val_loss: 8.5188 - val_accuracy: 0.2101\n",
            "Epoch 400/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1532 - accuracy: 0.3330 - val_loss: 8.5788 - val_accuracy: 0.2109\n",
            "Epoch 401/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1423 - accuracy: 0.3349 - val_loss: 8.5486 - val_accuracy: 0.2115\n",
            "Epoch 402/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1464 - accuracy: 0.3339 - val_loss: 8.5511 - val_accuracy: 0.2102\n",
            "Epoch 403/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1469 - accuracy: 0.3330 - val_loss: 8.5606 - val_accuracy: 0.2115\n",
            "Epoch 404/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1444 - accuracy: 0.3339 - val_loss: 8.5098 - val_accuracy: 0.2115\n",
            "Epoch 405/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 3.1406 - accuracy: 0.3354 - val_loss: 8.5634 - val_accuracy: 0.2118\n",
            "Epoch 406/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1399 - accuracy: 0.3339 - val_loss: 8.5496 - val_accuracy: 0.2101\n",
            "Epoch 407/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.1358 - accuracy: 0.3338 - val_loss: 8.5735 - val_accuracy: 0.2114\n",
            "Epoch 408/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1306 - accuracy: 0.3355 - val_loss: 8.5623 - val_accuracy: 0.2106\n",
            "Epoch 409/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.1338 - accuracy: 0.3358 - val_loss: 8.5557 - val_accuracy: 0.2114\n",
            "Epoch 410/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1266 - accuracy: 0.3357 - val_loss: 8.5364 - val_accuracy: 0.2118\n",
            "Epoch 411/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.1303 - accuracy: 0.3355 - val_loss: 8.5779 - val_accuracy: 0.2116\n",
            "Epoch 412/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.1264 - accuracy: 0.3358 - val_loss: 8.5718 - val_accuracy: 0.2110\n",
            "Epoch 413/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.1205 - accuracy: 0.3366 - val_loss: 8.5875 - val_accuracy: 0.2130\n",
            "Epoch 414/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1262 - accuracy: 0.3342 - val_loss: 8.5946 - val_accuracy: 0.2112\n",
            "Epoch 415/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1296 - accuracy: 0.3348 - val_loss: 8.5656 - val_accuracy: 0.2124\n",
            "Epoch 416/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1214 - accuracy: 0.3361 - val_loss: 8.5856 - val_accuracy: 0.2118\n",
            "Epoch 417/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.1176 - accuracy: 0.3369 - val_loss: 8.5728 - val_accuracy: 0.2125\n",
            "Epoch 418/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.1215 - accuracy: 0.3356 - val_loss: 8.5964 - val_accuracy: 0.2115\n",
            "Epoch 419/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1144 - accuracy: 0.3382 - val_loss: 8.5905 - val_accuracy: 0.2125\n",
            "Epoch 420/500\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 3.1169 - accuracy: 0.3384 - val_loss: 8.5783 - val_accuracy: 0.2125\n",
            "Epoch 421/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1093 - accuracy: 0.3376 - val_loss: 8.5741 - val_accuracy: 0.2127\n",
            "Epoch 422/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.1135 - accuracy: 0.3378 - val_loss: 8.5986 - val_accuracy: 0.2135\n",
            "Epoch 423/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1136 - accuracy: 0.3390 - val_loss: 8.6173 - val_accuracy: 0.2135\n",
            "Epoch 424/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 3.1014 - accuracy: 0.3412 - val_loss: 8.6152 - val_accuracy: 0.2143\n",
            "Epoch 425/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1019 - accuracy: 0.3393 - val_loss: 8.5989 - val_accuracy: 0.2131\n",
            "Epoch 426/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1035 - accuracy: 0.3394 - val_loss: 8.6204 - val_accuracy: 0.2134\n",
            "Epoch 427/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.1007 - accuracy: 0.3401 - val_loss: 8.6265 - val_accuracy: 0.2143\n",
            "Epoch 428/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0965 - accuracy: 0.3397 - val_loss: 8.6462 - val_accuracy: 0.2135\n",
            "Epoch 429/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.1033 - accuracy: 0.3409 - val_loss: 8.6172 - val_accuracy: 0.2137\n",
            "Epoch 430/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.1066 - accuracy: 0.3393 - val_loss: 8.6067 - val_accuracy: 0.2133\n",
            "Epoch 431/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0929 - accuracy: 0.3420 - val_loss: 8.6399 - val_accuracy: 0.2135\n",
            "Epoch 432/500\n",
            "79/79 [==============================] - 10s 131ms/step - loss: 3.0909 - accuracy: 0.3408 - val_loss: 8.6236 - val_accuracy: 0.2145\n",
            "Epoch 433/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0951 - accuracy: 0.3426 - val_loss: 8.6237 - val_accuracy: 0.2142\n",
            "Epoch 434/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.0949 - accuracy: 0.3419 - val_loss: 8.5933 - val_accuracy: 0.2150\n",
            "Epoch 435/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0943 - accuracy: 0.3411 - val_loss: 8.6360 - val_accuracy: 0.2133\n",
            "Epoch 436/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.0815 - accuracy: 0.3435 - val_loss: 8.6180 - val_accuracy: 0.2151\n",
            "Epoch 437/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0852 - accuracy: 0.3416 - val_loss: 8.6422 - val_accuracy: 0.2162\n",
            "Epoch 438/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0820 - accuracy: 0.3425 - val_loss: 8.6323 - val_accuracy: 0.2143\n",
            "Epoch 439/500\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 3.0793 - accuracy: 0.3445 - val_loss: 8.6312 - val_accuracy: 0.2167\n",
            "Epoch 440/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0811 - accuracy: 0.3425 - val_loss: 8.6386 - val_accuracy: 0.2152\n",
            "Epoch 441/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0820 - accuracy: 0.3421 - val_loss: 8.6640 - val_accuracy: 0.2155\n",
            "Epoch 442/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0792 - accuracy: 0.3435 - val_loss: 8.6402 - val_accuracy: 0.2161\n",
            "Epoch 443/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0795 - accuracy: 0.3431 - val_loss: 8.6527 - val_accuracy: 0.2150\n",
            "Epoch 444/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0803 - accuracy: 0.3435 - val_loss: 8.6852 - val_accuracy: 0.2156\n",
            "Epoch 445/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.0758 - accuracy: 0.3441 - val_loss: 8.6736 - val_accuracy: 0.2154\n",
            "Epoch 446/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0748 - accuracy: 0.3441 - val_loss: 8.6817 - val_accuracy: 0.2166\n",
            "Epoch 447/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0651 - accuracy: 0.3455 - val_loss: 8.6640 - val_accuracy: 0.2164\n",
            "Epoch 448/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0703 - accuracy: 0.3446 - val_loss: 8.6732 - val_accuracy: 0.2155\n",
            "Epoch 449/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0698 - accuracy: 0.3457 - val_loss: 8.6928 - val_accuracy: 0.2163\n",
            "Epoch 450/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0661 - accuracy: 0.3456 - val_loss: 8.6725 - val_accuracy: 0.2162\n",
            "Epoch 451/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0581 - accuracy: 0.3455 - val_loss: 8.6978 - val_accuracy: 0.2156\n",
            "Epoch 452/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.0601 - accuracy: 0.3466 - val_loss: 8.6843 - val_accuracy: 0.2169\n",
            "Epoch 453/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0590 - accuracy: 0.3457 - val_loss: 8.7155 - val_accuracy: 0.2144\n",
            "Epoch 454/500\n",
            "79/79 [==============================] - 10s 128ms/step - loss: 3.0566 - accuracy: 0.3467 - val_loss: 8.7078 - val_accuracy: 0.2169\n",
            "Epoch 455/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.0597 - accuracy: 0.3464 - val_loss: 8.7130 - val_accuracy: 0.2162\n",
            "Epoch 456/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0490 - accuracy: 0.3473 - val_loss: 8.6988 - val_accuracy: 0.2169\n",
            "Epoch 457/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.0485 - accuracy: 0.3482 - val_loss: 8.7215 - val_accuracy: 0.2182\n",
            "Epoch 458/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0560 - accuracy: 0.3471 - val_loss: 8.6969 - val_accuracy: 0.2174\n",
            "Epoch 459/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0466 - accuracy: 0.3481 - val_loss: 8.6627 - val_accuracy: 0.2180\n",
            "Epoch 460/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0440 - accuracy: 0.3483 - val_loss: 8.7230 - val_accuracy: 0.2174\n",
            "Epoch 461/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0478 - accuracy: 0.3476 - val_loss: 8.7183 - val_accuracy: 0.2175\n",
            "Epoch 462/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0509 - accuracy: 0.3482 - val_loss: 8.7050 - val_accuracy: 0.2169\n",
            "Epoch 463/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0474 - accuracy: 0.3476 - val_loss: 8.7034 - val_accuracy: 0.2171\n",
            "Epoch 464/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0467 - accuracy: 0.3482 - val_loss: 8.7178 - val_accuracy: 0.2178\n",
            "Epoch 465/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.0431 - accuracy: 0.3490 - val_loss: 8.7363 - val_accuracy: 0.2189\n",
            "Epoch 466/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0328 - accuracy: 0.3495 - val_loss: 8.7420 - val_accuracy: 0.2185\n",
            "Epoch 467/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0433 - accuracy: 0.3493 - val_loss: 8.6834 - val_accuracy: 0.2186\n",
            "Epoch 468/500\n",
            "79/79 [==============================] - 10s 127ms/step - loss: 3.0389 - accuracy: 0.3501 - val_loss: 8.7446 - val_accuracy: 0.2191\n",
            "Epoch 469/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0342 - accuracy: 0.3496 - val_loss: 8.7657 - val_accuracy: 0.2178\n",
            "Epoch 470/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0473 - accuracy: 0.3484 - val_loss: 8.7107 - val_accuracy: 0.2191\n",
            "Epoch 471/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0281 - accuracy: 0.3510 - val_loss: 8.7312 - val_accuracy: 0.2185\n",
            "Epoch 472/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0295 - accuracy: 0.3507 - val_loss: 8.7145 - val_accuracy: 0.2185\n",
            "Epoch 473/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.0329 - accuracy: 0.3495 - val_loss: 8.7647 - val_accuracy: 0.2193\n",
            "Epoch 474/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.0216 - accuracy: 0.3521 - val_loss: 8.7583 - val_accuracy: 0.2199\n",
            "Epoch 475/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0267 - accuracy: 0.3511 - val_loss: 8.7520 - val_accuracy: 0.2190\n",
            "Epoch 476/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0235 - accuracy: 0.3518 - val_loss: 8.7642 - val_accuracy: 0.2189\n",
            "Epoch 477/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0221 - accuracy: 0.3511 - val_loss: 8.7537 - val_accuracy: 0.2189\n",
            "Epoch 478/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0241 - accuracy: 0.3527 - val_loss: 8.7398 - val_accuracy: 0.2191\n",
            "Epoch 479/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0179 - accuracy: 0.3537 - val_loss: 8.7988 - val_accuracy: 0.2196\n",
            "Epoch 480/500\n",
            "79/79 [==============================] - 10s 125ms/step - loss: 3.0206 - accuracy: 0.3524 - val_loss: 8.7864 - val_accuracy: 0.2212\n",
            "Epoch 481/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0184 - accuracy: 0.3535 - val_loss: 8.7713 - val_accuracy: 0.2209\n",
            "Epoch 482/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0139 - accuracy: 0.3523 - val_loss: 8.7738 - val_accuracy: 0.2197\n",
            "Epoch 483/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0199 - accuracy: 0.3519 - val_loss: 8.7518 - val_accuracy: 0.2204\n",
            "Epoch 484/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0136 - accuracy: 0.3540 - val_loss: 8.7769 - val_accuracy: 0.2207\n",
            "Epoch 485/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.0094 - accuracy: 0.3554 - val_loss: 8.7496 - val_accuracy: 0.2192\n",
            "Epoch 486/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0141 - accuracy: 0.3538 - val_loss: 8.7627 - val_accuracy: 0.2208\n",
            "Epoch 487/500\n",
            "79/79 [==============================] - 9s 114ms/step - loss: 3.0104 - accuracy: 0.3541 - val_loss: 8.7433 - val_accuracy: 0.2190\n",
            "Epoch 488/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0059 - accuracy: 0.3548 - val_loss: 8.7718 - val_accuracy: 0.2211\n",
            "Epoch 489/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 3.0156 - accuracy: 0.3528 - val_loss: 8.7737 - val_accuracy: 0.2206\n",
            "Epoch 490/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.0024 - accuracy: 0.3550 - val_loss: 8.7886 - val_accuracy: 0.2199\n",
            "Epoch 491/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 3.0076 - accuracy: 0.3540 - val_loss: 8.7941 - val_accuracy: 0.2212\n",
            "Epoch 492/500\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 3.0062 - accuracy: 0.3542 - val_loss: 8.7788 - val_accuracy: 0.2230\n",
            "Epoch 493/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 3.0029 - accuracy: 0.3559 - val_loss: 8.8287 - val_accuracy: 0.2233\n",
            "Epoch 494/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 2.9947 - accuracy: 0.3569 - val_loss: 8.7783 - val_accuracy: 0.2228\n",
            "Epoch 495/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 2.9946 - accuracy: 0.3564 - val_loss: 8.8408 - val_accuracy: 0.2220\n",
            "Epoch 496/500\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 2.9984 - accuracy: 0.3554 - val_loss: 8.8086 - val_accuracy: 0.2218\n",
            "Epoch 497/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 2.9995 - accuracy: 0.3551 - val_loss: 8.7985 - val_accuracy: 0.2220\n",
            "Epoch 498/500\n",
            "79/79 [==============================] - 9s 116ms/step - loss: 3.0003 - accuracy: 0.3546 - val_loss: 8.7707 - val_accuracy: 0.2225\n",
            "Epoch 499/500\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 2.9934 - accuracy: 0.3563 - val_loss: 8.8001 - val_accuracy: 0.2228\n",
            "Epoch 500/500\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 2.9899 - accuracy: 0.3547 - val_loss: 8.8127 - val_accuracy: 0.2230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y35orGI_7Mh",
        "colab_type": "text"
      },
      "source": [
        "## V5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNmL-cAkspbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "05728951-b84d-4757-eac6-68a255070326"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(    \n",
        "    Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=embedding_matrix.shape[1],\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=True)\n",
        ")\n",
        "\n",
        "model.add(LSTM(256, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(256))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(num_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7xulino73AY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f75aa500-1a13-4638-fff3-04089e9db843"
      },
      "source": [
        "# model_filename = f'{DATASET}-custom-5.h5'\n",
        "# model_filepath = os.path.join(MODELS_DIR, model_filename)\n",
        "# print(model_filepath)\n",
        "# # model = load_model(model_filepath)\n",
        "\n",
        "# callbacks = [\n",
        "#     EarlyStopping(monitor='val_accuracy', patience=25),\n",
        "#     ModelCheckpoint(f'{model_filepath}', save_best_only=True, save_weights_only=False, monitor='val_accuracy')\n",
        "# ]\n",
        "\n",
        "# EPOCHS = 500\n",
        "\n",
        "# history = model.fit(\n",
        "#     X_train, \n",
        "#     y_train, \n",
        "#     epochs=EPOCHS, \n",
        "#     batch_size=2048, \n",
        "#     validation_data=(X_test, y_test), \n",
        "#     verbose=1,\n",
        "#     callbacks=callbacks\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/models/BBC-TECH-custom-5.h5\n",
            "Epoch 1/500\n",
            "79/79 [==============================] - 12s 152ms/step - loss: 7.4532 - accuracy: 0.0541 - val_loss: 7.0820 - val_accuracy: 0.0571\n",
            "Epoch 2/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 7.0215 - accuracy: 0.0578 - val_loss: 7.0999 - val_accuracy: 0.0571\n",
            "Epoch 3/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 7.0088 - accuracy: 0.0578 - val_loss: 7.1079 - val_accuracy: 0.0571\n",
            "Epoch 4/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 6.9853 - accuracy: 0.0578 - val_loss: 7.0093 - val_accuracy: 0.0571\n",
            "Epoch 5/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 6.8651 - accuracy: 0.0621 - val_loss: 6.9215 - val_accuracy: 0.0664\n",
            "Epoch 6/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 6.7333 - accuracy: 0.0699 - val_loss: 6.8204 - val_accuracy: 0.0715\n",
            "Epoch 7/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 6.6165 - accuracy: 0.0778 - val_loss: 6.7527 - val_accuracy: 0.0811\n",
            "Epoch 8/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 6.5189 - accuracy: 0.0836 - val_loss: 6.7082 - val_accuracy: 0.0861\n",
            "Epoch 9/500\n",
            "79/79 [==============================] - 12s 149ms/step - loss: 6.4445 - accuracy: 0.0896 - val_loss: 6.6736 - val_accuracy: 0.0919\n",
            "Epoch 10/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 6.3746 - accuracy: 0.0964 - val_loss: 6.6353 - val_accuracy: 0.0950\n",
            "Epoch 11/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 6.2983 - accuracy: 0.1016 - val_loss: 6.5998 - val_accuracy: 0.0980\n",
            "Epoch 12/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 6.2208 - accuracy: 0.1052 - val_loss: 6.5675 - val_accuracy: 0.1001\n",
            "Epoch 13/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 6.1499 - accuracy: 0.1094 - val_loss: 6.5498 - val_accuracy: 0.1030\n",
            "Epoch 14/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 6.0829 - accuracy: 0.1120 - val_loss: 6.5342 - val_accuracy: 0.1056\n",
            "Epoch 15/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 6.0201 - accuracy: 0.1157 - val_loss: 6.5196 - val_accuracy: 0.1098\n",
            "Epoch 16/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 5.9542 - accuracy: 0.1188 - val_loss: 6.5004 - val_accuracy: 0.1114\n",
            "Epoch 17/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 5.8870 - accuracy: 0.1224 - val_loss: 6.4847 - val_accuracy: 0.1142\n",
            "Epoch 18/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 5.8243 - accuracy: 0.1259 - val_loss: 6.4806 - val_accuracy: 0.1151\n",
            "Epoch 19/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 5.7672 - accuracy: 0.1279 - val_loss: 6.4636 - val_accuracy: 0.1172\n",
            "Epoch 20/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 5.7124 - accuracy: 0.1307 - val_loss: 6.4644 - val_accuracy: 0.1179\n",
            "Epoch 21/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 5.6605 - accuracy: 0.1326 - val_loss: 6.4645 - val_accuracy: 0.1205\n",
            "Epoch 22/500\n",
            "79/79 [==============================] - 11s 146ms/step - loss: 5.6130 - accuracy: 0.1351 - val_loss: 6.4649 - val_accuracy: 0.1221\n",
            "Epoch 23/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 5.5678 - accuracy: 0.1370 - val_loss: 6.4736 - val_accuracy: 0.1243\n",
            "Epoch 24/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 5.5234 - accuracy: 0.1391 - val_loss: 6.4814 - val_accuracy: 0.1251\n",
            "Epoch 25/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 5.4794 - accuracy: 0.1414 - val_loss: 6.4758 - val_accuracy: 0.1261\n",
            "Epoch 26/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 5.4401 - accuracy: 0.1426 - val_loss: 6.4961 - val_accuracy: 0.1270\n",
            "Epoch 27/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 5.4024 - accuracy: 0.1438 - val_loss: 6.5024 - val_accuracy: 0.1277\n",
            "Epoch 28/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 5.3592 - accuracy: 0.1466 - val_loss: 6.5081 - val_accuracy: 0.1286\n",
            "Epoch 29/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 5.3261 - accuracy: 0.1470 - val_loss: 6.5342 - val_accuracy: 0.1274\n",
            "Epoch 30/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 5.3681 - accuracy: 0.1455 - val_loss: 6.5373 - val_accuracy: 0.1301\n",
            "Epoch 31/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 5.2635 - accuracy: 0.1502 - val_loss: 6.5439 - val_accuracy: 0.1310\n",
            "Epoch 32/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 5.2244 - accuracy: 0.1521 - val_loss: 6.5539 - val_accuracy: 0.1323\n",
            "Epoch 33/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 5.1866 - accuracy: 0.1535 - val_loss: 6.5585 - val_accuracy: 0.1337\n",
            "Epoch 34/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 5.1555 - accuracy: 0.1543 - val_loss: 6.5768 - val_accuracy: 0.1333\n",
            "Epoch 35/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 5.1194 - accuracy: 0.1561 - val_loss: 6.5852 - val_accuracy: 0.1336\n",
            "Epoch 36/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 5.0881 - accuracy: 0.1567 - val_loss: 6.5937 - val_accuracy: 0.1358\n",
            "Epoch 37/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 5.0579 - accuracy: 0.1583 - val_loss: 6.6121 - val_accuracy: 0.1361\n",
            "Epoch 38/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 5.0240 - accuracy: 0.1594 - val_loss: 6.6257 - val_accuracy: 0.1365\n",
            "Epoch 39/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 4.9950 - accuracy: 0.1614 - val_loss: 6.6268 - val_accuracy: 0.1369\n",
            "Epoch 40/500\n",
            "79/79 [==============================] - 12s 148ms/step - loss: 4.9670 - accuracy: 0.1613 - val_loss: 6.6376 - val_accuracy: 0.1377\n",
            "Epoch 41/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 4.9349 - accuracy: 0.1636 - val_loss: 6.6397 - val_accuracy: 0.1399\n",
            "Epoch 42/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 4.9077 - accuracy: 0.1650 - val_loss: 6.6694 - val_accuracy: 0.1385\n",
            "Epoch 43/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 4.8781 - accuracy: 0.1658 - val_loss: 6.6772 - val_accuracy: 0.1399\n",
            "Epoch 44/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 4.8508 - accuracy: 0.1679 - val_loss: 6.6903 - val_accuracy: 0.1411\n",
            "Epoch 45/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 4.8224 - accuracy: 0.1685 - val_loss: 6.6962 - val_accuracy: 0.1418\n",
            "Epoch 46/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 4.7972 - accuracy: 0.1703 - val_loss: 6.7094 - val_accuracy: 0.1418\n",
            "Epoch 47/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 4.7672 - accuracy: 0.1722 - val_loss: 6.7237 - val_accuracy: 0.1420\n",
            "Epoch 48/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 4.7443 - accuracy: 0.1725 - val_loss: 6.7376 - val_accuracy: 0.1429\n",
            "Epoch 49/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 4.7157 - accuracy: 0.1742 - val_loss: 6.7607 - val_accuracy: 0.1431\n",
            "Epoch 50/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 4.6941 - accuracy: 0.1761 - val_loss: 6.7802 - val_accuracy: 0.1443\n",
            "Epoch 51/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 4.6672 - accuracy: 0.1774 - val_loss: 6.7762 - val_accuracy: 0.1443\n",
            "Epoch 52/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 4.6430 - accuracy: 0.1786 - val_loss: 6.7938 - val_accuracy: 0.1460\n",
            "Epoch 53/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 4.6192 - accuracy: 0.1800 - val_loss: 6.8100 - val_accuracy: 0.1463\n",
            "Epoch 54/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 4.5962 - accuracy: 0.1815 - val_loss: 6.8290 - val_accuracy: 0.1467\n",
            "Epoch 55/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 4.5724 - accuracy: 0.1820 - val_loss: 6.8360 - val_accuracy: 0.1468\n",
            "Epoch 56/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 4.5483 - accuracy: 0.1848 - val_loss: 6.8531 - val_accuracy: 0.1471\n",
            "Epoch 57/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 4.5287 - accuracy: 0.1855 - val_loss: 6.8589 - val_accuracy: 0.1477\n",
            "Epoch 58/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 4.5085 - accuracy: 0.1870 - val_loss: 6.8714 - val_accuracy: 0.1493\n",
            "Epoch 59/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 4.4856 - accuracy: 0.1885 - val_loss: 6.8866 - val_accuracy: 0.1495\n",
            "Epoch 60/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 4.4628 - accuracy: 0.1898 - val_loss: 6.9124 - val_accuracy: 0.1494\n",
            "Epoch 61/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 4.4408 - accuracy: 0.1921 - val_loss: 6.9248 - val_accuracy: 0.1511\n",
            "Epoch 62/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 4.4236 - accuracy: 0.1927 - val_loss: 6.9306 - val_accuracy: 0.1510\n",
            "Epoch 63/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 4.4008 - accuracy: 0.1946 - val_loss: 6.9435 - val_accuracy: 0.1530\n",
            "Epoch 64/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 4.3815 - accuracy: 0.1956 - val_loss: 6.9626 - val_accuracy: 0.1535\n",
            "Epoch 65/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 4.3642 - accuracy: 0.1969 - val_loss: 6.9735 - val_accuracy: 0.1522\n",
            "Epoch 66/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 4.3475 - accuracy: 0.1984 - val_loss: 6.9890 - val_accuracy: 0.1534\n",
            "Epoch 67/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 4.3236 - accuracy: 0.2003 - val_loss: 7.0021 - val_accuracy: 0.1526\n",
            "Epoch 68/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 4.3095 - accuracy: 0.2008 - val_loss: 7.0205 - val_accuracy: 0.1550\n",
            "Epoch 69/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 4.2896 - accuracy: 0.2023 - val_loss: 7.0279 - val_accuracy: 0.1553\n",
            "Epoch 70/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 4.2700 - accuracy: 0.2040 - val_loss: 7.0441 - val_accuracy: 0.1553\n",
            "Epoch 71/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 4.2607 - accuracy: 0.2050 - val_loss: 7.0563 - val_accuracy: 0.1565\n",
            "Epoch 72/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 4.2409 - accuracy: 0.2070 - val_loss: 7.0793 - val_accuracy: 0.1583\n",
            "Epoch 73/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 4.2205 - accuracy: 0.2086 - val_loss: 7.0962 - val_accuracy: 0.1567\n",
            "Epoch 74/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 4.2057 - accuracy: 0.2097 - val_loss: 7.0989 - val_accuracy: 0.1579\n",
            "Epoch 75/500\n",
            "79/79 [==============================] - 12s 152ms/step - loss: 4.1887 - accuracy: 0.2111 - val_loss: 7.1199 - val_accuracy: 0.1587\n",
            "Epoch 76/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 4.1711 - accuracy: 0.2124 - val_loss: 7.1208 - val_accuracy: 0.1603\n",
            "Epoch 77/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 4.1600 - accuracy: 0.2137 - val_loss: 7.1578 - val_accuracy: 0.1595\n",
            "Epoch 78/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 4.1423 - accuracy: 0.2151 - val_loss: 7.1610 - val_accuracy: 0.1601\n",
            "Epoch 79/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 4.1273 - accuracy: 0.2157 - val_loss: 7.1685 - val_accuracy: 0.1605\n",
            "Epoch 80/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 4.1085 - accuracy: 0.2184 - val_loss: 7.1907 - val_accuracy: 0.1612\n",
            "Epoch 81/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 4.0934 - accuracy: 0.2194 - val_loss: 7.1929 - val_accuracy: 0.1609\n",
            "Epoch 82/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 4.0793 - accuracy: 0.2210 - val_loss: 7.2073 - val_accuracy: 0.1607\n",
            "Epoch 83/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 4.0683 - accuracy: 0.2223 - val_loss: 7.2331 - val_accuracy: 0.1616\n",
            "Epoch 84/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 4.0535 - accuracy: 0.2234 - val_loss: 7.2484 - val_accuracy: 0.1611\n",
            "Epoch 85/500\n",
            "79/79 [==============================] - 12s 152ms/step - loss: 4.0386 - accuracy: 0.2250 - val_loss: 7.2624 - val_accuracy: 0.1626\n",
            "Epoch 86/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 4.0201 - accuracy: 0.2271 - val_loss: 7.2822 - val_accuracy: 0.1639\n",
            "Epoch 87/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 4.0073 - accuracy: 0.2275 - val_loss: 7.3006 - val_accuracy: 0.1639\n",
            "Epoch 88/500\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 3.9914 - accuracy: 0.2278 - val_loss: 7.3113 - val_accuracy: 0.1639\n",
            "Epoch 89/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 3.9800 - accuracy: 0.2310 - val_loss: 7.3378 - val_accuracy: 0.1649\n",
            "Epoch 90/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.9668 - accuracy: 0.2319 - val_loss: 7.3054 - val_accuracy: 0.1643\n",
            "Epoch 91/500\n",
            "79/79 [==============================] - 12s 152ms/step - loss: 3.9571 - accuracy: 0.2326 - val_loss: 7.3536 - val_accuracy: 0.1651\n",
            "Epoch 92/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.9417 - accuracy: 0.2343 - val_loss: 7.3688 - val_accuracy: 0.1665\n",
            "Epoch 93/500\n",
            "79/79 [==============================] - 12s 149ms/step - loss: 3.9264 - accuracy: 0.2356 - val_loss: 7.3907 - val_accuracy: 0.1686\n",
            "Epoch 94/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.9174 - accuracy: 0.2347 - val_loss: 7.3996 - val_accuracy: 0.1675\n",
            "Epoch 95/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 3.8975 - accuracy: 0.2393 - val_loss: 7.4036 - val_accuracy: 0.1690\n",
            "Epoch 96/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.8824 - accuracy: 0.2400 - val_loss: 7.4092 - val_accuracy: 0.1675\n",
            "Epoch 97/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 3.8785 - accuracy: 0.2406 - val_loss: 7.4315 - val_accuracy: 0.1697\n",
            "Epoch 98/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.8661 - accuracy: 0.2427 - val_loss: 7.4637 - val_accuracy: 0.1692\n",
            "Epoch 99/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.8525 - accuracy: 0.2430 - val_loss: 7.4566 - val_accuracy: 0.1697\n",
            "Epoch 100/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 3.8342 - accuracy: 0.2444 - val_loss: 7.4818 - val_accuracy: 0.1701\n",
            "Epoch 101/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 3.8291 - accuracy: 0.2459 - val_loss: 7.4864 - val_accuracy: 0.1719\n",
            "Epoch 102/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.8147 - accuracy: 0.2481 - val_loss: 7.5138 - val_accuracy: 0.1712\n",
            "Epoch 103/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.8036 - accuracy: 0.2487 - val_loss: 7.5188 - val_accuracy: 0.1717\n",
            "Epoch 104/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 3.7900 - accuracy: 0.2509 - val_loss: 7.5365 - val_accuracy: 0.1735\n",
            "Epoch 105/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.7779 - accuracy: 0.2514 - val_loss: 7.5748 - val_accuracy: 0.1726\n",
            "Epoch 106/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 3.7659 - accuracy: 0.2538 - val_loss: 7.5765 - val_accuracy: 0.1743\n",
            "Epoch 107/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.7561 - accuracy: 0.2531 - val_loss: 7.5892 - val_accuracy: 0.1746\n",
            "Epoch 108/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.7440 - accuracy: 0.2549 - val_loss: 7.6063 - val_accuracy: 0.1740\n",
            "Epoch 109/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 3.7331 - accuracy: 0.2581 - val_loss: 7.6162 - val_accuracy: 0.1753\n",
            "Epoch 110/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.7175 - accuracy: 0.2582 - val_loss: 7.6297 - val_accuracy: 0.1756\n",
            "Epoch 111/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.7099 - accuracy: 0.2592 - val_loss: 7.6292 - val_accuracy: 0.1755\n",
            "Epoch 112/500\n",
            "79/79 [==============================] - 12s 152ms/step - loss: 3.6939 - accuracy: 0.2618 - val_loss: 7.6441 - val_accuracy: 0.1763\n",
            "Epoch 113/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.6858 - accuracy: 0.2618 - val_loss: 7.6751 - val_accuracy: 0.1754\n",
            "Epoch 114/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 3.6764 - accuracy: 0.2627 - val_loss: 7.6839 - val_accuracy: 0.1766\n",
            "Epoch 115/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.6675 - accuracy: 0.2631 - val_loss: 7.7062 - val_accuracy: 0.1765\n",
            "Epoch 116/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 3.6560 - accuracy: 0.2649 - val_loss: 7.7319 - val_accuracy: 0.1766\n",
            "Epoch 117/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 3.6444 - accuracy: 0.2663 - val_loss: 7.7393 - val_accuracy: 0.1793\n",
            "Epoch 118/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.6333 - accuracy: 0.2671 - val_loss: 7.7589 - val_accuracy: 0.1759\n",
            "Epoch 119/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.6218 - accuracy: 0.2687 - val_loss: 7.7670 - val_accuracy: 0.1780\n",
            "Epoch 120/500\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 3.6154 - accuracy: 0.2697 - val_loss: 7.7743 - val_accuracy: 0.1774\n",
            "Epoch 121/500\n",
            "79/79 [==============================] - 12s 152ms/step - loss: 3.6059 - accuracy: 0.2702 - val_loss: 7.8004 - val_accuracy: 0.1796\n",
            "Epoch 122/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 3.5909 - accuracy: 0.2733 - val_loss: 7.7903 - val_accuracy: 0.1799\n",
            "Epoch 123/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.5819 - accuracy: 0.2743 - val_loss: 7.8020 - val_accuracy: 0.1822\n",
            "Epoch 124/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.5764 - accuracy: 0.2754 - val_loss: 7.8246 - val_accuracy: 0.1801\n",
            "Epoch 125/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.5617 - accuracy: 0.2760 - val_loss: 7.8383 - val_accuracy: 0.1818\n",
            "Epoch 126/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.5515 - accuracy: 0.2777 - val_loss: 7.8445 - val_accuracy: 0.1808\n",
            "Epoch 127/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.5428 - accuracy: 0.2778 - val_loss: 7.8826 - val_accuracy: 0.1812\n",
            "Epoch 128/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 3.5339 - accuracy: 0.2789 - val_loss: 7.8890 - val_accuracy: 0.1823\n",
            "Epoch 129/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.5205 - accuracy: 0.2823 - val_loss: 7.9029 - val_accuracy: 0.1816\n",
            "Epoch 130/500\n",
            "79/79 [==============================] - 13s 169ms/step - loss: 3.5093 - accuracy: 0.2816 - val_loss: 7.9066 - val_accuracy: 0.1830\n",
            "Epoch 131/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.4980 - accuracy: 0.2851 - val_loss: 7.9350 - val_accuracy: 0.1849\n",
            "Epoch 132/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.4914 - accuracy: 0.2823 - val_loss: 7.9549 - val_accuracy: 0.1840\n",
            "Epoch 133/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.4822 - accuracy: 0.2861 - val_loss: 7.9465 - val_accuracy: 0.1841\n",
            "Epoch 134/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.4707 - accuracy: 0.2871 - val_loss: 7.9757 - val_accuracy: 0.1841\n",
            "Epoch 135/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 3.4584 - accuracy: 0.2892 - val_loss: 7.9717 - val_accuracy: 0.1855\n",
            "Epoch 136/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.4525 - accuracy: 0.2903 - val_loss: 8.0007 - val_accuracy: 0.1846\n",
            "Epoch 137/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.4421 - accuracy: 0.2902 - val_loss: 8.0044 - val_accuracy: 0.1840\n",
            "Epoch 138/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 3.4327 - accuracy: 0.2913 - val_loss: 8.0279 - val_accuracy: 0.1857\n",
            "Epoch 139/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 3.4267 - accuracy: 0.2930 - val_loss: 8.0354 - val_accuracy: 0.1866\n",
            "Epoch 140/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.4151 - accuracy: 0.2943 - val_loss: 8.0462 - val_accuracy: 0.1877\n",
            "Epoch 141/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.4010 - accuracy: 0.2941 - val_loss: 8.1140 - val_accuracy: 0.1865\n",
            "Epoch 142/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.3974 - accuracy: 0.2971 - val_loss: 8.1042 - val_accuracy: 0.1874\n",
            "Epoch 143/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 3.3859 - accuracy: 0.2973 - val_loss: 8.0816 - val_accuracy: 0.1892\n",
            "Epoch 144/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.3768 - accuracy: 0.2986 - val_loss: 8.0992 - val_accuracy: 0.1899\n",
            "Epoch 145/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.3643 - accuracy: 0.2996 - val_loss: 8.1079 - val_accuracy: 0.1886\n",
            "Epoch 146/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.3620 - accuracy: 0.3009 - val_loss: 8.1396 - val_accuracy: 0.1897\n",
            "Epoch 147/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.3472 - accuracy: 0.3020 - val_loss: 8.1989 - val_accuracy: 0.1892\n",
            "Epoch 148/500\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 3.3415 - accuracy: 0.3032 - val_loss: 8.1846 - val_accuracy: 0.1882\n",
            "Epoch 149/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 3.3337 - accuracy: 0.3038 - val_loss: 8.1512 - val_accuracy: 0.1902\n",
            "Epoch 150/500\n",
            "79/79 [==============================] - 12s 158ms/step - loss: 3.3223 - accuracy: 0.3054 - val_loss: 8.1881 - val_accuracy: 0.1904\n",
            "Epoch 151/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 3.3132 - accuracy: 0.3065 - val_loss: 8.1998 - val_accuracy: 0.1906\n",
            "Epoch 152/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.3052 - accuracy: 0.3087 - val_loss: 8.1994 - val_accuracy: 0.1924\n",
            "Epoch 153/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 3.2967 - accuracy: 0.3094 - val_loss: 8.1985 - val_accuracy: 0.1924\n",
            "Epoch 154/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.2908 - accuracy: 0.3099 - val_loss: 8.2508 - val_accuracy: 0.1924\n",
            "Epoch 155/500\n",
            "79/79 [==============================] - 13s 163ms/step - loss: 3.2804 - accuracy: 0.3111 - val_loss: 8.2391 - val_accuracy: 0.1931\n",
            "Epoch 156/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.2749 - accuracy: 0.3112 - val_loss: 8.2500 - val_accuracy: 0.1947\n",
            "Epoch 157/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.2637 - accuracy: 0.3140 - val_loss: 8.2899 - val_accuracy: 0.1925\n",
            "Epoch 158/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.2572 - accuracy: 0.3133 - val_loss: 8.2840 - val_accuracy: 0.1923\n",
            "Epoch 159/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.2419 - accuracy: 0.3172 - val_loss: 8.2919 - val_accuracy: 0.1946\n",
            "Epoch 160/500\n",
            "79/79 [==============================] - 24s 305ms/step - loss: 3.2413 - accuracy: 0.3161 - val_loss: 8.3034 - val_accuracy: 0.1961\n",
            "Epoch 161/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.2310 - accuracy: 0.3180 - val_loss: 8.3464 - val_accuracy: 0.1962\n",
            "Epoch 162/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.2225 - accuracy: 0.3192 - val_loss: 8.3818 - val_accuracy: 0.1961\n",
            "Epoch 163/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 3.2187 - accuracy: 0.3188 - val_loss: 8.4056 - val_accuracy: 0.1960\n",
            "Epoch 164/500\n",
            "79/79 [==============================] - 13s 170ms/step - loss: 3.2064 - accuracy: 0.3221 - val_loss: 8.3479 - val_accuracy: 0.1966\n",
            "Epoch 165/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 3.1976 - accuracy: 0.3224 - val_loss: 8.3628 - val_accuracy: 0.1974\n",
            "Epoch 166/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 3.1888 - accuracy: 0.3240 - val_loss: 8.3992 - val_accuracy: 0.1988\n",
            "Epoch 167/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.1847 - accuracy: 0.3240 - val_loss: 8.3688 - val_accuracy: 0.1978\n",
            "Epoch 168/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.1770 - accuracy: 0.3253 - val_loss: 8.4126 - val_accuracy: 0.1977\n",
            "Epoch 169/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.1709 - accuracy: 0.3253 - val_loss: 8.4046 - val_accuracy: 0.1986\n",
            "Epoch 170/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.1642 - accuracy: 0.3269 - val_loss: 8.4264 - val_accuracy: 0.1982\n",
            "Epoch 171/500\n",
            "79/79 [==============================] - 16s 199ms/step - loss: 3.1521 - accuracy: 0.3284 - val_loss: 8.4131 - val_accuracy: 0.1995\n",
            "Epoch 172/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.1417 - accuracy: 0.3292 - val_loss: 8.4652 - val_accuracy: 0.1996\n",
            "Epoch 173/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.1341 - accuracy: 0.3316 - val_loss: 8.4588 - val_accuracy: 0.1997\n",
            "Epoch 174/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.1333 - accuracy: 0.3310 - val_loss: 8.4595 - val_accuracy: 0.2002\n",
            "Epoch 175/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 3.1252 - accuracy: 0.3314 - val_loss: 8.5035 - val_accuracy: 0.1996\n",
            "Epoch 176/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.1169 - accuracy: 0.3335 - val_loss: 8.4992 - val_accuracy: 0.1998\n",
            "Epoch 177/500\n",
            "79/79 [==============================] - 13s 166ms/step - loss: 3.1020 - accuracy: 0.3369 - val_loss: 8.5437 - val_accuracy: 0.2026\n",
            "Epoch 178/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.0991 - accuracy: 0.3359 - val_loss: 8.5080 - val_accuracy: 0.2025\n",
            "Epoch 179/500\n",
            "79/79 [==============================] - 13s 168ms/step - loss: 3.0907 - accuracy: 0.3352 - val_loss: 8.5278 - val_accuracy: 0.2031\n",
            "Epoch 180/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 3.0858 - accuracy: 0.3376 - val_loss: 8.5810 - val_accuracy: 0.2013\n",
            "Epoch 181/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.0839 - accuracy: 0.3384 - val_loss: 8.5581 - val_accuracy: 0.2020\n",
            "Epoch 182/500\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 3.0694 - accuracy: 0.3402 - val_loss: 8.5436 - val_accuracy: 0.2022\n",
            "Epoch 183/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 3.0574 - accuracy: 0.3418 - val_loss: 8.5859 - val_accuracy: 0.2042\n",
            "Epoch 184/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 3.0505 - accuracy: 0.3428 - val_loss: 8.6115 - val_accuracy: 0.2046\n",
            "Epoch 185/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.0496 - accuracy: 0.3440 - val_loss: 8.6394 - val_accuracy: 0.2039\n",
            "Epoch 186/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.0425 - accuracy: 0.3430 - val_loss: 8.6376 - val_accuracy: 0.2036\n",
            "Epoch 187/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.0325 - accuracy: 0.3455 - val_loss: 8.6557 - val_accuracy: 0.2044\n",
            "Epoch 188/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 3.0251 - accuracy: 0.3459 - val_loss: 8.6707 - val_accuracy: 0.2064\n",
            "Epoch 189/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 3.0191 - accuracy: 0.3475 - val_loss: 8.6865 - val_accuracy: 0.2066\n",
            "Epoch 190/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 3.0111 - accuracy: 0.3478 - val_loss: 8.6981 - val_accuracy: 0.2064\n",
            "Epoch 191/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 3.0101 - accuracy: 0.3485 - val_loss: 8.6641 - val_accuracy: 0.2052\n",
            "Epoch 192/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.9983 - accuracy: 0.3493 - val_loss: 8.7187 - val_accuracy: 0.2064\n",
            "Epoch 193/500\n",
            "79/79 [==============================] - 12s 157ms/step - loss: 2.9869 - accuracy: 0.3514 - val_loss: 8.6824 - val_accuracy: 0.2069\n",
            "Epoch 194/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.9825 - accuracy: 0.3524 - val_loss: 8.7274 - val_accuracy: 0.2057\n",
            "Epoch 195/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.9749 - accuracy: 0.3542 - val_loss: 8.6885 - val_accuracy: 0.2084\n",
            "Epoch 196/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.9709 - accuracy: 0.3544 - val_loss: 8.7771 - val_accuracy: 0.2068\n",
            "Epoch 197/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.9635 - accuracy: 0.3550 - val_loss: 8.7760 - val_accuracy: 0.2076\n",
            "Epoch 198/500\n",
            "79/79 [==============================] - 12s 158ms/step - loss: 2.9602 - accuracy: 0.3562 - val_loss: 8.7549 - val_accuracy: 0.2094\n",
            "Epoch 199/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.9500 - accuracy: 0.3558 - val_loss: 8.7347 - val_accuracy: 0.2105\n",
            "Epoch 200/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.9430 - accuracy: 0.3571 - val_loss: 8.7642 - val_accuracy: 0.2103\n",
            "Epoch 201/500\n",
            "79/79 [==============================] - 13s 159ms/step - loss: 2.9356 - accuracy: 0.3599 - val_loss: 8.8062 - val_accuracy: 0.2118\n",
            "Epoch 202/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.9265 - accuracy: 0.3592 - val_loss: 8.8301 - val_accuracy: 0.2096\n",
            "Epoch 203/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.9211 - accuracy: 0.3620 - val_loss: 8.8271 - val_accuracy: 0.2090\n",
            "Epoch 204/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.9160 - accuracy: 0.3623 - val_loss: 8.8021 - val_accuracy: 0.2116\n",
            "Epoch 205/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.9187 - accuracy: 0.3619 - val_loss: 8.8263 - val_accuracy: 0.2131\n",
            "Epoch 206/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.9001 - accuracy: 0.3634 - val_loss: 8.8287 - val_accuracy: 0.2129\n",
            "Epoch 207/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.8948 - accuracy: 0.3657 - val_loss: 8.8679 - val_accuracy: 0.2112\n",
            "Epoch 208/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.8925 - accuracy: 0.3658 - val_loss: 8.8841 - val_accuracy: 0.2131\n",
            "Epoch 209/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.8843 - accuracy: 0.3668 - val_loss: 8.9145 - val_accuracy: 0.2125\n",
            "Epoch 210/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.8790 - accuracy: 0.3661 - val_loss: 8.8862 - val_accuracy: 0.2138\n",
            "Epoch 211/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.8766 - accuracy: 0.3676 - val_loss: 8.8961 - val_accuracy: 0.2127\n",
            "Epoch 212/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.8614 - accuracy: 0.3701 - val_loss: 8.9127 - val_accuracy: 0.2137\n",
            "Epoch 213/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.8625 - accuracy: 0.3702 - val_loss: 8.9275 - val_accuracy: 0.2134\n",
            "Epoch 214/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.8548 - accuracy: 0.3708 - val_loss: 8.9677 - val_accuracy: 0.2143\n",
            "Epoch 215/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.8500 - accuracy: 0.3712 - val_loss: 8.9890 - val_accuracy: 0.2162\n",
            "Epoch 216/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.8448 - accuracy: 0.3726 - val_loss: 8.9936 - val_accuracy: 0.2154\n",
            "Epoch 217/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.8399 - accuracy: 0.3730 - val_loss: 8.9614 - val_accuracy: 0.2152\n",
            "Epoch 218/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.8284 - accuracy: 0.3759 - val_loss: 9.0273 - val_accuracy: 0.2173\n",
            "Epoch 219/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.8279 - accuracy: 0.3758 - val_loss: 9.0019 - val_accuracy: 0.2170\n",
            "Epoch 220/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.8172 - accuracy: 0.3769 - val_loss: 8.9740 - val_accuracy: 0.2173\n",
            "Epoch 221/500\n",
            "79/79 [==============================] - 12s 157ms/step - loss: 2.8091 - accuracy: 0.3776 - val_loss: 9.0449 - val_accuracy: 0.2175\n",
            "Epoch 222/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.8018 - accuracy: 0.3787 - val_loss: 8.9856 - val_accuracy: 0.2185\n",
            "Epoch 223/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.7982 - accuracy: 0.3804 - val_loss: 9.0661 - val_accuracy: 0.2184\n",
            "Epoch 224/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.7968 - accuracy: 0.3791 - val_loss: 9.0386 - val_accuracy: 0.2184\n",
            "Epoch 225/500\n",
            "79/79 [==============================] - 12s 157ms/step - loss: 2.7855 - accuracy: 0.3809 - val_loss: 9.0629 - val_accuracy: 0.2196\n",
            "Epoch 226/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.7806 - accuracy: 0.3823 - val_loss: 9.0622 - val_accuracy: 0.2210\n",
            "Epoch 227/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.7734 - accuracy: 0.3843 - val_loss: 9.1244 - val_accuracy: 0.2199\n",
            "Epoch 228/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.7688 - accuracy: 0.3836 - val_loss: 9.0707 - val_accuracy: 0.2206\n",
            "Epoch 229/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.7654 - accuracy: 0.3846 - val_loss: 9.1068 - val_accuracy: 0.2208\n",
            "Epoch 230/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.7580 - accuracy: 0.3858 - val_loss: 9.1261 - val_accuracy: 0.2218\n",
            "Epoch 231/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.7567 - accuracy: 0.3852 - val_loss: 9.0739 - val_accuracy: 0.2212\n",
            "Epoch 232/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 2.7441 - accuracy: 0.3889 - val_loss: 9.1481 - val_accuracy: 0.2220\n",
            "Epoch 233/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.7423 - accuracy: 0.3883 - val_loss: 9.1210 - val_accuracy: 0.2217\n",
            "Epoch 234/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.7375 - accuracy: 0.3879 - val_loss: 9.1604 - val_accuracy: 0.2219\n",
            "Epoch 235/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.7289 - accuracy: 0.3900 - val_loss: 9.1654 - val_accuracy: 0.2228\n",
            "Epoch 236/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.7219 - accuracy: 0.3904 - val_loss: 9.1806 - val_accuracy: 0.2225\n",
            "Epoch 237/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.7169 - accuracy: 0.3929 - val_loss: 9.1830 - val_accuracy: 0.2239\n",
            "Epoch 238/500\n",
            "79/79 [==============================] - 12s 148ms/step - loss: 2.7133 - accuracy: 0.3929 - val_loss: 9.1944 - val_accuracy: 0.2250\n",
            "Epoch 239/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.7077 - accuracy: 0.3943 - val_loss: 9.1873 - val_accuracy: 0.2230\n",
            "Epoch 240/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.7053 - accuracy: 0.3931 - val_loss: 9.2098 - val_accuracy: 0.2248\n",
            "Epoch 241/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.6949 - accuracy: 0.3956 - val_loss: 9.2008 - val_accuracy: 0.2251\n",
            "Epoch 242/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.6902 - accuracy: 0.3959 - val_loss: 9.2065 - val_accuracy: 0.2250\n",
            "Epoch 243/500\n",
            "79/79 [==============================] - 12s 158ms/step - loss: 2.6894 - accuracy: 0.3968 - val_loss: 9.1890 - val_accuracy: 0.2258\n",
            "Epoch 244/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.6806 - accuracy: 0.3976 - val_loss: 9.2203 - val_accuracy: 0.2259\n",
            "Epoch 245/500\n",
            "79/79 [==============================] - 13s 158ms/step - loss: 2.6763 - accuracy: 0.3996 - val_loss: 9.2213 - val_accuracy: 0.2269\n",
            "Epoch 246/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.6690 - accuracy: 0.3998 - val_loss: 9.2275 - val_accuracy: 0.2266\n",
            "Epoch 247/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.6624 - accuracy: 0.4006 - val_loss: 9.2676 - val_accuracy: 0.2267\n",
            "Epoch 248/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.6632 - accuracy: 0.4003 - val_loss: 9.2756 - val_accuracy: 0.2265\n",
            "Epoch 249/500\n",
            "79/79 [==============================] - 12s 157ms/step - loss: 2.6537 - accuracy: 0.4021 - val_loss: 9.3187 - val_accuracy: 0.2279\n",
            "Epoch 250/500\n",
            "79/79 [==============================] - 12s 148ms/step - loss: 2.6510 - accuracy: 0.4041 - val_loss: 9.3433 - val_accuracy: 0.2288\n",
            "Epoch 251/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.6453 - accuracy: 0.4036 - val_loss: 9.3185 - val_accuracy: 0.2288\n",
            "Epoch 252/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.6423 - accuracy: 0.4029 - val_loss: 9.3167 - val_accuracy: 0.2282\n",
            "Epoch 253/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.6354 - accuracy: 0.4051 - val_loss: 9.3486 - val_accuracy: 0.2283\n",
            "Epoch 254/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.6311 - accuracy: 0.4057 - val_loss: 9.2947 - val_accuracy: 0.2304\n",
            "Epoch 255/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.6228 - accuracy: 0.4082 - val_loss: 9.3067 - val_accuracy: 0.2292\n",
            "Epoch 256/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.6166 - accuracy: 0.4074 - val_loss: 9.4049 - val_accuracy: 0.2291\n",
            "Epoch 257/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 2.6173 - accuracy: 0.4091 - val_loss: 9.3704 - val_accuracy: 0.2305\n",
            "Epoch 258/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.6032 - accuracy: 0.4109 - val_loss: 9.3600 - val_accuracy: 0.2330\n",
            "Epoch 259/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.6052 - accuracy: 0.4096 - val_loss: 9.4549 - val_accuracy: 0.2312\n",
            "Epoch 260/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.5996 - accuracy: 0.4105 - val_loss: 9.3899 - val_accuracy: 0.2314\n",
            "Epoch 261/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.5889 - accuracy: 0.4134 - val_loss: 9.4280 - val_accuracy: 0.2327\n",
            "Epoch 262/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.5898 - accuracy: 0.4117 - val_loss: 9.3990 - val_accuracy: 0.2305\n",
            "Epoch 263/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.5825 - accuracy: 0.4136 - val_loss: 9.3757 - val_accuracy: 0.2326\n",
            "Epoch 264/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.5816 - accuracy: 0.4138 - val_loss: 9.4805 - val_accuracy: 0.2332\n",
            "Epoch 265/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.5755 - accuracy: 0.4141 - val_loss: 9.3710 - val_accuracy: 0.2330\n",
            "Epoch 266/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.5735 - accuracy: 0.4155 - val_loss: 9.4046 - val_accuracy: 0.2326\n",
            "Epoch 267/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.5661 - accuracy: 0.4150 - val_loss: 9.4112 - val_accuracy: 0.2344\n",
            "Epoch 268/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.5656 - accuracy: 0.4158 - val_loss: 9.4294 - val_accuracy: 0.2344\n",
            "Epoch 269/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.5542 - accuracy: 0.4180 - val_loss: 9.4869 - val_accuracy: 0.2348\n",
            "Epoch 270/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.5471 - accuracy: 0.4197 - val_loss: 9.5097 - val_accuracy: 0.2359\n",
            "Epoch 271/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.5493 - accuracy: 0.4189 - val_loss: 9.4509 - val_accuracy: 0.2355\n",
            "Epoch 272/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.5427 - accuracy: 0.4211 - val_loss: 9.5215 - val_accuracy: 0.2352\n",
            "Epoch 273/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.5411 - accuracy: 0.4200 - val_loss: 9.5369 - val_accuracy: 0.2344\n",
            "Epoch 274/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.5304 - accuracy: 0.4222 - val_loss: 9.5047 - val_accuracy: 0.2352\n",
            "Epoch 275/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.5300 - accuracy: 0.4224 - val_loss: 9.5431 - val_accuracy: 0.2357\n",
            "Epoch 276/500\n",
            "79/79 [==============================] - 13s 159ms/step - loss: 2.5266 - accuracy: 0.4232 - val_loss: 9.5039 - val_accuracy: 0.2369\n",
            "Epoch 277/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.5156 - accuracy: 0.4240 - val_loss: 9.5225 - val_accuracy: 0.2349\n",
            "Epoch 278/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.5148 - accuracy: 0.4247 - val_loss: 9.5239 - val_accuracy: 0.2376\n",
            "Epoch 279/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.5036 - accuracy: 0.4261 - val_loss: 9.5758 - val_accuracy: 0.2361\n",
            "Epoch 280/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.5004 - accuracy: 0.4259 - val_loss: 9.5845 - val_accuracy: 0.2394\n",
            "Epoch 281/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.4996 - accuracy: 0.4270 - val_loss: 9.6363 - val_accuracy: 0.2380\n",
            "Epoch 282/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.4985 - accuracy: 0.4265 - val_loss: 9.5687 - val_accuracy: 0.2382\n",
            "Epoch 283/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.4879 - accuracy: 0.4294 - val_loss: 9.5546 - val_accuracy: 0.2377\n",
            "Epoch 284/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.4906 - accuracy: 0.4284 - val_loss: 9.6208 - val_accuracy: 0.2396\n",
            "Epoch 285/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.4825 - accuracy: 0.4290 - val_loss: 9.5967 - val_accuracy: 0.2410\n",
            "Epoch 286/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.4744 - accuracy: 0.4313 - val_loss: 9.6406 - val_accuracy: 0.2397\n",
            "Epoch 287/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.4735 - accuracy: 0.4327 - val_loss: 9.6290 - val_accuracy: 0.2406\n",
            "Epoch 288/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.4714 - accuracy: 0.4310 - val_loss: 9.6227 - val_accuracy: 0.2409\n",
            "Epoch 289/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.4660 - accuracy: 0.4328 - val_loss: 9.6245 - val_accuracy: 0.2404\n",
            "Epoch 290/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.4599 - accuracy: 0.4333 - val_loss: 9.6685 - val_accuracy: 0.2419\n",
            "Epoch 291/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.4596 - accuracy: 0.4340 - val_loss: 9.5844 - val_accuracy: 0.2412\n",
            "Epoch 292/500\n",
            "79/79 [==============================] - 12s 158ms/step - loss: 2.4559 - accuracy: 0.4335 - val_loss: 9.6515 - val_accuracy: 0.2424\n",
            "Epoch 293/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.4513 - accuracy: 0.4349 - val_loss: 9.6823 - val_accuracy: 0.2427\n",
            "Epoch 294/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.4394 - accuracy: 0.4374 - val_loss: 9.6615 - val_accuracy: 0.2415\n",
            "Epoch 295/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.4408 - accuracy: 0.4388 - val_loss: 9.6634 - val_accuracy: 0.2421\n",
            "Epoch 296/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.4333 - accuracy: 0.4373 - val_loss: 9.7053 - val_accuracy: 0.2433\n",
            "Epoch 297/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.4264 - accuracy: 0.4406 - val_loss: 9.6496 - val_accuracy: 0.2432\n",
            "Epoch 298/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.4195 - accuracy: 0.4398 - val_loss: 9.7004 - val_accuracy: 0.2426\n",
            "Epoch 299/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.4180 - accuracy: 0.4406 - val_loss: 9.7232 - val_accuracy: 0.2428\n",
            "Epoch 300/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.4211 - accuracy: 0.4402 - val_loss: 9.7486 - val_accuracy: 0.2403\n",
            "Epoch 301/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.4130 - accuracy: 0.4421 - val_loss: 9.7200 - val_accuracy: 0.2450\n",
            "Epoch 302/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.4156 - accuracy: 0.4420 - val_loss: 9.7134 - val_accuracy: 0.2443\n",
            "Epoch 303/500\n",
            "79/79 [==============================] - 12s 158ms/step - loss: 2.4083 - accuracy: 0.4433 - val_loss: 9.7817 - val_accuracy: 0.2455\n",
            "Epoch 304/500\n",
            "79/79 [==============================] - 12s 148ms/step - loss: 2.4021 - accuracy: 0.4439 - val_loss: 9.7306 - val_accuracy: 0.2455\n",
            "Epoch 305/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.3993 - accuracy: 0.4444 - val_loss: 9.7409 - val_accuracy: 0.2456\n",
            "Epoch 306/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.3963 - accuracy: 0.4451 - val_loss: 9.7807 - val_accuracy: 0.2441\n",
            "Epoch 307/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.3903 - accuracy: 0.4456 - val_loss: 9.8118 - val_accuracy: 0.2439\n",
            "Epoch 308/500\n",
            "79/79 [==============================] - 12s 157ms/step - loss: 2.3849 - accuracy: 0.4471 - val_loss: 9.8091 - val_accuracy: 0.2463\n",
            "Epoch 309/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.3834 - accuracy: 0.4465 - val_loss: 9.8662 - val_accuracy: 0.2456\n",
            "Epoch 310/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.3815 - accuracy: 0.4469 - val_loss: 9.8013 - val_accuracy: 0.2459\n",
            "Epoch 311/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.3723 - accuracy: 0.4492 - val_loss: 9.8258 - val_accuracy: 0.2454\n",
            "Epoch 312/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.3740 - accuracy: 0.4476 - val_loss: 9.8332 - val_accuracy: 0.2454\n",
            "Epoch 313/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.3737 - accuracy: 0.4485 - val_loss: 9.7949 - val_accuracy: 0.2458\n",
            "Epoch 314/500\n",
            "79/79 [==============================] - 13s 162ms/step - loss: 2.3632 - accuracy: 0.4484 - val_loss: 9.8133 - val_accuracy: 0.2476\n",
            "Epoch 315/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.3624 - accuracy: 0.4498 - val_loss: 9.8626 - val_accuracy: 0.2475\n",
            "Epoch 316/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.3606 - accuracy: 0.4503 - val_loss: 9.8640 - val_accuracy: 0.2473\n",
            "Epoch 317/500\n",
            "79/79 [==============================] - 13s 159ms/step - loss: 2.3540 - accuracy: 0.4510 - val_loss: 9.8205 - val_accuracy: 0.2483\n",
            "Epoch 318/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.3500 - accuracy: 0.4524 - val_loss: 9.8081 - val_accuracy: 0.2480\n",
            "Epoch 319/500\n",
            "79/79 [==============================] - 35s 446ms/step - loss: 2.3379 - accuracy: 0.4554 - val_loss: 9.8717 - val_accuracy: 0.2489\n",
            "Epoch 320/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.3453 - accuracy: 0.4526 - val_loss: 9.8147 - val_accuracy: 0.2482\n",
            "Epoch 321/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.3382 - accuracy: 0.4545 - val_loss: 9.8966 - val_accuracy: 0.2500\n",
            "Epoch 322/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.3396 - accuracy: 0.4537 - val_loss: 9.8468 - val_accuracy: 0.2499\n",
            "Epoch 323/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.3243 - accuracy: 0.4568 - val_loss: 9.8563 - val_accuracy: 0.2490\n",
            "Epoch 324/500\n",
            "79/79 [==============================] - 13s 159ms/step - loss: 2.3240 - accuracy: 0.4576 - val_loss: 9.9201 - val_accuracy: 0.2505\n",
            "Epoch 325/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.3241 - accuracy: 0.4561 - val_loss: 9.8779 - val_accuracy: 0.2514\n",
            "Epoch 326/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.3211 - accuracy: 0.4569 - val_loss: 9.9626 - val_accuracy: 0.2508\n",
            "Epoch 327/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.3179 - accuracy: 0.4584 - val_loss: 9.9064 - val_accuracy: 0.2509\n",
            "Epoch 328/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.3183 - accuracy: 0.4574 - val_loss: 9.9939 - val_accuracy: 0.2491\n",
            "Epoch 329/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.3103 - accuracy: 0.4583 - val_loss: 9.9433 - val_accuracy: 0.2510\n",
            "Epoch 330/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.3030 - accuracy: 0.4606 - val_loss: 9.9306 - val_accuracy: 0.2513\n",
            "Epoch 331/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.3003 - accuracy: 0.4620 - val_loss: 9.9211 - val_accuracy: 0.2523\n",
            "Epoch 332/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.2999 - accuracy: 0.4612 - val_loss: 9.9429 - val_accuracy: 0.2516\n",
            "Epoch 333/500\n",
            "79/79 [==============================] - 12s 157ms/step - loss: 2.3021 - accuracy: 0.4602 - val_loss: 9.9432 - val_accuracy: 0.2524\n",
            "Epoch 334/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.2923 - accuracy: 0.4634 - val_loss: 10.0233 - val_accuracy: 0.2524\n",
            "Epoch 335/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 2.2923 - accuracy: 0.4611 - val_loss: 9.9510 - val_accuracy: 0.2528\n",
            "Epoch 336/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.2882 - accuracy: 0.4631 - val_loss: 9.9673 - val_accuracy: 0.2526\n",
            "Epoch 337/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.2774 - accuracy: 0.4650 - val_loss: 10.0051 - val_accuracy: 0.2532\n",
            "Epoch 338/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.2725 - accuracy: 0.4664 - val_loss: 9.9495 - val_accuracy: 0.2530\n",
            "Epoch 339/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 2.2777 - accuracy: 0.4646 - val_loss: 9.9400 - val_accuracy: 0.2534\n",
            "Epoch 340/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.2674 - accuracy: 0.4667 - val_loss: 10.0891 - val_accuracy: 0.2527\n",
            "Epoch 341/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.2727 - accuracy: 0.4647 - val_loss: 10.0014 - val_accuracy: 0.2543\n",
            "Epoch 342/500\n",
            "79/79 [==============================] - 11s 146ms/step - loss: 2.2599 - accuracy: 0.4686 - val_loss: 9.9663 - val_accuracy: 0.2549\n",
            "Epoch 343/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.2536 - accuracy: 0.4699 - val_loss: 10.0065 - val_accuracy: 0.2555\n",
            "Epoch 344/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.2550 - accuracy: 0.4698 - val_loss: 9.9964 - val_accuracy: 0.2555\n",
            "Epoch 345/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 2.2514 - accuracy: 0.4684 - val_loss: 10.0088 - val_accuracy: 0.2559\n",
            "Epoch 346/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.2501 - accuracy: 0.4705 - val_loss: 10.0120 - val_accuracy: 0.2566\n",
            "Epoch 347/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.2443 - accuracy: 0.4718 - val_loss: 10.0309 - val_accuracy: 0.2564\n",
            "Epoch 348/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 2.2426 - accuracy: 0.4720 - val_loss: 10.0420 - val_accuracy: 0.2572\n",
            "Epoch 349/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.2417 - accuracy: 0.4715 - val_loss: 10.0444 - val_accuracy: 0.2577\n",
            "Epoch 350/500\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 2.2403 - accuracy: 0.4718 - val_loss: 10.0308 - val_accuracy: 0.2561\n",
            "Epoch 351/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.2299 - accuracy: 0.4728 - val_loss: 10.0385 - val_accuracy: 0.2564\n",
            "Epoch 352/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.2311 - accuracy: 0.4735 - val_loss: 10.0243 - val_accuracy: 0.2567\n",
            "Epoch 353/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.2282 - accuracy: 0.4741 - val_loss: 10.0639 - val_accuracy: 0.2566\n",
            "Epoch 354/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.2213 - accuracy: 0.4752 - val_loss: 10.0722 - val_accuracy: 0.2573\n",
            "Epoch 355/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.2146 - accuracy: 0.4768 - val_loss: 10.0981 - val_accuracy: 0.2582\n",
            "Epoch 356/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.2143 - accuracy: 0.4753 - val_loss: 10.1008 - val_accuracy: 0.2584\n",
            "Epoch 357/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.2149 - accuracy: 0.4772 - val_loss: 10.1444 - val_accuracy: 0.2585\n",
            "Epoch 358/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.2125 - accuracy: 0.4763 - val_loss: 10.0919 - val_accuracy: 0.2593\n",
            "Epoch 359/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.2049 - accuracy: 0.4778 - val_loss: 10.0986 - val_accuracy: 0.2595\n",
            "Epoch 360/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.2026 - accuracy: 0.4783 - val_loss: 10.1309 - val_accuracy: 0.2585\n",
            "Epoch 361/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.2010 - accuracy: 0.4788 - val_loss: 10.1089 - val_accuracy: 0.2564\n",
            "Epoch 362/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 2.1962 - accuracy: 0.4795 - val_loss: 10.1918 - val_accuracy: 0.2598\n",
            "Epoch 363/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 2.1943 - accuracy: 0.4803 - val_loss: 10.1488 - val_accuracy: 0.2602\n",
            "Epoch 364/500\n",
            "79/79 [==============================] - 12s 148ms/step - loss: 2.1922 - accuracy: 0.4812 - val_loss: 10.1303 - val_accuracy: 0.2603\n",
            "Epoch 365/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.1911 - accuracy: 0.4803 - val_loss: 10.1470 - val_accuracy: 0.2609\n",
            "Epoch 366/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.1857 - accuracy: 0.4818 - val_loss: 10.1928 - val_accuracy: 0.2602\n",
            "Epoch 367/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.1841 - accuracy: 0.4816 - val_loss: 10.1582 - val_accuracy: 0.2599\n",
            "Epoch 368/500\n",
            "79/79 [==============================] - 13s 161ms/step - loss: 2.1753 - accuracy: 0.4834 - val_loss: 10.2242 - val_accuracy: 0.2614\n",
            "Epoch 369/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.1786 - accuracy: 0.4831 - val_loss: 10.1226 - val_accuracy: 0.2626\n",
            "Epoch 370/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.1676 - accuracy: 0.4865 - val_loss: 10.1600 - val_accuracy: 0.2616\n",
            "Epoch 371/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.1678 - accuracy: 0.4851 - val_loss: 10.1137 - val_accuracy: 0.2609\n",
            "Epoch 372/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.1632 - accuracy: 0.4852 - val_loss: 10.2039 - val_accuracy: 0.2619\n",
            "Epoch 373/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.1590 - accuracy: 0.4862 - val_loss: 10.1973 - val_accuracy: 0.2635\n",
            "Epoch 374/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.1621 - accuracy: 0.4857 - val_loss: 10.1666 - val_accuracy: 0.2613\n",
            "Epoch 375/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 2.1512 - accuracy: 0.4878 - val_loss: 10.1390 - val_accuracy: 0.2637\n",
            "Epoch 376/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.1522 - accuracy: 0.4878 - val_loss: 10.1638 - val_accuracy: 0.2623\n",
            "Epoch 377/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.1552 - accuracy: 0.4863 - val_loss: 10.2255 - val_accuracy: 0.2630\n",
            "Epoch 378/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.1502 - accuracy: 0.4866 - val_loss: 10.1766 - val_accuracy: 0.2627\n",
            "Epoch 379/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.1404 - accuracy: 0.4898 - val_loss: 10.2456 - val_accuracy: 0.2615\n",
            "Epoch 380/500\n",
            "79/79 [==============================] - 12s 158ms/step - loss: 2.1420 - accuracy: 0.4895 - val_loss: 10.2466 - val_accuracy: 0.2638\n",
            "Epoch 381/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.1360 - accuracy: 0.4907 - val_loss: 10.2387 - val_accuracy: 0.2639\n",
            "Epoch 382/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.1339 - accuracy: 0.4901 - val_loss: 10.2419 - val_accuracy: 0.2641\n",
            "Epoch 383/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.1355 - accuracy: 0.4915 - val_loss: 10.2209 - val_accuracy: 0.2653\n",
            "Epoch 384/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.1327 - accuracy: 0.4908 - val_loss: 10.2598 - val_accuracy: 0.2639\n",
            "Epoch 385/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.1282 - accuracy: 0.4932 - val_loss: 10.1895 - val_accuracy: 0.2619\n",
            "Epoch 386/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.1230 - accuracy: 0.4925 - val_loss: 10.2933 - val_accuracy: 0.2639\n",
            "Epoch 387/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.1280 - accuracy: 0.4920 - val_loss: 10.2473 - val_accuracy: 0.2651\n",
            "Epoch 388/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.1137 - accuracy: 0.4933 - val_loss: 10.2882 - val_accuracy: 0.2647\n",
            "Epoch 389/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 2.1128 - accuracy: 0.4955 - val_loss: 10.2890 - val_accuracy: 0.2661\n",
            "Epoch 390/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.1137 - accuracy: 0.4956 - val_loss: 10.2140 - val_accuracy: 0.2643\n",
            "Epoch 391/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.1130 - accuracy: 0.4947 - val_loss: 10.2447 - val_accuracy: 0.2647\n",
            "Epoch 392/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.1161 - accuracy: 0.4938 - val_loss: 10.3301 - val_accuracy: 0.2661\n",
            "Epoch 393/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.1024 - accuracy: 0.4973 - val_loss: 10.2735 - val_accuracy: 0.2671\n",
            "Epoch 394/500\n",
            "79/79 [==============================] - 12s 150ms/step - loss: 2.1002 - accuracy: 0.4972 - val_loss: 10.3080 - val_accuracy: 0.2657\n",
            "Epoch 395/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 2.0978 - accuracy: 0.4980 - val_loss: 10.2953 - val_accuracy: 0.2677\n",
            "Epoch 396/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.1020 - accuracy: 0.4966 - val_loss: 10.3773 - val_accuracy: 0.2660\n",
            "Epoch 397/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.0960 - accuracy: 0.4971 - val_loss: 10.2740 - val_accuracy: 0.2674\n",
            "Epoch 398/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0954 - accuracy: 0.4973 - val_loss: 10.3427 - val_accuracy: 0.2658\n",
            "Epoch 399/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0872 - accuracy: 0.4986 - val_loss: 10.2979 - val_accuracy: 0.2665\n",
            "Epoch 400/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0887 - accuracy: 0.4998 - val_loss: 10.2814 - val_accuracy: 0.2674\n",
            "Epoch 401/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.0781 - accuracy: 0.5002 - val_loss: 10.3929 - val_accuracy: 0.2686\n",
            "Epoch 402/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.0841 - accuracy: 0.4992 - val_loss: 10.3553 - val_accuracy: 0.2683\n",
            "Epoch 403/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0878 - accuracy: 0.4989 - val_loss: 10.3295 - val_accuracy: 0.2686\n",
            "Epoch 404/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.0786 - accuracy: 0.5029 - val_loss: 10.3528 - val_accuracy: 0.2689\n",
            "Epoch 405/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.0738 - accuracy: 0.5025 - val_loss: 10.3397 - val_accuracy: 0.2701\n",
            "Epoch 406/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.0655 - accuracy: 0.5047 - val_loss: 10.3206 - val_accuracy: 0.2678\n",
            "Epoch 407/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0669 - accuracy: 0.5045 - val_loss: 10.3638 - val_accuracy: 0.2699\n",
            "Epoch 408/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0671 - accuracy: 0.5040 - val_loss: 10.3200 - val_accuracy: 0.2691\n",
            "Epoch 409/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.0591 - accuracy: 0.5055 - val_loss: 10.3844 - val_accuracy: 0.2702\n",
            "Epoch 410/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 2.0612 - accuracy: 0.5050 - val_loss: 10.3127 - val_accuracy: 0.2702\n",
            "Epoch 411/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0557 - accuracy: 0.5050 - val_loss: 10.5059 - val_accuracy: 0.2691\n",
            "Epoch 412/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.0531 - accuracy: 0.5054 - val_loss: 10.4531 - val_accuracy: 0.2705\n",
            "Epoch 413/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.0506 - accuracy: 0.5082 - val_loss: 10.4132 - val_accuracy: 0.2715\n",
            "Epoch 414/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.0514 - accuracy: 0.5059 - val_loss: 10.4313 - val_accuracy: 0.2716\n",
            "Epoch 415/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.0500 - accuracy: 0.5061 - val_loss: 10.4210 - val_accuracy: 0.2700\n",
            "Epoch 416/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.0446 - accuracy: 0.5076 - val_loss: 10.4281 - val_accuracy: 0.2706\n",
            "Epoch 417/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0348 - accuracy: 0.5102 - val_loss: 10.3945 - val_accuracy: 0.2705\n",
            "Epoch 418/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0452 - accuracy: 0.5083 - val_loss: 10.4086 - val_accuracy: 0.2707\n",
            "Epoch 419/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0340 - accuracy: 0.5093 - val_loss: 10.3437 - val_accuracy: 0.2712\n",
            "Epoch 420/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 2.0314 - accuracy: 0.5115 - val_loss: 10.4212 - val_accuracy: 0.2721\n",
            "Epoch 421/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.0365 - accuracy: 0.5087 - val_loss: 10.4749 - val_accuracy: 0.2704\n",
            "Epoch 422/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0316 - accuracy: 0.5106 - val_loss: 10.3714 - val_accuracy: 0.2718\n",
            "Epoch 423/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0260 - accuracy: 0.5123 - val_loss: 10.4421 - val_accuracy: 0.2721\n",
            "Epoch 424/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 2.0290 - accuracy: 0.5108 - val_loss: 10.4512 - val_accuracy: 0.2718\n",
            "Epoch 425/500\n",
            "79/79 [==============================] - 12s 153ms/step - loss: 2.0251 - accuracy: 0.5112 - val_loss: 10.5065 - val_accuracy: 0.2725\n",
            "Epoch 426/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 2.0178 - accuracy: 0.5133 - val_loss: 10.4591 - val_accuracy: 0.2731\n",
            "Epoch 427/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0128 - accuracy: 0.5138 - val_loss: 10.4661 - val_accuracy: 0.2714\n",
            "Epoch 428/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.0206 - accuracy: 0.5125 - val_loss: 10.4892 - val_accuracy: 0.2718\n",
            "Epoch 429/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 2.0065 - accuracy: 0.5145 - val_loss: 10.4208 - val_accuracy: 0.2737\n",
            "Epoch 430/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 2.0150 - accuracy: 0.5129 - val_loss: 10.4274 - val_accuracy: 0.2739\n",
            "Epoch 431/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0098 - accuracy: 0.5131 - val_loss: 10.4608 - val_accuracy: 0.2734\n",
            "Epoch 432/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0010 - accuracy: 0.5164 - val_loss: 10.4504 - val_accuracy: 0.2736\n",
            "Epoch 433/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 2.0008 - accuracy: 0.5160 - val_loss: 10.5247 - val_accuracy: 0.2718\n",
            "Epoch 434/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.9997 - accuracy: 0.5156 - val_loss: 10.5029 - val_accuracy: 0.2738\n",
            "Epoch 435/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 1.9933 - accuracy: 0.5171 - val_loss: 10.4743 - val_accuracy: 0.2750\n",
            "Epoch 436/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 2.0014 - accuracy: 0.5151 - val_loss: 10.4950 - val_accuracy: 0.2741\n",
            "Epoch 437/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 1.9929 - accuracy: 0.5172 - val_loss: 10.5054 - val_accuracy: 0.2731\n",
            "Epoch 438/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9845 - accuracy: 0.5198 - val_loss: 10.4803 - val_accuracy: 0.2739\n",
            "Epoch 439/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 1.9848 - accuracy: 0.5192 - val_loss: 10.5538 - val_accuracy: 0.2740\n",
            "Epoch 440/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9819 - accuracy: 0.5198 - val_loss: 10.5608 - val_accuracy: 0.2747\n",
            "Epoch 441/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.9815 - accuracy: 0.5208 - val_loss: 10.5397 - val_accuracy: 0.2739\n",
            "Epoch 442/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 1.9806 - accuracy: 0.5205 - val_loss: 10.4915 - val_accuracy: 0.2755\n",
            "Epoch 443/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.9763 - accuracy: 0.5210 - val_loss: 10.5542 - val_accuracy: 0.2752\n",
            "Epoch 444/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9724 - accuracy: 0.5216 - val_loss: 10.6106 - val_accuracy: 0.2741\n",
            "Epoch 445/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 1.9690 - accuracy: 0.5211 - val_loss: 10.5661 - val_accuracy: 0.2758\n",
            "Epoch 446/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9733 - accuracy: 0.5210 - val_loss: 10.5110 - val_accuracy: 0.2751\n",
            "Epoch 447/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 1.9763 - accuracy: 0.5201 - val_loss: 10.5226 - val_accuracy: 0.2759\n",
            "Epoch 448/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 1.9654 - accuracy: 0.5218 - val_loss: 10.6113 - val_accuracy: 0.2760\n",
            "Epoch 449/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9640 - accuracy: 0.5227 - val_loss: 10.5980 - val_accuracy: 0.2769\n",
            "Epoch 450/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9594 - accuracy: 0.5237 - val_loss: 10.5882 - val_accuracy: 0.2765\n",
            "Epoch 451/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.9595 - accuracy: 0.5238 - val_loss: 10.5643 - val_accuracy: 0.2755\n",
            "Epoch 452/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 1.9527 - accuracy: 0.5257 - val_loss: 10.5055 - val_accuracy: 0.2761\n",
            "Epoch 453/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 1.9531 - accuracy: 0.5241 - val_loss: 10.6377 - val_accuracy: 0.2772\n",
            "Epoch 454/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 1.9473 - accuracy: 0.5270 - val_loss: 10.5651 - val_accuracy: 0.2775\n",
            "Epoch 455/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9469 - accuracy: 0.5261 - val_loss: 10.5519 - val_accuracy: 0.2754\n",
            "Epoch 456/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.9450 - accuracy: 0.5274 - val_loss: 10.6270 - val_accuracy: 0.2772\n",
            "Epoch 457/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9384 - accuracy: 0.5260 - val_loss: 10.6428 - val_accuracy: 0.2763\n",
            "Epoch 458/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9484 - accuracy: 0.5288 - val_loss: 10.6111 - val_accuracy: 0.2766\n",
            "Epoch 459/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 1.9431 - accuracy: 0.5265 - val_loss: 10.6283 - val_accuracy: 0.2774\n",
            "Epoch 460/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 1.9364 - accuracy: 0.5285 - val_loss: 10.5855 - val_accuracy: 0.2772\n",
            "Epoch 461/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 1.9355 - accuracy: 0.5285 - val_loss: 10.6114 - val_accuracy: 0.2778\n",
            "Epoch 462/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 1.9367 - accuracy: 0.5284 - val_loss: 10.6110 - val_accuracy: 0.2780\n",
            "Epoch 463/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 1.9230 - accuracy: 0.5299 - val_loss: 10.6591 - val_accuracy: 0.2776\n",
            "Epoch 464/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9297 - accuracy: 0.5294 - val_loss: 10.6953 - val_accuracy: 0.2779\n",
            "Epoch 465/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 1.9225 - accuracy: 0.5298 - val_loss: 10.5859 - val_accuracy: 0.2785\n",
            "Epoch 466/500\n",
            "79/79 [==============================] - 12s 146ms/step - loss: 1.9266 - accuracy: 0.5288 - val_loss: 10.5910 - val_accuracy: 0.2794\n",
            "Epoch 467/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.9180 - accuracy: 0.5329 - val_loss: 10.6977 - val_accuracy: 0.2785\n",
            "Epoch 468/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.9280 - accuracy: 0.5299 - val_loss: 10.6570 - val_accuracy: 0.2791\n",
            "Epoch 469/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.9191 - accuracy: 0.5310 - val_loss: 10.6800 - val_accuracy: 0.2790\n",
            "Epoch 470/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.9176 - accuracy: 0.5321 - val_loss: 10.7120 - val_accuracy: 0.2782\n",
            "Epoch 471/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 1.9162 - accuracy: 0.5308 - val_loss: 10.7001 - val_accuracy: 0.2781\n",
            "Epoch 472/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 1.9117 - accuracy: 0.5319 - val_loss: 10.6430 - val_accuracy: 0.2812\n",
            "Epoch 473/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.9129 - accuracy: 0.5327 - val_loss: 10.6916 - val_accuracy: 0.2810\n",
            "Epoch 474/500\n",
            "79/79 [==============================] - 11s 141ms/step - loss: 1.9081 - accuracy: 0.5338 - val_loss: 10.6723 - val_accuracy: 0.2810\n",
            "Epoch 475/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.9055 - accuracy: 0.5347 - val_loss: 10.7049 - val_accuracy: 0.2800\n",
            "Epoch 476/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 1.9037 - accuracy: 0.5337 - val_loss: 10.6594 - val_accuracy: 0.2809\n",
            "Epoch 477/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 1.9029 - accuracy: 0.5349 - val_loss: 10.6930 - val_accuracy: 0.2813\n",
            "Epoch 478/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 1.9038 - accuracy: 0.5337 - val_loss: 10.7195 - val_accuracy: 0.2810\n",
            "Epoch 479/500\n",
            "79/79 [==============================] - 12s 154ms/step - loss: 1.8995 - accuracy: 0.5359 - val_loss: 10.6863 - val_accuracy: 0.2815\n",
            "Epoch 480/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 1.8939 - accuracy: 0.5365 - val_loss: 10.6421 - val_accuracy: 0.2823\n",
            "Epoch 481/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 1.8913 - accuracy: 0.5369 - val_loss: 10.7777 - val_accuracy: 0.2803\n",
            "Epoch 482/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 1.8930 - accuracy: 0.5371 - val_loss: 10.7822 - val_accuracy: 0.2825\n",
            "Epoch 483/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 1.8893 - accuracy: 0.5377 - val_loss: 10.7114 - val_accuracy: 0.2826\n",
            "Epoch 484/500\n",
            "79/79 [==============================] - 12s 147ms/step - loss: 1.8862 - accuracy: 0.5379 - val_loss: 10.7201 - val_accuracy: 0.2826\n",
            "Epoch 485/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 1.8861 - accuracy: 0.5378 - val_loss: 10.7829 - val_accuracy: 0.2825\n",
            "Epoch 486/500\n",
            "79/79 [==============================] - 13s 159ms/step - loss: 1.8779 - accuracy: 0.5396 - val_loss: 10.7405 - val_accuracy: 0.2836\n",
            "Epoch 487/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.8822 - accuracy: 0.5388 - val_loss: 10.6976 - val_accuracy: 0.2827\n",
            "Epoch 488/500\n",
            "79/79 [==============================] - 12s 156ms/step - loss: 1.8769 - accuracy: 0.5409 - val_loss: 10.7353 - val_accuracy: 0.2842\n",
            "Epoch 489/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.8791 - accuracy: 0.5387 - val_loss: 10.7258 - val_accuracy: 0.2832\n",
            "Epoch 490/500\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 1.8729 - accuracy: 0.5413 - val_loss: 10.7818 - val_accuracy: 0.2827\n",
            "Epoch 491/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.8709 - accuracy: 0.5407 - val_loss: 10.7164 - val_accuracy: 0.2831\n",
            "Epoch 492/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.8672 - accuracy: 0.5419 - val_loss: 10.7762 - val_accuracy: 0.2837\n",
            "Epoch 493/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.8700 - accuracy: 0.5415 - val_loss: 10.8046 - val_accuracy: 0.2820\n",
            "Epoch 494/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.8668 - accuracy: 0.5423 - val_loss: 10.7935 - val_accuracy: 0.2821\n",
            "Epoch 495/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 1.8626 - accuracy: 0.5427 - val_loss: 10.7494 - val_accuracy: 0.2814\n",
            "Epoch 496/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 1.8638 - accuracy: 0.5430 - val_loss: 10.8428 - val_accuracy: 0.2841\n",
            "Epoch 497/500\n",
            "79/79 [==============================] - 11s 143ms/step - loss: 1.8624 - accuracy: 0.5430 - val_loss: 10.7187 - val_accuracy: 0.2842\n",
            "Epoch 498/500\n",
            "79/79 [==============================] - 12s 155ms/step - loss: 1.8579 - accuracy: 0.5434 - val_loss: 10.7991 - val_accuracy: 0.2857\n",
            "Epoch 499/500\n",
            "79/79 [==============================] - 11s 144ms/step - loss: 1.8583 - accuracy: 0.5441 - val_loss: 10.7729 - val_accuracy: 0.2848\n",
            "Epoch 500/500\n",
            "79/79 [==============================] - 11s 142ms/step - loss: 1.8547 - accuracy: 0.5454 - val_loss: 10.8240 - val_accuracy: 0.2854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7JOIgTU_-O-",
        "colab_type": "text"
      },
      "source": [
        "## V6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf8Xngj_75dc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d66b7d91-b2cc-4a40-cc15-462ffec9f0af"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(    \n",
        "    Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=embedding_matrix.shape[1],\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=True)\n",
        ")\n",
        "\n",
        "model.add(LSTM(256, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(LSTM(256))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(num_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXlm2KmaA17M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "591af86d-c424-42ed-fbae-f5d750c02cce"
      },
      "source": [
        "# model_filename = f'{DATASET}-custom-6.h5'\n",
        "# model_filepath = os.path.join(MODELS_DIR, model_filename)\n",
        "# print(model_filepath)\n",
        "# # model = load_model(model_filepath)\n",
        "\n",
        "# callbacks = [\n",
        "#     EarlyStopping(monitor='val_accuracy', patience=25),\n",
        "#     ModelCheckpoint(f'{model_filepath}', save_best_only=True, save_weights_only=False, monitor='val_accuracy')\n",
        "# ]\n",
        "\n",
        "# EPOCHS = 500\n",
        "\n",
        "# history = model.fit(\n",
        "#     X_train, \n",
        "#     y_train, \n",
        "#     epochs=EPOCHS, \n",
        "#     batch_size=2048, \n",
        "#     validation_data=(X_test, y_test), \n",
        "#     verbose=1,\n",
        "#     callbacks=callbacks\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/models/BBC-TECH-custom-6.h5\n",
            "Epoch 1/500\n",
            "79/79 [==============================] - 20s 248ms/step - loss: 7.4586 - accuracy: 0.0542 - val_loss: 7.0811 - val_accuracy: 0.0571\n",
            "Epoch 2/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 7.0214 - accuracy: 0.0578 - val_loss: 7.1018 - val_accuracy: 0.0571\n",
            "Epoch 3/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 7.0093 - accuracy: 0.0578 - val_loss: 7.0904 - val_accuracy: 0.0571\n",
            "Epoch 4/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 6.9560 - accuracy: 0.0578 - val_loss: 7.0012 - val_accuracy: 0.0571\n",
            "Epoch 5/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 6.8344 - accuracy: 0.0645 - val_loss: 6.8867 - val_accuracy: 0.0687\n",
            "Epoch 6/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 6.7128 - accuracy: 0.0708 - val_loss: 6.8140 - val_accuracy: 0.0748\n",
            "Epoch 7/500\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 6.6082 - accuracy: 0.0779 - val_loss: 6.7411 - val_accuracy: 0.0824\n",
            "Epoch 8/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 6.5148 - accuracy: 0.0841 - val_loss: 6.7005 - val_accuracy: 0.0853\n",
            "Epoch 9/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 6.4412 - accuracy: 0.0896 - val_loss: 6.6743 - val_accuracy: 0.0915\n",
            "Epoch 10/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 6.3718 - accuracy: 0.0945 - val_loss: 6.6419 - val_accuracy: 0.0949\n",
            "Epoch 11/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 6.3004 - accuracy: 0.0988 - val_loss: 6.6203 - val_accuracy: 0.0981\n",
            "Epoch 12/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 6.2320 - accuracy: 0.1037 - val_loss: 6.5936 - val_accuracy: 0.1018\n",
            "Epoch 13/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 6.1703 - accuracy: 0.1077 - val_loss: 6.5891 - val_accuracy: 0.1032\n",
            "Epoch 14/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 6.1134 - accuracy: 0.1104 - val_loss: 6.5788 - val_accuracy: 0.1059\n",
            "Epoch 15/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 6.0594 - accuracy: 0.1136 - val_loss: 6.5587 - val_accuracy: 0.1082\n",
            "Epoch 16/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 6.0047 - accuracy: 0.1164 - val_loss: 6.5494 - val_accuracy: 0.1096\n",
            "Epoch 17/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 5.9499 - accuracy: 0.1184 - val_loss: 6.5380 - val_accuracy: 0.1124\n",
            "Epoch 18/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 5.8939 - accuracy: 0.1212 - val_loss: 6.5290 - val_accuracy: 0.1134\n",
            "Epoch 19/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 5.8401 - accuracy: 0.1228 - val_loss: 6.5174 - val_accuracy: 0.1152\n",
            "Epoch 20/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 5.7851 - accuracy: 0.1251 - val_loss: 6.5008 - val_accuracy: 0.1184\n",
            "Epoch 21/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 5.7331 - accuracy: 0.1273 - val_loss: 6.4946 - val_accuracy: 0.1191\n",
            "Epoch 22/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 5.6861 - accuracy: 0.1290 - val_loss: 6.5001 - val_accuracy: 0.1188\n",
            "Epoch 23/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 5.6432 - accuracy: 0.1312 - val_loss: 6.4930 - val_accuracy: 0.1206\n",
            "Epoch 24/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 5.5991 - accuracy: 0.1331 - val_loss: 6.5043 - val_accuracy: 0.1215\n",
            "Epoch 25/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 5.5561 - accuracy: 0.1349 - val_loss: 6.5040 - val_accuracy: 0.1217\n",
            "Epoch 26/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 5.5158 - accuracy: 0.1358 - val_loss: 6.5041 - val_accuracy: 0.1240\n",
            "Epoch 27/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 5.4754 - accuracy: 0.1376 - val_loss: 6.5058 - val_accuracy: 0.1251\n",
            "Epoch 28/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 5.4358 - accuracy: 0.1392 - val_loss: 6.5136 - val_accuracy: 0.1265\n",
            "Epoch 29/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 5.3957 - accuracy: 0.1412 - val_loss: 6.5241 - val_accuracy: 0.1263\n",
            "Epoch 30/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 5.3590 - accuracy: 0.1427 - val_loss: 6.5288 - val_accuracy: 0.1270\n",
            "Epoch 31/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 5.3190 - accuracy: 0.1434 - val_loss: 6.5332 - val_accuracy: 0.1272\n",
            "Epoch 32/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 5.2857 - accuracy: 0.1452 - val_loss: 6.5388 - val_accuracy: 0.1296\n",
            "Epoch 33/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 5.2514 - accuracy: 0.1465 - val_loss: 6.5509 - val_accuracy: 0.1320\n",
            "Epoch 34/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 5.2130 - accuracy: 0.1483 - val_loss: 6.5694 - val_accuracy: 0.1308\n",
            "Epoch 35/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 5.1780 - accuracy: 0.1495 - val_loss: 6.5686 - val_accuracy: 0.1337\n",
            "Epoch 36/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 5.1464 - accuracy: 0.1502 - val_loss: 6.5770 - val_accuracy: 0.1322\n",
            "Epoch 37/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 5.1117 - accuracy: 0.1517 - val_loss: 6.5967 - val_accuracy: 0.1341\n",
            "Epoch 38/500\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 5.0814 - accuracy: 0.1545 - val_loss: 6.6026 - val_accuracy: 0.1351\n",
            "Epoch 39/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 5.0491 - accuracy: 0.1545 - val_loss: 6.6165 - val_accuracy: 0.1358\n",
            "Epoch 40/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 5.0164 - accuracy: 0.1557 - val_loss: 6.6307 - val_accuracy: 0.1353\n",
            "Epoch 41/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 4.9859 - accuracy: 0.1570 - val_loss: 6.6416 - val_accuracy: 0.1381\n",
            "Epoch 42/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 4.9563 - accuracy: 0.1587 - val_loss: 6.6430 - val_accuracy: 0.1388\n",
            "Epoch 43/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 4.9302 - accuracy: 0.1592 - val_loss: 6.6549 - val_accuracy: 0.1394\n",
            "Epoch 44/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 4.9015 - accuracy: 0.1610 - val_loss: 6.6740 - val_accuracy: 0.1397\n",
            "Epoch 45/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 4.8737 - accuracy: 0.1622 - val_loss: 6.6846 - val_accuracy: 0.1400\n",
            "Epoch 46/500\n",
            "79/79 [==============================] - 19s 242ms/step - loss: 4.8417 - accuracy: 0.1639 - val_loss: 6.6933 - val_accuracy: 0.1403\n",
            "Epoch 47/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 4.8140 - accuracy: 0.1666 - val_loss: 6.7232 - val_accuracy: 0.1409\n",
            "Epoch 48/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 4.7854 - accuracy: 0.1674 - val_loss: 6.7230 - val_accuracy: 0.1419\n",
            "Epoch 49/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 4.7608 - accuracy: 0.1683 - val_loss: 6.7354 - val_accuracy: 0.1418\n",
            "Epoch 50/500\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 4.7362 - accuracy: 0.1695 - val_loss: 6.7564 - val_accuracy: 0.1435\n",
            "Epoch 51/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 4.7086 - accuracy: 0.1714 - val_loss: 6.7570 - val_accuracy: 0.1445\n",
            "Epoch 52/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 4.6866 - accuracy: 0.1717 - val_loss: 6.7871 - val_accuracy: 0.1452\n",
            "Epoch 53/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 4.6577 - accuracy: 0.1736 - val_loss: 6.7920 - val_accuracy: 0.1460\n",
            "Epoch 54/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 4.6326 - accuracy: 0.1753 - val_loss: 6.8140 - val_accuracy: 0.1461\n",
            "Epoch 55/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 4.6077 - accuracy: 0.1764 - val_loss: 6.8193 - val_accuracy: 0.1470\n",
            "Epoch 56/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 4.5854 - accuracy: 0.1779 - val_loss: 6.8411 - val_accuracy: 0.1480\n",
            "Epoch 57/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 4.5602 - accuracy: 0.1791 - val_loss: 6.8531 - val_accuracy: 0.1479\n",
            "Epoch 58/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 4.5406 - accuracy: 0.1814 - val_loss: 6.8588 - val_accuracy: 0.1489\n",
            "Epoch 59/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 4.5122 - accuracy: 0.1824 - val_loss: 6.8771 - val_accuracy: 0.1501\n",
            "Epoch 60/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 4.4925 - accuracy: 0.1842 - val_loss: 6.8908 - val_accuracy: 0.1491\n",
            "Epoch 61/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 4.4723 - accuracy: 0.1856 - val_loss: 6.9064 - val_accuracy: 0.1508\n",
            "Epoch 62/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 4.4511 - accuracy: 0.1861 - val_loss: 6.9318 - val_accuracy: 0.1504\n",
            "Epoch 63/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 4.4288 - accuracy: 0.1881 - val_loss: 6.9305 - val_accuracy: 0.1499\n",
            "Epoch 64/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 4.4135 - accuracy: 0.1888 - val_loss: 6.9446 - val_accuracy: 0.1522\n",
            "Epoch 65/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 4.3917 - accuracy: 0.1906 - val_loss: 6.9750 - val_accuracy: 0.1495\n",
            "Epoch 66/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 4.3690 - accuracy: 0.1924 - val_loss: 6.9877 - val_accuracy: 0.1517\n",
            "Epoch 67/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 4.3505 - accuracy: 0.1938 - val_loss: 7.0011 - val_accuracy: 0.1522\n",
            "Epoch 68/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 4.3267 - accuracy: 0.1956 - val_loss: 7.0207 - val_accuracy: 0.1521\n",
            "Epoch 69/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 4.3116 - accuracy: 0.1971 - val_loss: 7.0337 - val_accuracy: 0.1527\n",
            "Epoch 70/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 4.2922 - accuracy: 0.1988 - val_loss: 7.0398 - val_accuracy: 0.1531\n",
            "Epoch 71/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 4.2694 - accuracy: 0.1995 - val_loss: 7.0545 - val_accuracy: 0.1549\n",
            "Epoch 72/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 4.2567 - accuracy: 0.2013 - val_loss: 7.0633 - val_accuracy: 0.1542\n",
            "Epoch 73/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 4.2382 - accuracy: 0.2025 - val_loss: 7.0786 - val_accuracy: 0.1554\n",
            "Epoch 74/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 4.2192 - accuracy: 0.2045 - val_loss: 7.1055 - val_accuracy: 0.1549\n",
            "Epoch 75/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 4.2027 - accuracy: 0.2050 - val_loss: 7.1307 - val_accuracy: 0.1561\n",
            "Epoch 76/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 4.1849 - accuracy: 0.2073 - val_loss: 7.1289 - val_accuracy: 0.1571\n",
            "Epoch 77/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 4.1693 - accuracy: 0.2080 - val_loss: 7.1468 - val_accuracy: 0.1564\n",
            "Epoch 78/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 4.1495 - accuracy: 0.2097 - val_loss: 7.1685 - val_accuracy: 0.1575\n",
            "Epoch 79/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 4.1378 - accuracy: 0.2116 - val_loss: 7.1587 - val_accuracy: 0.1589\n",
            "Epoch 80/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 4.1168 - accuracy: 0.2138 - val_loss: 7.1987 - val_accuracy: 0.1588\n",
            "Epoch 81/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 4.1005 - accuracy: 0.2146 - val_loss: 7.2216 - val_accuracy: 0.1577\n",
            "Epoch 82/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 4.0834 - accuracy: 0.2167 - val_loss: 7.2191 - val_accuracy: 0.1582\n",
            "Epoch 83/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 4.0702 - accuracy: 0.2168 - val_loss: 7.2393 - val_accuracy: 0.1581\n",
            "Epoch 84/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 4.0596 - accuracy: 0.2182 - val_loss: 7.2442 - val_accuracy: 0.1605\n",
            "Epoch 85/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 4.0394 - accuracy: 0.2211 - val_loss: 7.2747 - val_accuracy: 0.1594\n",
            "Epoch 86/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 4.0276 - accuracy: 0.2213 - val_loss: 7.2725 - val_accuracy: 0.1606\n",
            "Epoch 87/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 4.0118 - accuracy: 0.2232 - val_loss: 7.2834 - val_accuracy: 0.1617\n",
            "Epoch 88/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 3.9942 - accuracy: 0.2243 - val_loss: 7.2960 - val_accuracy: 0.1606\n",
            "Epoch 89/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.9787 - accuracy: 0.2263 - val_loss: 7.3291 - val_accuracy: 0.1606\n",
            "Epoch 90/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.9631 - accuracy: 0.2272 - val_loss: 7.3549 - val_accuracy: 0.1608\n",
            "Epoch 91/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 3.9532 - accuracy: 0.2288 - val_loss: 7.3700 - val_accuracy: 0.1642\n",
            "Epoch 92/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 3.9450 - accuracy: 0.2291 - val_loss: 7.3715 - val_accuracy: 0.1635\n",
            "Epoch 93/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.9302 - accuracy: 0.2307 - val_loss: 7.3922 - val_accuracy: 0.1641\n",
            "Epoch 94/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.9062 - accuracy: 0.2338 - val_loss: 7.3880 - val_accuracy: 0.1638\n",
            "Epoch 95/500\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 3.8976 - accuracy: 0.2340 - val_loss: 7.4292 - val_accuracy: 0.1648\n",
            "Epoch 96/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 3.8875 - accuracy: 0.2361 - val_loss: 7.4101 - val_accuracy: 0.1661\n",
            "Epoch 97/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.8704 - accuracy: 0.2376 - val_loss: 7.4345 - val_accuracy: 0.1648\n",
            "Epoch 98/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.8598 - accuracy: 0.2382 - val_loss: 7.4653 - val_accuracy: 0.1659\n",
            "Epoch 99/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 3.8441 - accuracy: 0.2410 - val_loss: 7.4854 - val_accuracy: 0.1674\n",
            "Epoch 100/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 3.8323 - accuracy: 0.2411 - val_loss: 7.4832 - val_accuracy: 0.1654\n",
            "Epoch 101/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 3.8212 - accuracy: 0.2429 - val_loss: 7.4937 - val_accuracy: 0.1667\n",
            "Epoch 102/500\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 3.8114 - accuracy: 0.2433 - val_loss: 7.5065 - val_accuracy: 0.1693\n",
            "Epoch 103/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.7917 - accuracy: 0.2454 - val_loss: 7.5367 - val_accuracy: 0.1667\n",
            "Epoch 104/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.7843 - accuracy: 0.2463 - val_loss: 7.5459 - val_accuracy: 0.1683\n",
            "Epoch 105/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.7682 - accuracy: 0.2474 - val_loss: 7.5627 - val_accuracy: 0.1682\n",
            "Epoch 106/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 3.7584 - accuracy: 0.2487 - val_loss: 7.5720 - val_accuracy: 0.1678\n",
            "Epoch 107/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.7501 - accuracy: 0.2505 - val_loss: 7.5966 - val_accuracy: 0.1694\n",
            "Epoch 108/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.7339 - accuracy: 0.2526 - val_loss: 7.6253 - val_accuracy: 0.1703\n",
            "Epoch 109/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.7244 - accuracy: 0.2526 - val_loss: 7.6017 - val_accuracy: 0.1690\n",
            "Epoch 110/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 3.7168 - accuracy: 0.2542 - val_loss: 7.6301 - val_accuracy: 0.1709\n",
            "Epoch 111/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 3.7006 - accuracy: 0.2556 - val_loss: 7.6517 - val_accuracy: 0.1703\n",
            "Epoch 112/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 3.6866 - accuracy: 0.2576 - val_loss: 7.6535 - val_accuracy: 0.1728\n",
            "Epoch 113/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 3.6780 - accuracy: 0.2586 - val_loss: 7.6921 - val_accuracy: 0.1735\n",
            "Epoch 114/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 3.6691 - accuracy: 0.2605 - val_loss: 7.6753 - val_accuracy: 0.1711\n",
            "Epoch 115/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 3.6540 - accuracy: 0.2619 - val_loss: 7.7012 - val_accuracy: 0.1726\n",
            "Epoch 116/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 3.6440 - accuracy: 0.2633 - val_loss: 7.7083 - val_accuracy: 0.1738\n",
            "Epoch 117/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 3.6396 - accuracy: 0.2645 - val_loss: 7.7157 - val_accuracy: 0.1738\n",
            "Epoch 118/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.6317 - accuracy: 0.2626 - val_loss: 7.7223 - val_accuracy: 0.1745\n",
            "Epoch 119/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 3.6170 - accuracy: 0.2652 - val_loss: 7.7525 - val_accuracy: 0.1746\n",
            "Epoch 120/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.6093 - accuracy: 0.2665 - val_loss: 7.7610 - val_accuracy: 0.1755\n",
            "Epoch 121/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.5966 - accuracy: 0.2687 - val_loss: 7.7763 - val_accuracy: 0.1762\n",
            "Epoch 122/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 3.5904 - accuracy: 0.2686 - val_loss: 7.7953 - val_accuracy: 0.1748\n",
            "Epoch 123/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 3.5754 - accuracy: 0.2715 - val_loss: 7.7988 - val_accuracy: 0.1765\n",
            "Epoch 124/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.5648 - accuracy: 0.2734 - val_loss: 7.8359 - val_accuracy: 0.1776\n",
            "Epoch 125/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 3.5559 - accuracy: 0.2724 - val_loss: 7.8297 - val_accuracy: 0.1761\n",
            "Epoch 126/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 3.5411 - accuracy: 0.2752 - val_loss: 7.8521 - val_accuracy: 0.1758\n",
            "Epoch 127/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.5412 - accuracy: 0.2751 - val_loss: 7.8759 - val_accuracy: 0.1761\n",
            "Epoch 128/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.5270 - accuracy: 0.2756 - val_loss: 7.8891 - val_accuracy: 0.1775\n",
            "Epoch 129/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 3.5164 - accuracy: 0.2786 - val_loss: 7.8873 - val_accuracy: 0.1784\n",
            "Epoch 130/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 3.5043 - accuracy: 0.2792 - val_loss: 7.8835 - val_accuracy: 0.1787\n",
            "Epoch 131/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.5012 - accuracy: 0.2786 - val_loss: 7.9168 - val_accuracy: 0.1766\n",
            "Epoch 132/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 3.4924 - accuracy: 0.2813 - val_loss: 7.9448 - val_accuracy: 0.1779\n",
            "Epoch 133/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 3.4790 - accuracy: 0.2823 - val_loss: 7.9437 - val_accuracy: 0.1786\n",
            "Epoch 134/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 3.4744 - accuracy: 0.2830 - val_loss: 7.9455 - val_accuracy: 0.1807\n",
            "Epoch 135/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.4579 - accuracy: 0.2857 - val_loss: 7.9490 - val_accuracy: 0.1808\n",
            "Epoch 136/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 3.4514 - accuracy: 0.2867 - val_loss: 7.9919 - val_accuracy: 0.1802\n",
            "Epoch 137/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 3.4426 - accuracy: 0.2869 - val_loss: 7.9693 - val_accuracy: 0.1822\n",
            "Epoch 138/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.4374 - accuracy: 0.2884 - val_loss: 8.0289 - val_accuracy: 0.1813\n",
            "Epoch 139/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 3.4224 - accuracy: 0.2906 - val_loss: 8.0119 - val_accuracy: 0.1831\n",
            "Epoch 140/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.4201 - accuracy: 0.2902 - val_loss: 8.0174 - val_accuracy: 0.1841\n",
            "Epoch 141/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.4048 - accuracy: 0.2929 - val_loss: 8.0419 - val_accuracy: 0.1845\n",
            "Epoch 142/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.3990 - accuracy: 0.2917 - val_loss: 8.0712 - val_accuracy: 0.1850\n",
            "Epoch 143/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 3.3897 - accuracy: 0.2943 - val_loss: 8.0816 - val_accuracy: 0.1838\n",
            "Epoch 144/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.3810 - accuracy: 0.2955 - val_loss: 8.0583 - val_accuracy: 0.1860\n",
            "Epoch 145/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 3.3723 - accuracy: 0.2985 - val_loss: 8.1151 - val_accuracy: 0.1849\n",
            "Epoch 146/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.3670 - accuracy: 0.2973 - val_loss: 8.1138 - val_accuracy: 0.1850\n",
            "Epoch 147/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 3.3584 - accuracy: 0.2974 - val_loss: 8.1273 - val_accuracy: 0.1843\n",
            "Epoch 148/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 3.3477 - accuracy: 0.2998 - val_loss: 8.1481 - val_accuracy: 0.1858\n",
            "Epoch 149/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.3388 - accuracy: 0.3013 - val_loss: 8.1533 - val_accuracy: 0.1857\n",
            "Epoch 150/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 3.3319 - accuracy: 0.3011 - val_loss: 8.1437 - val_accuracy: 0.1863\n",
            "Epoch 151/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 3.3255 - accuracy: 0.3029 - val_loss: 8.1540 - val_accuracy: 0.1869\n",
            "Epoch 152/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 3.3180 - accuracy: 0.3036 - val_loss: 8.1576 - val_accuracy: 0.1866\n",
            "Epoch 153/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 3.3104 - accuracy: 0.3036 - val_loss: 8.2231 - val_accuracy: 0.1875\n",
            "Epoch 154/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 3.3011 - accuracy: 0.3058 - val_loss: 8.2035 - val_accuracy: 0.1898\n",
            "Epoch 155/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 3.2952 - accuracy: 0.3074 - val_loss: 8.1987 - val_accuracy: 0.1887\n",
            "Epoch 156/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 3.2857 - accuracy: 0.3087 - val_loss: 8.2237 - val_accuracy: 0.1883\n",
            "Epoch 157/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 3.2768 - accuracy: 0.3086 - val_loss: 8.2660 - val_accuracy: 0.1898\n",
            "Epoch 158/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 3.2681 - accuracy: 0.3098 - val_loss: 8.2888 - val_accuracy: 0.1887\n",
            "Epoch 159/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.2588 - accuracy: 0.3107 - val_loss: 8.2615 - val_accuracy: 0.1890\n",
            "Epoch 160/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 3.2529 - accuracy: 0.3121 - val_loss: 8.2596 - val_accuracy: 0.1903\n",
            "Epoch 161/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 3.2500 - accuracy: 0.3128 - val_loss: 8.2804 - val_accuracy: 0.1904\n",
            "Epoch 162/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 3.2423 - accuracy: 0.3135 - val_loss: 8.2902 - val_accuracy: 0.1917\n",
            "Epoch 163/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 3.2315 - accuracy: 0.3165 - val_loss: 8.3155 - val_accuracy: 0.1898\n",
            "Epoch 164/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.2217 - accuracy: 0.3174 - val_loss: 8.3293 - val_accuracy: 0.1898\n",
            "Epoch 165/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 3.2199 - accuracy: 0.3165 - val_loss: 8.3340 - val_accuracy: 0.1903\n",
            "Epoch 166/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 3.2107 - accuracy: 0.3174 - val_loss: 8.3470 - val_accuracy: 0.1935\n",
            "Epoch 167/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.1989 - accuracy: 0.3205 - val_loss: 8.3278 - val_accuracy: 0.1918\n",
            "Epoch 168/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 3.2041 - accuracy: 0.3187 - val_loss: 8.3568 - val_accuracy: 0.1926\n",
            "Epoch 169/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 3.1880 - accuracy: 0.3201 - val_loss: 8.3848 - val_accuracy: 0.1937\n",
            "Epoch 170/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.1793 - accuracy: 0.3217 - val_loss: 8.3961 - val_accuracy: 0.1933\n",
            "Epoch 171/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 3.1763 - accuracy: 0.3225 - val_loss: 8.4237 - val_accuracy: 0.1948\n",
            "Epoch 172/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 3.1670 - accuracy: 0.3228 - val_loss: 8.4075 - val_accuracy: 0.1950\n",
            "Epoch 173/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.1664 - accuracy: 0.3240 - val_loss: 8.4368 - val_accuracy: 0.1946\n",
            "Epoch 174/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.1562 - accuracy: 0.3266 - val_loss: 8.4366 - val_accuracy: 0.1931\n",
            "Epoch 175/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 3.1522 - accuracy: 0.3255 - val_loss: 8.4557 - val_accuracy: 0.1941\n",
            "Epoch 176/500\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 3.1416 - accuracy: 0.3271 - val_loss: 8.4604 - val_accuracy: 0.1957\n",
            "Epoch 177/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 3.1326 - accuracy: 0.3286 - val_loss: 8.4897 - val_accuracy: 0.1950\n",
            "Epoch 178/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 3.1282 - accuracy: 0.3292 - val_loss: 8.4730 - val_accuracy: 0.1967\n",
            "Epoch 179/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 3.1240 - accuracy: 0.3301 - val_loss: 8.5109 - val_accuracy: 0.1968\n",
            "Epoch 180/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.1095 - accuracy: 0.3325 - val_loss: 8.5437 - val_accuracy: 0.1962\n",
            "Epoch 181/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 3.1070 - accuracy: 0.3334 - val_loss: 8.4887 - val_accuracy: 0.1969\n",
            "Epoch 182/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 3.1093 - accuracy: 0.3332 - val_loss: 8.5307 - val_accuracy: 0.1968\n",
            "Epoch 183/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 3.0961 - accuracy: 0.3343 - val_loss: 8.5251 - val_accuracy: 0.1969\n",
            "Epoch 184/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.0829 - accuracy: 0.3357 - val_loss: 8.5575 - val_accuracy: 0.1969\n",
            "Epoch 185/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 3.0855 - accuracy: 0.3364 - val_loss: 8.5805 - val_accuracy: 0.1976\n",
            "Epoch 186/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 3.0723 - accuracy: 0.3372 - val_loss: 8.5788 - val_accuracy: 0.1992\n",
            "Epoch 187/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 3.0719 - accuracy: 0.3375 - val_loss: 8.5798 - val_accuracy: 0.1987\n",
            "Epoch 188/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 3.0608 - accuracy: 0.3393 - val_loss: 8.6041 - val_accuracy: 0.1980\n",
            "Epoch 189/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 3.0545 - accuracy: 0.3405 - val_loss: 8.6018 - val_accuracy: 0.1997\n",
            "Epoch 190/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 3.0476 - accuracy: 0.3405 - val_loss: 8.6238 - val_accuracy: 0.1994\n",
            "Epoch 191/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 3.0420 - accuracy: 0.3426 - val_loss: 8.6228 - val_accuracy: 0.1997\n",
            "Epoch 192/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 3.0338 - accuracy: 0.3427 - val_loss: 8.6418 - val_accuracy: 0.2000\n",
            "Epoch 193/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 3.0355 - accuracy: 0.3417 - val_loss: 8.6453 - val_accuracy: 0.2006\n",
            "Epoch 194/500\n",
            "79/79 [==============================] - 19s 242ms/step - loss: 3.0263 - accuracy: 0.3454 - val_loss: 8.6583 - val_accuracy: 0.2008\n",
            "Epoch 195/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 3.0213 - accuracy: 0.3445 - val_loss: 8.6835 - val_accuracy: 0.2005\n",
            "Epoch 196/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 3.0127 - accuracy: 0.3475 - val_loss: 8.6916 - val_accuracy: 0.2007\n",
            "Epoch 197/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 3.0056 - accuracy: 0.3475 - val_loss: 8.7543 - val_accuracy: 0.2030\n",
            "Epoch 198/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.9997 - accuracy: 0.3485 - val_loss: 8.6686 - val_accuracy: 0.2020\n",
            "Epoch 199/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.9940 - accuracy: 0.3494 - val_loss: 8.7125 - val_accuracy: 0.2028\n",
            "Epoch 200/500\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 2.9915 - accuracy: 0.3494 - val_loss: 8.7135 - val_accuracy: 0.2038\n",
            "Epoch 201/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.9831 - accuracy: 0.3503 - val_loss: 8.7229 - val_accuracy: 0.2029\n",
            "Epoch 202/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 2.9763 - accuracy: 0.3514 - val_loss: 8.7269 - val_accuracy: 0.2036\n",
            "Epoch 203/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.9720 - accuracy: 0.3537 - val_loss: 8.7468 - val_accuracy: 0.2032\n",
            "Epoch 204/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.9659 - accuracy: 0.3532 - val_loss: 8.7677 - val_accuracy: 0.2043\n",
            "Epoch 205/500\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 2.9575 - accuracy: 0.3542 - val_loss: 8.7872 - val_accuracy: 0.2044\n",
            "Epoch 206/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.9552 - accuracy: 0.3554 - val_loss: 8.7699 - val_accuracy: 0.2046\n",
            "Epoch 207/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.9528 - accuracy: 0.3553 - val_loss: 8.7985 - val_accuracy: 0.2064\n",
            "Epoch 208/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.9435 - accuracy: 0.3558 - val_loss: 8.8078 - val_accuracy: 0.2071\n",
            "Epoch 209/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.9438 - accuracy: 0.3580 - val_loss: 8.7995 - val_accuracy: 0.2055\n",
            "Epoch 210/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.9275 - accuracy: 0.3592 - val_loss: 8.8106 - val_accuracy: 0.2059\n",
            "Epoch 211/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 2.9208 - accuracy: 0.3606 - val_loss: 8.8345 - val_accuracy: 0.2049\n",
            "Epoch 212/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.9204 - accuracy: 0.3613 - val_loss: 8.8145 - val_accuracy: 0.2065\n",
            "Epoch 213/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 2.9203 - accuracy: 0.3603 - val_loss: 8.8304 - val_accuracy: 0.2071\n",
            "Epoch 214/500\n",
            "79/79 [==============================] - 18s 228ms/step - loss: 2.9070 - accuracy: 0.3628 - val_loss: 8.8261 - val_accuracy: 0.2073\n",
            "Epoch 215/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.9014 - accuracy: 0.3633 - val_loss: 8.8675 - val_accuracy: 0.2088\n",
            "Epoch 216/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.8997 - accuracy: 0.3633 - val_loss: 8.9236 - val_accuracy: 0.2080\n",
            "Epoch 217/500\n",
            "79/79 [==============================] - 17s 215ms/step - loss: 2.8873 - accuracy: 0.3657 - val_loss: 8.8708 - val_accuracy: 0.2080\n",
            "Epoch 218/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.8871 - accuracy: 0.3654 - val_loss: 8.8907 - val_accuracy: 0.2091\n",
            "Epoch 219/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.8781 - accuracy: 0.3663 - val_loss: 8.9181 - val_accuracy: 0.2091\n",
            "Epoch 220/500\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.8732 - accuracy: 0.3664 - val_loss: 8.9324 - val_accuracy: 0.2095\n",
            "Epoch 221/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.8722 - accuracy: 0.3679 - val_loss: 8.9322 - val_accuracy: 0.2090\n",
            "Epoch 222/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.8691 - accuracy: 0.3680 - val_loss: 8.9570 - val_accuracy: 0.2097\n",
            "Epoch 223/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.8627 - accuracy: 0.3693 - val_loss: 8.9237 - val_accuracy: 0.2105\n",
            "Epoch 224/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.8571 - accuracy: 0.3681 - val_loss: 8.9266 - val_accuracy: 0.2115\n",
            "Epoch 225/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 2.8543 - accuracy: 0.3710 - val_loss: 8.9284 - val_accuracy: 0.2108\n",
            "Epoch 226/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 2.8469 - accuracy: 0.3725 - val_loss: 8.9624 - val_accuracy: 0.2108\n",
            "Epoch 227/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 2.8352 - accuracy: 0.3721 - val_loss: 9.0131 - val_accuracy: 0.2117\n",
            "Epoch 228/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.8365 - accuracy: 0.3718 - val_loss: 8.9758 - val_accuracy: 0.2121\n",
            "Epoch 229/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 2.8315 - accuracy: 0.3744 - val_loss: 9.0133 - val_accuracy: 0.2112\n",
            "Epoch 230/500\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.8236 - accuracy: 0.3751 - val_loss: 9.0341 - val_accuracy: 0.2125\n",
            "Epoch 231/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.8181 - accuracy: 0.3767 - val_loss: 8.9721 - val_accuracy: 0.2126\n",
            "Epoch 232/500\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 2.8168 - accuracy: 0.3757 - val_loss: 9.0074 - val_accuracy: 0.2147\n",
            "Epoch 233/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.8124 - accuracy: 0.3773 - val_loss: 9.0264 - val_accuracy: 0.2139\n",
            "Epoch 234/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.8091 - accuracy: 0.3768 - val_loss: 9.0421 - val_accuracy: 0.2130\n",
            "Epoch 235/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 2.8044 - accuracy: 0.3772 - val_loss: 9.0486 - val_accuracy: 0.2146\n",
            "Epoch 236/500\n",
            "79/79 [==============================] - 18s 229ms/step - loss: 2.7989 - accuracy: 0.3798 - val_loss: 9.0288 - val_accuracy: 0.2147\n",
            "Epoch 237/500\n",
            "79/79 [==============================] - 17s 216ms/step - loss: 2.7968 - accuracy: 0.3794 - val_loss: 9.0203 - val_accuracy: 0.2132\n",
            "Epoch 238/500\n",
            "79/79 [==============================] - 17s 215ms/step - loss: 2.7930 - accuracy: 0.3809 - val_loss: 9.0365 - val_accuracy: 0.2141\n",
            "Epoch 239/500\n",
            "79/79 [==============================] - 17s 216ms/step - loss: 2.7830 - accuracy: 0.3825 - val_loss: 9.0813 - val_accuracy: 0.2127\n",
            "Epoch 240/500\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.7787 - accuracy: 0.3820 - val_loss: 9.0803 - val_accuracy: 0.2158\n",
            "Epoch 241/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.7744 - accuracy: 0.3832 - val_loss: 9.0937 - val_accuracy: 0.2164\n",
            "Epoch 242/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.7651 - accuracy: 0.3839 - val_loss: 9.1350 - val_accuracy: 0.2168\n",
            "Epoch 243/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.7625 - accuracy: 0.3844 - val_loss: 9.1034 - val_accuracy: 0.2164\n",
            "Epoch 244/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.7571 - accuracy: 0.3857 - val_loss: 9.1387 - val_accuracy: 0.2170\n",
            "Epoch 245/500\n",
            "79/79 [==============================] - 18s 225ms/step - loss: 2.7480 - accuracy: 0.3869 - val_loss: 9.0991 - val_accuracy: 0.2165\n",
            "Epoch 246/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.7509 - accuracy: 0.3866 - val_loss: 9.1485 - val_accuracy: 0.2187\n",
            "Epoch 247/500\n",
            "79/79 [==============================] - 17s 222ms/step - loss: 2.7424 - accuracy: 0.3886 - val_loss: 9.1216 - val_accuracy: 0.2170\n",
            "Epoch 248/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.7390 - accuracy: 0.3877 - val_loss: 9.1391 - val_accuracy: 0.2174\n",
            "Epoch 249/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.7318 - accuracy: 0.3901 - val_loss: 9.1746 - val_accuracy: 0.2163\n",
            "Epoch 250/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.7335 - accuracy: 0.3896 - val_loss: 9.1545 - val_accuracy: 0.2196\n",
            "Epoch 251/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.7259 - accuracy: 0.3888 - val_loss: 9.1829 - val_accuracy: 0.2189\n",
            "Epoch 252/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.7208 - accuracy: 0.3905 - val_loss: 9.1916 - val_accuracy: 0.2188\n",
            "Epoch 253/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.7181 - accuracy: 0.3927 - val_loss: 9.1762 - val_accuracy: 0.2199\n",
            "Epoch 254/500\n",
            "79/79 [==============================] - 18s 225ms/step - loss: 2.7169 - accuracy: 0.3918 - val_loss: 9.1916 - val_accuracy: 0.2198\n",
            "Epoch 255/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.7081 - accuracy: 0.3934 - val_loss: 9.1891 - val_accuracy: 0.2193\n",
            "Epoch 256/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.6990 - accuracy: 0.3935 - val_loss: 9.2434 - val_accuracy: 0.2205\n",
            "Epoch 257/500\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.6949 - accuracy: 0.3960 - val_loss: 9.2558 - val_accuracy: 0.2206\n",
            "Epoch 258/500\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.6981 - accuracy: 0.3957 - val_loss: 9.2271 - val_accuracy: 0.2209\n",
            "Epoch 259/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.6961 - accuracy: 0.3966 - val_loss: 9.2001 - val_accuracy: 0.2221\n",
            "Epoch 260/500\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.6856 - accuracy: 0.3974 - val_loss: 9.2789 - val_accuracy: 0.2240\n",
            "Epoch 261/500\n",
            "79/79 [==============================] - 18s 225ms/step - loss: 2.6834 - accuracy: 0.3971 - val_loss: 9.2629 - val_accuracy: 0.2223\n",
            "Epoch 262/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.6768 - accuracy: 0.3978 - val_loss: 9.2451 - val_accuracy: 0.2216\n",
            "Epoch 263/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.6696 - accuracy: 0.3994 - val_loss: 9.2944 - val_accuracy: 0.2234\n",
            "Epoch 264/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.6717 - accuracy: 0.3994 - val_loss: 9.3161 - val_accuracy: 0.2228\n",
            "Epoch 265/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.6666 - accuracy: 0.3997 - val_loss: 9.3201 - val_accuracy: 0.2236\n",
            "Epoch 266/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.6555 - accuracy: 0.4018 - val_loss: 9.2711 - val_accuracy: 0.2236\n",
            "Epoch 267/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.6524 - accuracy: 0.4023 - val_loss: 9.2689 - val_accuracy: 0.2218\n",
            "Epoch 268/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 2.6518 - accuracy: 0.4013 - val_loss: 9.3122 - val_accuracy: 0.2241\n",
            "Epoch 269/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.6420 - accuracy: 0.4032 - val_loss: 9.3270 - val_accuracy: 0.2234\n",
            "Epoch 270/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.6392 - accuracy: 0.4043 - val_loss: 9.3087 - val_accuracy: 0.2237\n",
            "Epoch 271/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.6405 - accuracy: 0.4050 - val_loss: 9.2770 - val_accuracy: 0.2239\n",
            "Epoch 272/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.6317 - accuracy: 0.4054 - val_loss: 9.3152 - val_accuracy: 0.2233\n",
            "Epoch 273/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.6299 - accuracy: 0.4060 - val_loss: 9.3534 - val_accuracy: 0.2249\n",
            "Epoch 274/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.6316 - accuracy: 0.4058 - val_loss: 9.3451 - val_accuracy: 0.2260\n",
            "Epoch 275/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.6189 - accuracy: 0.4078 - val_loss: 9.2923 - val_accuracy: 0.2262\n",
            "Epoch 276/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.6266 - accuracy: 0.4071 - val_loss: 9.3994 - val_accuracy: 0.2253\n",
            "Epoch 277/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.6110 - accuracy: 0.4078 - val_loss: 9.3928 - val_accuracy: 0.2270\n",
            "Epoch 278/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.6131 - accuracy: 0.4092 - val_loss: 9.3874 - val_accuracy: 0.2252\n",
            "Epoch 279/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.6061 - accuracy: 0.4094 - val_loss: 9.3849 - val_accuracy: 0.2266\n",
            "Epoch 280/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.6068 - accuracy: 0.4098 - val_loss: 9.4364 - val_accuracy: 0.2265\n",
            "Epoch 281/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.5942 - accuracy: 0.4134 - val_loss: 9.3834 - val_accuracy: 0.2264\n",
            "Epoch 282/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.5964 - accuracy: 0.4128 - val_loss: 9.3700 - val_accuracy: 0.2271\n",
            "Epoch 283/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.5936 - accuracy: 0.4111 - val_loss: 9.4009 - val_accuracy: 0.2260\n",
            "Epoch 284/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.5845 - accuracy: 0.4143 - val_loss: 9.4541 - val_accuracy: 0.2266\n",
            "Epoch 285/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.5808 - accuracy: 0.4138 - val_loss: 9.4210 - val_accuracy: 0.2278\n",
            "Epoch 286/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.5806 - accuracy: 0.4131 - val_loss: 9.4501 - val_accuracy: 0.2272\n",
            "Epoch 287/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.5706 - accuracy: 0.4146 - val_loss: 9.4759 - val_accuracy: 0.2291\n",
            "Epoch 288/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.5698 - accuracy: 0.4155 - val_loss: 9.4322 - val_accuracy: 0.2289\n",
            "Epoch 289/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.5621 - accuracy: 0.4173 - val_loss: 9.4388 - val_accuracy: 0.2285\n",
            "Epoch 290/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.5637 - accuracy: 0.4185 - val_loss: 9.4415 - val_accuracy: 0.2293\n",
            "Epoch 291/500\n",
            "79/79 [==============================] - 19s 240ms/step - loss: 2.5595 - accuracy: 0.4173 - val_loss: 9.4720 - val_accuracy: 0.2300\n",
            "Epoch 292/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.5538 - accuracy: 0.4189 - val_loss: 9.4037 - val_accuracy: 0.2301\n",
            "Epoch 293/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.5496 - accuracy: 0.4182 - val_loss: 9.4569 - val_accuracy: 0.2283\n",
            "Epoch 294/500\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.5503 - accuracy: 0.4202 - val_loss: 9.4893 - val_accuracy: 0.2306\n",
            "Epoch 295/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.5479 - accuracy: 0.4193 - val_loss: 9.4725 - val_accuracy: 0.2301\n",
            "Epoch 296/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.5419 - accuracy: 0.4220 - val_loss: 9.4678 - val_accuracy: 0.2303\n",
            "Epoch 297/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.5404 - accuracy: 0.4206 - val_loss: 9.4479 - val_accuracy: 0.2314\n",
            "Epoch 298/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.5334 - accuracy: 0.4224 - val_loss: 9.5054 - val_accuracy: 0.2310\n",
            "Epoch 299/500\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.5281 - accuracy: 0.4236 - val_loss: 9.4957 - val_accuracy: 0.2323\n",
            "Epoch 300/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.5271 - accuracy: 0.4222 - val_loss: 9.5505 - val_accuracy: 0.2304\n",
            "Epoch 301/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.5240 - accuracy: 0.4240 - val_loss: 9.4946 - val_accuracy: 0.2322\n",
            "Epoch 302/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.5221 - accuracy: 0.4250 - val_loss: 9.5266 - val_accuracy: 0.2316\n",
            "Epoch 303/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.5180 - accuracy: 0.4240 - val_loss: 9.5720 - val_accuracy: 0.2318\n",
            "Epoch 304/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.5109 - accuracy: 0.4256 - val_loss: 9.5604 - val_accuracy: 0.2310\n",
            "Epoch 305/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.5106 - accuracy: 0.4273 - val_loss: 9.5203 - val_accuracy: 0.2329\n",
            "Epoch 306/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 2.4962 - accuracy: 0.4295 - val_loss: 9.6257 - val_accuracy: 0.2339\n",
            "Epoch 307/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.5007 - accuracy: 0.4277 - val_loss: 9.5997 - val_accuracy: 0.2329\n",
            "Epoch 308/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.4993 - accuracy: 0.4278 - val_loss: 9.6144 - val_accuracy: 0.2331\n",
            "Epoch 309/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.4952 - accuracy: 0.4296 - val_loss: 9.6196 - val_accuracy: 0.2328\n",
            "Epoch 310/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.4897 - accuracy: 0.4292 - val_loss: 9.5430 - val_accuracy: 0.2332\n",
            "Epoch 311/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.4896 - accuracy: 0.4301 - val_loss: 9.5800 - val_accuracy: 0.2337\n",
            "Epoch 312/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.4849 - accuracy: 0.4309 - val_loss: 9.6591 - val_accuracy: 0.2326\n",
            "Epoch 313/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.4842 - accuracy: 0.4297 - val_loss: 9.6506 - val_accuracy: 0.2331\n",
            "Epoch 314/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.4836 - accuracy: 0.4296 - val_loss: 9.5898 - val_accuracy: 0.2343\n",
            "Epoch 315/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.4805 - accuracy: 0.4310 - val_loss: 9.6868 - val_accuracy: 0.2342\n",
            "Epoch 316/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.4682 - accuracy: 0.4330 - val_loss: 9.6783 - val_accuracy: 0.2344\n",
            "Epoch 317/500\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.4617 - accuracy: 0.4338 - val_loss: 9.6417 - val_accuracy: 0.2349\n",
            "Epoch 318/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.4698 - accuracy: 0.4316 - val_loss: 9.6323 - val_accuracy: 0.2353\n",
            "Epoch 319/500\n",
            "79/79 [==============================] - 18s 225ms/step - loss: 2.4554 - accuracy: 0.4366 - val_loss: 9.6783 - val_accuracy: 0.2338\n",
            "Epoch 320/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.4540 - accuracy: 0.4354 - val_loss: 9.6682 - val_accuracy: 0.2345\n",
            "Epoch 321/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.4472 - accuracy: 0.4368 - val_loss: 9.7005 - val_accuracy: 0.2339\n",
            "Epoch 322/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.4511 - accuracy: 0.4370 - val_loss: 9.6707 - val_accuracy: 0.2353\n",
            "Epoch 323/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.4495 - accuracy: 0.4363 - val_loss: 9.7366 - val_accuracy: 0.2332\n",
            "Epoch 324/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.4477 - accuracy: 0.4357 - val_loss: 9.7149 - val_accuracy: 0.2360\n",
            "Epoch 325/500\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.4406 - accuracy: 0.4376 - val_loss: 9.7471 - val_accuracy: 0.2369\n",
            "Epoch 326/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.4342 - accuracy: 0.4392 - val_loss: 9.7107 - val_accuracy: 0.2365\n",
            "Epoch 327/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.4323 - accuracy: 0.4390 - val_loss: 9.7265 - val_accuracy: 0.2355\n",
            "Epoch 328/500\n",
            "79/79 [==============================] - 19s 239ms/step - loss: 2.4319 - accuracy: 0.4397 - val_loss: 9.7678 - val_accuracy: 0.2378\n",
            "Epoch 329/500\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 2.4284 - accuracy: 0.4408 - val_loss: 9.7065 - val_accuracy: 0.2364\n",
            "Epoch 330/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.4281 - accuracy: 0.4403 - val_loss: 9.6872 - val_accuracy: 0.2376\n",
            "Epoch 331/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.4239 - accuracy: 0.4400 - val_loss: 9.7064 - val_accuracy: 0.2379\n",
            "Epoch 332/500\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 2.4220 - accuracy: 0.4418 - val_loss: 9.6940 - val_accuracy: 0.2361\n",
            "Epoch 333/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.4219 - accuracy: 0.4423 - val_loss: 9.6830 - val_accuracy: 0.2372\n",
            "Epoch 334/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.4141 - accuracy: 0.4432 - val_loss: 9.8019 - val_accuracy: 0.2377\n",
            "Epoch 335/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.4080 - accuracy: 0.4442 - val_loss: 9.7353 - val_accuracy: 0.2383\n",
            "Epoch 336/500\n",
            "79/79 [==============================] - 18s 226ms/step - loss: 2.4047 - accuracy: 0.4454 - val_loss: 9.7247 - val_accuracy: 0.2380\n",
            "Epoch 337/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.4081 - accuracy: 0.4446 - val_loss: 9.6988 - val_accuracy: 0.2392\n",
            "Epoch 338/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.4002 - accuracy: 0.4445 - val_loss: 9.7538 - val_accuracy: 0.2382\n",
            "Epoch 339/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.4002 - accuracy: 0.4460 - val_loss: 9.7601 - val_accuracy: 0.2391\n",
            "Epoch 340/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3944 - accuracy: 0.4457 - val_loss: 9.8391 - val_accuracy: 0.2409\n",
            "Epoch 341/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.3933 - accuracy: 0.4465 - val_loss: 9.8459 - val_accuracy: 0.2376\n",
            "Epoch 342/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.3838 - accuracy: 0.4480 - val_loss: 9.8553 - val_accuracy: 0.2401\n",
            "Epoch 343/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.3845 - accuracy: 0.4477 - val_loss: 9.7918 - val_accuracy: 0.2408\n",
            "Epoch 344/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.3816 - accuracy: 0.4482 - val_loss: 9.7658 - val_accuracy: 0.2403\n",
            "Epoch 345/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.3773 - accuracy: 0.4485 - val_loss: 9.8505 - val_accuracy: 0.2402\n",
            "Epoch 346/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.3802 - accuracy: 0.4490 - val_loss: 9.7975 - val_accuracy: 0.2382\n",
            "Epoch 347/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3701 - accuracy: 0.4503 - val_loss: 9.8049 - val_accuracy: 0.2411\n",
            "Epoch 348/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.3617 - accuracy: 0.4520 - val_loss: 9.8575 - val_accuracy: 0.2397\n",
            "Epoch 349/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.3691 - accuracy: 0.4498 - val_loss: 9.8149 - val_accuracy: 0.2398\n",
            "Epoch 350/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.3542 - accuracy: 0.4541 - val_loss: 9.8231 - val_accuracy: 0.2407\n",
            "Epoch 351/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.3582 - accuracy: 0.4528 - val_loss: 9.7866 - val_accuracy: 0.2412\n",
            "Epoch 352/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.3483 - accuracy: 0.4533 - val_loss: 9.7867 - val_accuracy: 0.2421\n",
            "Epoch 353/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.3491 - accuracy: 0.4545 - val_loss: 9.8912 - val_accuracy: 0.2415\n",
            "Epoch 354/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.3509 - accuracy: 0.4538 - val_loss: 9.7889 - val_accuracy: 0.2399\n",
            "Epoch 355/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.3523 - accuracy: 0.4532 - val_loss: 9.9019 - val_accuracy: 0.2416\n",
            "Epoch 356/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 2.3456 - accuracy: 0.4546 - val_loss: 9.8794 - val_accuracy: 0.2428\n",
            "Epoch 357/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.3439 - accuracy: 0.4566 - val_loss: 9.8602 - val_accuracy: 0.2414\n",
            "Epoch 358/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.3429 - accuracy: 0.4563 - val_loss: 9.8975 - val_accuracy: 0.2426\n",
            "Epoch 359/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3421 - accuracy: 0.4551 - val_loss: 9.7792 - val_accuracy: 0.2436\n",
            "Epoch 360/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.3345 - accuracy: 0.4574 - val_loss: 9.8568 - val_accuracy: 0.2426\n",
            "Epoch 361/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.3294 - accuracy: 0.4575 - val_loss: 9.8722 - val_accuracy: 0.2441\n",
            "Epoch 362/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.3329 - accuracy: 0.4554 - val_loss: 9.9040 - val_accuracy: 0.2415\n",
            "Epoch 363/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.3180 - accuracy: 0.4590 - val_loss: 9.9766 - val_accuracy: 0.2417\n",
            "Epoch 364/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.3224 - accuracy: 0.4580 - val_loss: 9.9950 - val_accuracy: 0.2430\n",
            "Epoch 365/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.3164 - accuracy: 0.4594 - val_loss: 9.9397 - val_accuracy: 0.2444\n",
            "Epoch 366/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.3140 - accuracy: 0.4604 - val_loss: 9.8926 - val_accuracy: 0.2431\n",
            "Epoch 367/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.3158 - accuracy: 0.4611 - val_loss: 9.9076 - val_accuracy: 0.2436\n",
            "Epoch 368/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.3085 - accuracy: 0.4621 - val_loss: 9.9479 - val_accuracy: 0.2434\n",
            "Epoch 369/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.3045 - accuracy: 0.4614 - val_loss: 9.9915 - val_accuracy: 0.2442\n",
            "Epoch 370/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.3044 - accuracy: 0.4621 - val_loss: 9.9847 - val_accuracy: 0.2434\n",
            "Epoch 371/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.3032 - accuracy: 0.4627 - val_loss: 9.9851 - val_accuracy: 0.2446\n",
            "Epoch 372/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.2948 - accuracy: 0.4647 - val_loss: 9.9756 - val_accuracy: 0.2458\n",
            "Epoch 373/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.3008 - accuracy: 0.4636 - val_loss: 9.9764 - val_accuracy: 0.2449\n",
            "Epoch 374/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.2943 - accuracy: 0.4629 - val_loss: 9.9526 - val_accuracy: 0.2448\n",
            "Epoch 375/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.2992 - accuracy: 0.4630 - val_loss: 9.9770 - val_accuracy: 0.2463\n",
            "Epoch 376/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.2901 - accuracy: 0.4644 - val_loss: 9.9387 - val_accuracy: 0.2453\n",
            "Epoch 377/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.2869 - accuracy: 0.4636 - val_loss: 10.0030 - val_accuracy: 0.2465\n",
            "Epoch 378/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.2804 - accuracy: 0.4682 - val_loss: 10.0144 - val_accuracy: 0.2463\n",
            "Epoch 379/500\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.2785 - accuracy: 0.4672 - val_loss: 10.0150 - val_accuracy: 0.2483\n",
            "Epoch 380/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.2768 - accuracy: 0.4667 - val_loss: 10.0609 - val_accuracy: 0.2463\n",
            "Epoch 381/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.2799 - accuracy: 0.4665 - val_loss: 10.0888 - val_accuracy: 0.2466\n",
            "Epoch 382/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.2755 - accuracy: 0.4666 - val_loss: 10.0254 - val_accuracy: 0.2455\n",
            "Epoch 383/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.2724 - accuracy: 0.4688 - val_loss: 9.9894 - val_accuracy: 0.2478\n",
            "Epoch 384/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.2691 - accuracy: 0.4678 - val_loss: 10.0291 - val_accuracy: 0.2457\n",
            "Epoch 385/500\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.2688 - accuracy: 0.4695 - val_loss: 9.9467 - val_accuracy: 0.2485\n",
            "Epoch 386/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.2628 - accuracy: 0.4695 - val_loss: 10.0483 - val_accuracy: 0.2479\n",
            "Epoch 387/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.2564 - accuracy: 0.4705 - val_loss: 10.0436 - val_accuracy: 0.2469\n",
            "Epoch 388/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.2534 - accuracy: 0.4699 - val_loss: 10.0558 - val_accuracy: 0.2479\n",
            "Epoch 389/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.2563 - accuracy: 0.4708 - val_loss: 10.0024 - val_accuracy: 0.2481\n",
            "Epoch 390/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.2520 - accuracy: 0.4719 - val_loss: 10.0361 - val_accuracy: 0.2474\n",
            "Epoch 391/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.2521 - accuracy: 0.4698 - val_loss: 9.9858 - val_accuracy: 0.2460\n",
            "Epoch 392/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.2528 - accuracy: 0.4717 - val_loss: 10.0569 - val_accuracy: 0.2484\n",
            "Epoch 393/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.2436 - accuracy: 0.4730 - val_loss: 10.0467 - val_accuracy: 0.2496\n",
            "Epoch 394/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 2.2368 - accuracy: 0.4749 - val_loss: 10.0434 - val_accuracy: 0.2497\n",
            "Epoch 395/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.2418 - accuracy: 0.4725 - val_loss: 10.0573 - val_accuracy: 0.2492\n",
            "Epoch 396/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.2350 - accuracy: 0.4749 - val_loss: 10.0891 - val_accuracy: 0.2480\n",
            "Epoch 397/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 2.2347 - accuracy: 0.4740 - val_loss: 10.0939 - val_accuracy: 0.2499\n",
            "Epoch 398/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.2325 - accuracy: 0.4741 - val_loss: 10.1535 - val_accuracy: 0.2490\n",
            "Epoch 399/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.2346 - accuracy: 0.4740 - val_loss: 10.1048 - val_accuracy: 0.2509\n",
            "Epoch 400/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.2280 - accuracy: 0.4762 - val_loss: 10.0647 - val_accuracy: 0.2508\n",
            "Epoch 401/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.2208 - accuracy: 0.4773 - val_loss: 10.1498 - val_accuracy: 0.2501\n",
            "Epoch 402/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.2201 - accuracy: 0.4773 - val_loss: 10.1750 - val_accuracy: 0.2513\n",
            "Epoch 403/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.2251 - accuracy: 0.4765 - val_loss: 10.1535 - val_accuracy: 0.2483\n",
            "Epoch 404/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.2170 - accuracy: 0.4776 - val_loss: 10.1489 - val_accuracy: 0.2514\n",
            "Epoch 405/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.2149 - accuracy: 0.4777 - val_loss: 10.0985 - val_accuracy: 0.2504\n",
            "Epoch 406/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.2161 - accuracy: 0.4776 - val_loss: 10.1880 - val_accuracy: 0.2524\n",
            "Epoch 407/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.2099 - accuracy: 0.4797 - val_loss: 10.1520 - val_accuracy: 0.2526\n",
            "Epoch 408/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.2059 - accuracy: 0.4799 - val_loss: 10.1100 - val_accuracy: 0.2511\n",
            "Epoch 409/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.2042 - accuracy: 0.4807 - val_loss: 10.1524 - val_accuracy: 0.2504\n",
            "Epoch 410/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.1978 - accuracy: 0.4824 - val_loss: 10.2042 - val_accuracy: 0.2520\n",
            "Epoch 411/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.1956 - accuracy: 0.4821 - val_loss: 10.1821 - val_accuracy: 0.2526\n",
            "Epoch 412/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.2016 - accuracy: 0.4807 - val_loss: 10.1775 - val_accuracy: 0.2542\n",
            "Epoch 413/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.2009 - accuracy: 0.4811 - val_loss: 10.1363 - val_accuracy: 0.2532\n",
            "Epoch 414/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.1934 - accuracy: 0.4823 - val_loss: 10.1926 - val_accuracy: 0.2512\n",
            "Epoch 415/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.1949 - accuracy: 0.4826 - val_loss: 10.1566 - val_accuracy: 0.2513\n",
            "Epoch 416/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.1847 - accuracy: 0.4836 - val_loss: 10.1830 - val_accuracy: 0.2542\n",
            "Epoch 417/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.1895 - accuracy: 0.4832 - val_loss: 10.1331 - val_accuracy: 0.2535\n",
            "Epoch 418/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.1845 - accuracy: 0.4833 - val_loss: 10.1104 - val_accuracy: 0.2534\n",
            "Epoch 419/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.1760 - accuracy: 0.4850 - val_loss: 10.1607 - val_accuracy: 0.2522\n",
            "Epoch 420/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.1766 - accuracy: 0.4842 - val_loss: 10.1993 - val_accuracy: 0.2535\n",
            "Epoch 421/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.1797 - accuracy: 0.4839 - val_loss: 10.1919 - val_accuracy: 0.2551\n",
            "Epoch 422/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.1688 - accuracy: 0.4863 - val_loss: 10.2306 - val_accuracy: 0.2545\n",
            "Epoch 423/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.1743 - accuracy: 0.4856 - val_loss: 10.1989 - val_accuracy: 0.2549\n",
            "Epoch 424/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.1619 - accuracy: 0.4874 - val_loss: 10.2016 - val_accuracy: 0.2540\n",
            "Epoch 425/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.1677 - accuracy: 0.4866 - val_loss: 10.2213 - val_accuracy: 0.2552\n",
            "Epoch 426/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.1629 - accuracy: 0.4880 - val_loss: 10.2354 - val_accuracy: 0.2535\n",
            "Epoch 427/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.1579 - accuracy: 0.4878 - val_loss: 10.1894 - val_accuracy: 0.2542\n",
            "Epoch 428/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.1610 - accuracy: 0.4880 - val_loss: 10.2198 - val_accuracy: 0.2542\n",
            "Epoch 429/500\n",
            "79/79 [==============================] - 18s 230ms/step - loss: 2.1588 - accuracy: 0.4885 - val_loss: 10.2509 - val_accuracy: 0.2553\n",
            "Epoch 430/500\n",
            "79/79 [==============================] - 19s 234ms/step - loss: 2.1592 - accuracy: 0.4881 - val_loss: 10.2987 - val_accuracy: 0.2556\n",
            "Epoch 431/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.1612 - accuracy: 0.4882 - val_loss: 10.2526 - val_accuracy: 0.2561\n",
            "Epoch 432/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.1484 - accuracy: 0.4912 - val_loss: 10.3042 - val_accuracy: 0.2554\n",
            "Epoch 433/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.1510 - accuracy: 0.4893 - val_loss: 10.1949 - val_accuracy: 0.2547\n",
            "Epoch 434/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 2.1545 - accuracy: 0.4886 - val_loss: 10.2474 - val_accuracy: 0.2549\n",
            "Epoch 435/500\n",
            "79/79 [==============================] - 17s 217ms/step - loss: 2.1431 - accuracy: 0.4907 - val_loss: 10.2463 - val_accuracy: 0.2560\n",
            "Epoch 436/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.1411 - accuracy: 0.4916 - val_loss: 10.2956 - val_accuracy: 0.2565\n",
            "Epoch 437/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.1417 - accuracy: 0.4916 - val_loss: 10.2617 - val_accuracy: 0.2566\n",
            "Epoch 438/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.1300 - accuracy: 0.4933 - val_loss: 10.2715 - val_accuracy: 0.2561\n",
            "Epoch 439/500\n",
            "79/79 [==============================] - 18s 231ms/step - loss: 2.1319 - accuracy: 0.4925 - val_loss: 10.3371 - val_accuracy: 0.2567\n",
            "Epoch 440/500\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.1288 - accuracy: 0.4956 - val_loss: 10.2739 - val_accuracy: 0.2573\n",
            "Epoch 441/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.1310 - accuracy: 0.4937 - val_loss: 10.2268 - val_accuracy: 0.2577\n",
            "Epoch 442/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.1297 - accuracy: 0.4938 - val_loss: 10.2664 - val_accuracy: 0.2574\n",
            "Epoch 443/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.1275 - accuracy: 0.4944 - val_loss: 10.2389 - val_accuracy: 0.2563\n",
            "Epoch 444/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.1260 - accuracy: 0.4948 - val_loss: 10.3355 - val_accuracy: 0.2565\n",
            "Epoch 445/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.1223 - accuracy: 0.4958 - val_loss: 10.3112 - val_accuracy: 0.2579\n",
            "Epoch 446/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.1150 - accuracy: 0.4974 - val_loss: 10.2807 - val_accuracy: 0.2578\n",
            "Epoch 447/500\n",
            "79/79 [==============================] - 17s 219ms/step - loss: 2.1190 - accuracy: 0.4949 - val_loss: 10.2985 - val_accuracy: 0.2571\n",
            "Epoch 448/500\n",
            "79/79 [==============================] - 18s 233ms/step - loss: 2.1167 - accuracy: 0.4963 - val_loss: 10.3565 - val_accuracy: 0.2584\n",
            "Epoch 449/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.1130 - accuracy: 0.4972 - val_loss: 10.3568 - val_accuracy: 0.2579\n",
            "Epoch 450/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.1142 - accuracy: 0.4952 - val_loss: 10.3587 - val_accuracy: 0.2572\n",
            "Epoch 451/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.1084 - accuracy: 0.4977 - val_loss: 10.3187 - val_accuracy: 0.2590\n",
            "Epoch 452/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.1086 - accuracy: 0.4980 - val_loss: 10.3382 - val_accuracy: 0.2581\n",
            "Epoch 453/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.1070 - accuracy: 0.4980 - val_loss: 10.3340 - val_accuracy: 0.2602\n",
            "Epoch 454/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.0974 - accuracy: 0.4988 - val_loss: 10.3592 - val_accuracy: 0.2597\n",
            "Epoch 455/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.1060 - accuracy: 0.4993 - val_loss: 10.3050 - val_accuracy: 0.2586\n",
            "Epoch 456/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.0964 - accuracy: 0.5003 - val_loss: 10.4146 - val_accuracy: 0.2598\n",
            "Epoch 457/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.0924 - accuracy: 0.5002 - val_loss: 10.3602 - val_accuracy: 0.2594\n",
            "Epoch 458/500\n",
            "79/79 [==============================] - 17s 218ms/step - loss: 2.0999 - accuracy: 0.4989 - val_loss: 10.4224 - val_accuracy: 0.2590\n",
            "Epoch 459/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.0934 - accuracy: 0.5019 - val_loss: 10.3836 - val_accuracy: 0.2597\n",
            "Epoch 460/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.0858 - accuracy: 0.5009 - val_loss: 10.3914 - val_accuracy: 0.2580\n",
            "Epoch 461/500\n",
            "79/79 [==============================] - 17s 220ms/step - loss: 2.0874 - accuracy: 0.5020 - val_loss: 10.3377 - val_accuracy: 0.2601\n",
            "Epoch 462/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.0845 - accuracy: 0.5016 - val_loss: 10.3991 - val_accuracy: 0.2614\n",
            "Epoch 463/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0864 - accuracy: 0.5023 - val_loss: 10.3808 - val_accuracy: 0.2601\n",
            "Epoch 464/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.0797 - accuracy: 0.5038 - val_loss: 10.4245 - val_accuracy: 0.2603\n",
            "Epoch 465/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0815 - accuracy: 0.5036 - val_loss: 10.3950 - val_accuracy: 0.2612\n",
            "Epoch 466/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.0752 - accuracy: 0.5042 - val_loss: 10.4652 - val_accuracy: 0.2600\n",
            "Epoch 467/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0812 - accuracy: 0.5026 - val_loss: 10.3381 - val_accuracy: 0.2613\n",
            "Epoch 468/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0702 - accuracy: 0.5067 - val_loss: 10.4320 - val_accuracy: 0.2612\n",
            "Epoch 469/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.0719 - accuracy: 0.5043 - val_loss: 10.4375 - val_accuracy: 0.2620\n",
            "Epoch 470/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.0689 - accuracy: 0.5047 - val_loss: 10.4132 - val_accuracy: 0.2598\n",
            "Epoch 471/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0732 - accuracy: 0.5030 - val_loss: 10.4448 - val_accuracy: 0.2614\n",
            "Epoch 472/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0701 - accuracy: 0.5049 - val_loss: 10.4090 - val_accuracy: 0.2610\n",
            "Epoch 473/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.0657 - accuracy: 0.5052 - val_loss: 10.4710 - val_accuracy: 0.2620\n",
            "Epoch 474/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.0585 - accuracy: 0.5060 - val_loss: 10.3421 - val_accuracy: 0.2627\n",
            "Epoch 475/500\n",
            "79/79 [==============================] - 18s 225ms/step - loss: 2.0574 - accuracy: 0.5074 - val_loss: 10.4719 - val_accuracy: 0.2612\n",
            "Epoch 476/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.0610 - accuracy: 0.5076 - val_loss: 10.4599 - val_accuracy: 0.2629\n",
            "Epoch 477/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0545 - accuracy: 0.5079 - val_loss: 10.4188 - val_accuracy: 0.2626\n",
            "Epoch 478/500\n",
            "79/79 [==============================] - 18s 232ms/step - loss: 2.0526 - accuracy: 0.5082 - val_loss: 10.4993 - val_accuracy: 0.2631\n",
            "Epoch 479/500\n",
            "79/79 [==============================] - 19s 237ms/step - loss: 2.0583 - accuracy: 0.5075 - val_loss: 10.4443 - val_accuracy: 0.2632\n",
            "Epoch 480/500\n",
            "79/79 [==============================] - 19s 238ms/step - loss: 2.0488 - accuracy: 0.5096 - val_loss: 10.4431 - val_accuracy: 0.2637\n",
            "Epoch 481/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.0537 - accuracy: 0.5079 - val_loss: 10.4617 - val_accuracy: 0.2624\n",
            "Epoch 482/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.0415 - accuracy: 0.5110 - val_loss: 10.4632 - val_accuracy: 0.2626\n",
            "Epoch 483/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.0464 - accuracy: 0.5109 - val_loss: 10.4446 - val_accuracy: 0.2641\n",
            "Epoch 484/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0393 - accuracy: 0.5107 - val_loss: 10.4329 - val_accuracy: 0.2633\n",
            "Epoch 485/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.0366 - accuracy: 0.5106 - val_loss: 10.4871 - val_accuracy: 0.2629\n",
            "Epoch 486/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.0353 - accuracy: 0.5122 - val_loss: 10.5235 - val_accuracy: 0.2639\n",
            "Epoch 487/500\n",
            "79/79 [==============================] - 18s 224ms/step - loss: 2.0387 - accuracy: 0.5119 - val_loss: 10.5452 - val_accuracy: 0.2636\n",
            "Epoch 488/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.0291 - accuracy: 0.5130 - val_loss: 10.5044 - val_accuracy: 0.2641\n",
            "Epoch 489/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.0342 - accuracy: 0.5116 - val_loss: 10.4690 - val_accuracy: 0.2644\n",
            "Epoch 490/500\n",
            "79/79 [==============================] - 18s 234ms/step - loss: 2.0331 - accuracy: 0.5121 - val_loss: 10.4472 - val_accuracy: 0.2655\n",
            "Epoch 491/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.0307 - accuracy: 0.5144 - val_loss: 10.4280 - val_accuracy: 0.2665\n",
            "Epoch 492/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.0275 - accuracy: 0.5132 - val_loss: 10.4992 - val_accuracy: 0.2650\n",
            "Epoch 493/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.0299 - accuracy: 0.5123 - val_loss: 10.4952 - val_accuracy: 0.2656\n",
            "Epoch 494/500\n",
            "79/79 [==============================] - 18s 222ms/step - loss: 2.0226 - accuracy: 0.5126 - val_loss: 10.5485 - val_accuracy: 0.2647\n",
            "Epoch 495/500\n",
            "79/79 [==============================] - 17s 221ms/step - loss: 2.0241 - accuracy: 0.5134 - val_loss: 10.5266 - val_accuracy: 0.2651\n",
            "Epoch 496/500\n",
            "79/79 [==============================] - 19s 236ms/step - loss: 2.0213 - accuracy: 0.5154 - val_loss: 10.5254 - val_accuracy: 0.2666\n",
            "Epoch 497/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0186 - accuracy: 0.5146 - val_loss: 10.4378 - val_accuracy: 0.2658\n",
            "Epoch 498/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0205 - accuracy: 0.5141 - val_loss: 10.4793 - val_accuracy: 0.2656\n",
            "Epoch 499/500\n",
            "79/79 [==============================] - 18s 223ms/step - loss: 2.0176 - accuracy: 0.5155 - val_loss: 10.5204 - val_accuracy: 0.2662\n",
            "Epoch 500/500\n",
            "79/79 [==============================] - 19s 235ms/step - loss: 2.0153 - accuracy: 0.5154 - val_loss: 10.4388 - val_accuracy: 0.2666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD93EE9F7qMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "4077e2eb-12cb-4c30-9910-e601ccec4b56"
      },
      "source": [
        "train_utils.plot_history(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"dc2c2089-688c-4027-84aa-30c456c68a31\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"dc2c2089-688c-4027-84aa-30c456c68a31\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'dc2c2089-688c-4027-84aa-30c456c68a31',\n",
              "                        [{\"line\": {\"color\": \"royalblue\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"train_loss\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499], \"y\": [7.458602428436279, 7.021402359008789, 7.009311676025391, 6.955985069274902, 6.8343939781188965, 6.712810039520264, 6.608242511749268, 6.514761447906494, 6.441170692443848, 6.371826171875, 6.300393581390381, 6.232043743133545, 6.170290470123291, 6.113407135009766, 6.059351444244385, 6.004700183868408, 5.949937343597412, 5.893865585327148, 5.840144634246826, 5.785127639770508, 5.73313570022583, 5.686136245727539, 5.643167018890381, 5.59910249710083, 5.556097507476807, 5.515835762023926, 5.475383281707764, 5.43580961227417, 5.395748615264893, 5.358993053436279, 5.318986415863037, 5.285747528076172, 5.251445293426514, 5.212973117828369, 5.178022384643555, 5.146390438079834, 5.111725807189941, 5.081413269042969, 5.049098491668701, 5.016397953033447, 4.985947608947754, 4.956323623657227, 4.93022346496582, 4.901480197906494, 4.873708724975586, 4.841719627380371, 4.813971996307373, 4.785449981689453, 4.76080846786499, 4.736237525939941, 4.708621501922607, 4.686616897583008, 4.657742977142334, 4.632593631744385, 4.607674598693848, 4.585359573364258, 4.560201168060303, 4.540639877319336, 4.51220703125, 4.492542266845703, 4.4723005294799805, 4.4511494636535645, 4.42878532409668, 4.413455963134766, 4.391733646392822, 4.369042873382568, 4.3505353927612305, 4.326739311218262, 4.311563968658447, 4.292220115661621, 4.269426345825195, 4.256741523742676, 4.238198757171631, 4.219151973724365, 4.20266056060791, 4.18494176864624, 4.169332027435303, 4.149455547332764, 4.137803554534912, 4.116767406463623, 4.100502967834473, 4.083449840545654, 4.0702009201049805, 4.059648036956787, 4.039373874664307, 4.027568340301514, 4.011825084686279, 3.9942076206207275, 3.9786579608917236, 3.9630703926086426, 3.953157663345337, 3.94500732421875, 3.930150032043457, 3.9062442779541016, 3.8975884914398193, 3.8874988555908203, 3.8704326152801514, 3.8597898483276367, 3.844069242477417, 3.8322761058807373, 3.821240186691284, 3.8114266395568848, 3.7916510105133057, 3.784296989440918, 3.768200397491455, 3.7584316730499268, 3.750084161758423, 3.733917236328125, 3.724353075027466, 3.716841220855713, 3.7006072998046875, 3.686579465866089, 3.67802095413208, 3.669113874435425, 3.6539947986602783, 3.643953323364258, 3.639620542526245, 3.631702423095703, 3.616957664489746, 3.609309196472168, 3.5965981483459473, 3.5904407501220703, 3.5754475593566895, 3.564770221710205, 3.5559475421905518, 3.5410876274108887, 3.54119610786438, 3.526963472366333, 3.5164248943328857, 3.504305601119995, 3.5012247562408447, 3.4923555850982666, 3.47900652885437, 3.474431037902832, 3.457871198654175, 3.4513890743255615, 3.4426355361938477, 3.437422752380371, 3.4223594665527344, 3.420081615447998, 3.404766321182251, 3.398977518081665, 3.389678716659546, 3.3810465335845947, 3.3723390102386475, 3.3669545650482178, 3.3583598136901855, 3.3477187156677246, 3.338785409927368, 3.33193302154541, 3.3255183696746826, 3.3179781436920166, 3.3103854656219482, 3.30106520652771, 3.2952380180358887, 3.2856810092926025, 3.2768495082855225, 3.268112897872925, 3.2588319778442383, 3.2528700828552246, 3.250032663345337, 3.2422804832458496, 3.231519937515259, 3.2216625213623047, 3.219912528991699, 3.2107439041137695, 3.1988728046417236, 3.204078197479248, 3.1879794597625732, 3.179272413253784, 3.1763107776641846, 3.1669631004333496, 3.1663520336151123, 3.156172275543213, 3.1521947383880615, 3.1415719985961914, 3.1325693130493164, 3.128201484680176, 3.1239748001098633, 3.1095027923583984, 3.107022762298584, 3.109335422515869, 3.0960733890533447, 3.0828840732574463, 3.0855002403259277, 3.0722806453704834, 3.0718817710876465, 3.060788631439209, 3.0544981956481934, 3.0475826263427734, 3.041982889175415, 3.0337958335876465, 3.0354974269866943, 3.026292562484741, 3.0212693214416504, 3.012688398361206, 3.0056071281433105, 2.999680995941162, 2.9940104484558105, 2.9915013313293457, 2.9830503463745117, 2.9763174057006836, 2.9720370769500732, 2.9659273624420166, 2.957529067993164, 2.9552230834960938, 2.952772617340088, 2.943516492843628, 2.943812370300293, 2.927532434463501, 2.9208385944366455, 2.9204330444335938, 2.920297622680664, 2.9069883823394775, 2.9014029502868652, 2.899669885635376, 2.887300729751587, 2.887101411819458, 2.878067970275879, 2.8732335567474365, 2.872183322906494, 2.869094133377075, 2.8626792430877686, 2.8570947647094727, 2.8543055057525635, 2.8468871116638184, 2.835191249847412, 2.8365352153778076, 2.8314614295959473, 2.8236448764801025, 2.818066120147705, 2.8167624473571777, 2.8123903274536133, 2.8090639114379883, 2.8043978214263916, 2.798945665359497, 2.796839714050293, 2.7929646968841553, 2.7829573154449463, 2.778717517852783, 2.7744243144989014, 2.7651422023773193, 2.7624804973602295, 2.75708270072937, 2.7479960918426514, 2.7508907318115234, 2.742372751235962, 2.739006280899048, 2.7318272590637207, 2.73349928855896, 2.7258694171905518, 2.720759868621826, 2.7181174755096436, 2.71685528755188, 2.7080912590026855, 2.6990468502044678, 2.6948909759521484, 2.6980807781219482, 2.6961491107940674, 2.685594081878662, 2.6833837032318115, 2.67678165435791, 2.669595956802368, 2.6717209815979004, 2.666579008102417, 2.6554994583129883, 2.6524298191070557, 2.6517951488494873, 2.6420364379882812, 2.6392295360565186, 2.6405091285705566, 2.6317214965820312, 2.6298704147338867, 2.6316287517547607, 2.6189308166503906, 2.6266093254089355, 2.6110169887542725, 2.613149881362915, 2.6061320304870605, 2.6067609786987305, 2.5941669940948486, 2.596419095993042, 2.593614339828491, 2.584463596343994, 2.580822229385376, 2.580596446990967, 2.5706098079681396, 2.5698089599609375, 2.5620675086975098, 2.563743829727173, 2.5594749450683594, 2.553781270980835, 2.5495808124542236, 2.5503041744232178, 2.5479135513305664, 2.541914701461792, 2.540370225906372, 2.5333597660064697, 2.5280609130859375, 2.527148723602295, 2.5240111351013184, 2.5221266746520996, 2.517972469329834, 2.510897636413574, 2.5106399059295654, 2.4961678981781006, 2.50069260597229, 2.4992992877960205, 2.4951581954956055, 2.4896724224090576, 2.4896066188812256, 2.484933614730835, 2.4841721057891846, 2.4836010932922363, 2.480484962463379, 2.4681806564331055, 2.461735725402832, 2.4697868824005127, 2.4554059505462646, 2.4540064334869385, 2.447173595428467, 2.451136350631714, 2.4495129585266113, 2.447692632675171, 2.440633535385132, 2.43415904045105, 2.432251214981079, 2.4319276809692383, 2.4283690452575684, 2.428084135055542, 2.423860788345337, 2.4220213890075684, 2.4219110012054443, 2.41408634185791, 2.407965660095215, 2.404655694961548, 2.408109188079834, 2.4001846313476562, 2.4002151489257812, 2.394381523132324, 2.3932816982269287, 2.3838207721710205, 2.3845086097717285, 2.381629228591919, 2.3772876262664795, 2.380197286605835, 2.3700618743896484, 2.361698865890503, 2.3691210746765137, 2.354217290878296, 2.3582186698913574, 2.3483285903930664, 2.34909725189209, 2.3508801460266113, 2.352296829223633, 2.3456146717071533, 2.343899726867676, 2.3429369926452637, 2.3420512676239014, 2.334465503692627, 2.3293683528900146, 2.332944631576538, 2.3179967403411865, 2.322411298751831, 2.3163552284240723, 2.31400465965271, 2.31575345993042, 2.308544397354126, 2.3045167922973633, 2.304391860961914, 2.3031654357910156, 2.2948250770568848, 2.3007946014404297, 2.2943413257598877, 2.299194097518921, 2.2900660037994385, 2.2869091033935547, 2.280423879623413, 2.2785377502441406, 2.276789665222168, 2.279853582382202, 2.275507688522339, 2.2724356651306152, 2.269101142883301, 2.2687745094299316, 2.2627599239349365, 2.2564404010772705, 2.2533669471740723, 2.256253242492676, 2.2519936561584473, 2.252096652984619, 2.25284481048584, 2.2436461448669434, 2.2367539405822754, 2.241771936416626, 2.2350378036499023, 2.2347187995910645, 2.2325217723846436, 2.234553813934326, 2.228029251098633, 2.220820188522339, 2.2201356887817383, 2.2250750064849854, 2.2170023918151855, 2.214937210083008, 2.2161030769348145, 2.2099266052246094, 2.2059361934661865, 2.2041614055633545, 2.197805643081665, 2.1955502033233643, 2.201632022857666, 2.2009034156799316, 2.1934211254119873, 2.1948812007904053, 2.184741497039795, 2.1895227432250977, 2.1845178604125977, 2.1759610176086426, 2.176597833633423, 2.1796576976776123, 2.1687614917755127, 2.1743369102478027, 2.1618545055389404, 2.1677160263061523, 2.1629109382629395, 2.157944679260254, 2.1609809398651123, 2.1588261127471924, 2.1591691970825195, 2.1612415313720703, 2.148361921310425, 2.1509604454040527, 2.1545166969299316, 2.143122673034668, 2.1410958766937256, 2.141697883605957, 2.1300461292266846, 2.1318600177764893, 2.128767251968384, 2.1309731006622314, 2.1296863555908203, 2.127523422241211, 2.1259565353393555, 2.1223254203796387, 2.115030527114868, 2.119023561477661, 2.116718292236328, 2.1130118370056152, 2.114192247390747, 2.108396530151367, 2.10859751701355, 2.106961965560913, 2.0974416732788086, 2.1060073375701904, 2.0964243412017822, 2.0923948287963867, 2.0999016761779785, 2.093358278274536, 2.0858376026153564, 2.087390422821045, 2.084538698196411, 2.0864334106445312, 2.079694986343384, 2.081512928009033, 2.0752129554748535, 2.08119797706604, 2.0702297687530518, 2.0719404220581055, 2.0688765048980713, 2.0731663703918457, 2.0700695514678955, 2.0657315254211426, 2.058476686477661, 2.0574235916137695, 2.0610194206237793, 2.0544745922088623, 2.052564859390259, 2.058309555053711, 2.048804759979248, 2.053652286529541, 2.041518449783325, 2.0463902950286865, 2.039344310760498, 2.0366008281707764, 2.0353167057037354, 2.038710117340088, 2.0290632247924805, 2.034236431121826, 2.033118486404419, 2.0306506156921387, 2.027523994445801, 2.029937982559204, 2.0225539207458496, 2.024111270904541, 2.0212676525115967, 2.018556594848633, 2.0204620361328125, 2.017644166946411, 2.0152645111083984]}, {\"line\": {\"color\": \"firebrick\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"train_accuracy\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499], \"xaxis\": \"x\", \"y\": [0.0541599839925766, 0.05779228359460831, 0.05779852718114853, 0.0578172504901886, 0.0645139142870903, 0.07083611935377121, 0.07786355912685394, 0.08414207398891449, 0.08962173014879227, 0.09450848400592804, 0.09875865280628204, 0.10367037355899811, 0.10773954540491104, 0.11044817417860031, 0.1136186346411705, 0.11635845899581909, 0.11837432533502579, 0.12124522030353546, 0.12284917384386063, 0.12506474554538727, 0.1273365020751953, 0.12904655933380127, 0.13121220469474792, 0.1330907642841339, 0.13485074043273926, 0.13576817512512207, 0.13764050602912903, 0.13923820853233337, 0.1411791890859604, 0.14272072911262512, 0.14338228106498718, 0.14515474438667297, 0.14648409187793732, 0.1483376920223236, 0.14953598380088806, 0.15018504858016968, 0.15170162916183472, 0.15447266399860382, 0.15454131364822388, 0.155702143907547, 0.15698781609535217, 0.1587165892124176, 0.15924707055091858, 0.16103202104568481, 0.16219286620616913, 0.1639029085636139, 0.16659905016422272, 0.16744160652160645, 0.16827790439128876, 0.16945746541023254, 0.1713859587907791, 0.17171673476696014, 0.17364521324634552, 0.1752803772687912, 0.1763538420200348, 0.1779453158378601, 0.17909367382526398, 0.18139038980007172, 0.18241392076015472, 0.18423007428646088, 0.18559686839580536, 0.18609614670276642, 0.18806833028793335, 0.1887548416852951, 0.19060219824314117, 0.1924121081829071, 0.19377265870571136, 0.19562625885009766, 0.1970929056406021, 0.19883416593074799, 0.19952069222927094, 0.20134307444095612, 0.20247894525527954, 0.20446985960006714, 0.20503778755664825, 0.20734699070453644, 0.20800229907035828, 0.20974980294704437, 0.21161587536334991, 0.21383145451545715, 0.21460534632205963, 0.216696098446846, 0.21679596602916718, 0.21816898882389069, 0.22108358144760132, 0.22125832736492157, 0.2232055366039276, 0.22429148852825165, 0.22633855044841766, 0.22724974155426025, 0.22884121537208557, 0.22905965149402618, 0.23065736889839172, 0.23375917971134186, 0.23399010300636292, 0.2360808551311493, 0.2375599890947342, 0.2381778508424759, 0.24095512926578522, 0.2411423623561859, 0.24287737905979156, 0.2432643324136734, 0.24540501832962036, 0.24626627564430237, 0.2474333643913269, 0.24871277809143066, 0.2504790127277374, 0.2525697648525238, 0.25258225202560425, 0.25417372584342957, 0.25564661622047424, 0.2575688660144806, 0.25863608717918396, 0.260520875453949, 0.2619188725948334, 0.26328566670417786, 0.26449644565582275, 0.2626241147518158, 0.26522040367126465, 0.26653727889060974, 0.2687341272830963, 0.2685968279838562, 0.27151140570640564, 0.27336499094963074, 0.27242258191108704, 0.2752123475074768, 0.27509376406669617, 0.2755680978298187, 0.27858254313468933, 0.27923783659935, 0.2786199748516083, 0.28127244114875793, 0.2823334038257599, 0.2830074429512024, 0.28568485379219055, 0.28665223717689514, 0.28694555163383484, 0.2884184420108795, 0.29057785868644714, 0.29015347361564636, 0.29294323921203613, 0.29165756702423096, 0.29429754614830017, 0.295545756816864, 0.2984790503978729, 0.29732444882392883, 0.29741182923316956, 0.29980841279029846, 0.30133122205734253, 0.30106285214424133, 0.3028790056705475, 0.3036404252052307, 0.30362793803215027, 0.3058185577392578, 0.3073538541793823, 0.3087456226348877, 0.30862703919410706, 0.30980658531188965, 0.3106616139411926, 0.31209081411361694, 0.3127586245536804, 0.3134576082229614, 0.3164907693862915, 0.3174331784248352, 0.3164595663547516, 0.31737077236175537, 0.32045385241508484, 0.31871259212493896, 0.3201417922973633, 0.3216833472251892, 0.3225383758544922, 0.32280048727989197, 0.3240424692630768, 0.32656386494636536, 0.32553407549858093, 0.3271068334579468, 0.3286171555519104, 0.32924750447273254, 0.3300651013851166, 0.33253031969070435, 0.3334040641784668, 0.33323556184768677, 0.33427780866622925, 0.3356570899486542, 0.33639976382255554, 0.33715495467185974, 0.3374670147895813, 0.3392644226551056, 0.34051263332366943, 0.3404689431190491, 0.34261587262153625, 0.3427157402038574, 0.3416547477245331, 0.34538692235946655, 0.3444632291793823, 0.3474963903427124, 0.34747767448425293, 0.3484575152397156, 0.34944984316825867, 0.3494373559951782, 0.35025495290756226, 0.35143449902534485, 0.353737473487854, 0.3531508147716522, 0.3542117774486542, 0.3554038405418396, 0.3552727699279785, 0.35581573843955994, 0.3579813838005066, 0.3592483401298523, 0.3606463372707367, 0.3612954020500183, 0.36030930280685425, 0.36278077960014343, 0.36332374811172485, 0.3632800579071045, 0.36574527621269226, 0.36542072892189026, 0.3663007318973541, 0.3664068281650543, 0.36787348985671997, 0.3679858148097992, 0.3693276643753052, 0.3680731952190399, 0.3709503412246704, 0.3725043535232544, 0.3720799684524536, 0.3717554211616516, 0.37443283200263977, 0.3751380741596222, 0.3767233192920685, 0.37574347853660583, 0.37730371952056885, 0.37679195404052734, 0.37720388174057007, 0.37975022196769714, 0.3793882429599762, 0.38088610768318176, 0.3824900686740875, 0.3819658160209656, 0.38318905234336853, 0.3838880658149719, 0.3844497501850128, 0.3857167065143585, 0.3868962526321411, 0.38655298948287964, 0.388637512922287, 0.3876951038837433, 0.3900729715824127, 0.3896111249923706, 0.388806015253067, 0.39050358533859253, 0.3926505148410797, 0.3917580544948578, 0.3934306502342224, 0.3935367465019226, 0.3959770202636719, 0.3956587016582489, 0.39658862352371216, 0.3974062204360962, 0.397144079208374, 0.3978118896484375, 0.39940959215164185, 0.39943456649780273, 0.39968419075012207, 0.4017874300479889, 0.4022991955280304, 0.4012756645679474, 0.4031604826450348, 0.40432754158973694, 0.4050390422344208, 0.40538230538368225, 0.40599390864372253, 0.4057754874229431, 0.4077601432800293, 0.4071485102176666, 0.40780383348464966, 0.4092455208301544, 0.409401535987854, 0.4097760021686554, 0.4134270250797272, 0.41277173161506653, 0.4110679030418396, 0.4142758250236511, 0.41382020711898804, 0.4131337106227875, 0.4146253168582916, 0.4154990613460541, 0.41732147336006165, 0.41847604513168335, 0.4173027276992798, 0.4189004600048065, 0.4181889593601227, 0.4202422797679901, 0.4192998707294464, 0.4219648241996765, 0.4206417202949524, 0.4223829507827759, 0.42361870408058167, 0.42216452956199646, 0.42401811480522156, 0.4249979853630066, 0.4239557087421417, 0.4256220757961273, 0.42725101113319397, 0.4295476973056793, 0.42767539620399475, 0.4278251826763153, 0.429628849029541, 0.42915451526641846, 0.43006572127342224, 0.43087083101272583, 0.42972245812416077, 0.4296225905418396, 0.43103307485580444, 0.4329615831375122, 0.43375417590141296, 0.43163222074508667, 0.4365564286708832, 0.4353768527507782, 0.4367998242378235, 0.43699952960014343, 0.4363442361354828, 0.4356764256954193, 0.4375612437725067, 0.43915271759033203, 0.4390091598033905, 0.4396519958972931, 0.4407878816127777, 0.4402698576450348, 0.43995779752731323, 0.4418051540851593, 0.44232940673828125, 0.44324684143066406, 0.4441767632961273, 0.4453750550746918, 0.44461989402770996, 0.4444701075553894, 0.4459554851055145, 0.44568711519241333, 0.4464547634124756, 0.44802752137184143, 0.44768425822257996, 0.4482022523880005, 0.4484955966472626, 0.4489574432373047, 0.45026180148124695, 0.4520280361175537, 0.4498249292373657, 0.4541187882423401, 0.45279568433761597, 0.4532824754714966, 0.4544932544231415, 0.45383793115615845, 0.4532325565814972, 0.4546118378639221, 0.45664018392562866, 0.45631563663482666, 0.4550924003124237, 0.4574265480041504, 0.4574640095233917, 0.45537325739860535, 0.4590242803096771, 0.4579695165157318, 0.4593987464904785, 0.46039730310440063, 0.4611150324344635, 0.4620511829853058, 0.46137091517448425, 0.46206989884376526, 0.46265658736228943, 0.4647223651409149, 0.46357402205467224, 0.4628937244415283, 0.46300607919692993, 0.46443527936935425, 0.46357402205467224, 0.46822986006736755, 0.46717509627342224, 0.466731995344162, 0.46645113825798035, 0.46657595038414, 0.4687977731227875, 0.46779295802116394, 0.46949678659439087, 0.46954047679901123, 0.4705016016960144, 0.46989619731903076, 0.4707637131214142, 0.47185590863227844, 0.46979010105133057, 0.47167491912841797, 0.473022997379303, 0.47487035393714905, 0.47252368927001953, 0.4749452471733093, 0.4740215539932251, 0.47412142157554626, 0.47397786378860474, 0.4761996865272522, 0.4772981107234955, 0.477279394865036, 0.4765491783618927, 0.47761017084121704, 0.4777037799358368, 0.47756025195121765, 0.47973838448524475, 0.4799380898475647, 0.4807431995868683, 0.4823783338069916, 0.48210999369621277, 0.4807494282722473, 0.4811488687992096, 0.48229098320007324, 0.4826467037200928, 0.48360782861709595, 0.483245849609375, 0.48328953981399536, 0.48498088121414185, 0.4841570556163788, 0.483938604593277, 0.48630398511886597, 0.48556753993034363, 0.4873899221420288, 0.4865598678588867, 0.48796409368515015, 0.48780182003974915, 0.4879578649997711, 0.488519549369812, 0.48809516429901123, 0.4881700575351715, 0.4912032186985016, 0.48931217193603516, 0.4886007010936737, 0.49066025018692017, 0.4916151165962219, 0.49162137508392334, 0.49328774213790894, 0.4924951195716858, 0.4955906867980957, 0.4936809241771698, 0.493793249130249, 0.494442343711853, 0.49484801292419434, 0.49582159519195557, 0.49737563729286194, 0.4948916733264923, 0.4962584674358368, 0.4972071349620819, 0.49522244930267334, 0.4976939260959625, 0.49799349904060364, 0.4980309307575226, 0.4987673759460449, 0.49928539991378784, 0.5002776980400085, 0.5001591444015503, 0.4989047050476074, 0.5019253492355347, 0.500933051109314, 0.5020189881324768, 0.5015820860862732, 0.5023372769355774, 0.5038164258003235, 0.5035542845726013, 0.5042282938957214, 0.5025744438171387, 0.5066685676574707, 0.5043219327926636, 0.5047088861465454, 0.5030050873756409, 0.5049210786819458, 0.505233108997345, 0.5060444474220276, 0.5073738098144531, 0.507604718208313, 0.5079230070114136, 0.5082350969314575, 0.5075298547744751, 0.5096330642700195, 0.5079042911529541, 0.5109749436378479, 0.5108688473701477, 0.5107439756393433, 0.5106441378593445, 0.5122168660163879, 0.5119172930717468, 0.5130032896995544, 0.5115865468978882, 0.5120670795440674, 0.5143575668334961, 0.5131655335426331, 0.5122855305671692, 0.5125726461410522, 0.513359010219574, 0.5153873562812805, 0.5146009922027588, 0.5140954256057739, 0.5155371427536011, 0.51540607213974], \"yaxis\": \"y2\"}, {\"line\": {\"color\": \"royalblue\", \"dash\": \"dot\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"validation_loss\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499], \"y\": [7.0811052322387695, 7.101848602294922, 7.090435981750488, 7.001238822937012, 6.886741638183594, 6.814002513885498, 6.741083145141602, 6.700465679168701, 6.6743316650390625, 6.641850471496582, 6.620259761810303, 6.593625068664551, 6.589068412780762, 6.578842639923096, 6.558661937713623, 6.549444675445557, 6.537961959838867, 6.5289506912231445, 6.517361640930176, 6.5008158683776855, 6.494589328765869, 6.5000691413879395, 6.493002414703369, 6.504294395446777, 6.5040154457092285, 6.504066467285156, 6.505837440490723, 6.513614177703857, 6.524117946624756, 6.528754711151123, 6.533158779144287, 6.53879976272583, 6.550942420959473, 6.569360256195068, 6.568551540374756, 6.577001571655273, 6.596731662750244, 6.602609157562256, 6.616481304168701, 6.630683898925781, 6.641595363616943, 6.642998218536377, 6.65492057800293, 6.673959255218506, 6.6845855712890625, 6.693271160125732, 6.723233222961426, 6.723042964935303, 6.735398292541504, 6.756357192993164, 6.756956100463867, 6.7870869636535645, 6.791988372802734, 6.813998699188232, 6.819335460662842, 6.841073989868164, 6.853143215179443, 6.858806133270264, 6.877065658569336, 6.890848159790039, 6.906373977661133, 6.9317545890808105, 6.93049430847168, 6.944567680358887, 6.974958896636963, 6.98774528503418, 7.0010857582092285, 7.020697116851807, 7.033700466156006, 7.0398454666137695, 7.05448579788208, 7.063262939453125, 7.078580379486084, 7.105457305908203, 7.130711078643799, 7.128904342651367, 7.146759986877441, 7.168460369110107, 7.1587371826171875, 7.198734283447266, 7.221553802490234, 7.219066143035889, 7.239317893981934, 7.244234085083008, 7.274664878845215, 7.272515773773193, 7.283438205718994, 7.2960357666015625, 7.329097747802734, 7.3549299240112305, 7.370049953460693, 7.3714599609375, 7.3922014236450195, 7.388037204742432, 7.429225921630859, 7.4100661277771, 7.434469223022461, 7.465261936187744, 7.485400199890137, 7.483192443847656, 7.49373722076416, 7.506464004516602, 7.536664962768555, 7.545938014984131, 7.562707424163818, 7.571969032287598, 7.596616268157959, 7.625345706939697, 7.601678371429443, 7.63006591796875, 7.651721477508545, 7.6534743309021, 7.692101001739502, 7.675325393676758, 7.701205730438232, 7.708262920379639, 7.715651988983154, 7.722330570220947, 7.752479076385498, 7.760960578918457, 7.776294708251953, 7.795327186584473, 7.798788547515869, 7.835936546325684, 7.829690933227539, 7.852116584777832, 7.875899314880371, 7.889072418212891, 7.887316703796387, 7.883529186248779, 7.9167962074279785, 7.944774627685547, 7.943746566772461, 7.945460319519043, 7.948983192443848, 7.991881370544434, 7.969258785247803, 8.028912544250488, 8.011883735656738, 8.017423629760742, 8.041860580444336, 8.071242332458496, 8.081646919250488, 8.058266639709473, 8.115095138549805, 8.113784790039062, 8.12731647491455, 8.14806842803955, 8.153298377990723, 8.143675804138184, 8.154038429260254, 8.157585144042969, 8.223134994506836, 8.203485488891602, 8.198715209960938, 8.22368049621582, 8.26600456237793, 8.288798332214355, 8.26154899597168, 8.259553909301758, 8.280402183532715, 8.290225982666016, 8.315468788146973, 8.329297065734863, 8.334005355834961, 8.346994400024414, 8.327754974365234, 8.3567533493042, 8.384794235229492, 8.396097183227539, 8.423657417297363, 8.40749454498291, 8.436782836914062, 8.436640739440918, 8.455733299255371, 8.460367202758789, 8.4896879196167, 8.473045349121094, 8.5108642578125, 8.54369831085205, 8.488730430603027, 8.53065299987793, 8.525118827819824, 8.557458877563477, 8.58045482635498, 8.57884693145752, 8.579798698425293, 8.604087829589844, 8.601811408996582, 8.62378978729248, 8.622810363769531, 8.641777038574219, 8.64533805847168, 8.65832233428955, 8.683515548706055, 8.691615104675293, 8.754294395446777, 8.668593406677246, 8.712483406066895, 8.71349811553955, 8.722867965698242, 8.726900100708008, 8.746829986572266, 8.767716407775879, 8.787223815917969, 8.769930839538574, 8.798505783081055, 8.807829856872559, 8.799479484558105, 8.810611724853516, 8.834456443786621, 8.814477920532227, 8.830406188964844, 8.826130867004395, 8.867487907409668, 8.923562049865723, 8.8707914352417, 8.890682220458984, 8.918107032775879, 8.932426452636719, 8.932161331176758, 8.956990242004395, 8.923675537109375, 8.926551818847656, 8.928370475769043, 8.962406158447266, 9.01309871673584, 8.975807189941406, 9.013347625732422, 9.0341157913208, 8.972091674804688, 9.007434844970703, 9.026371955871582, 9.042062759399414, 9.048633575439453, 9.028782844543457, 9.02031421661377, 9.03646469116211, 9.08127498626709, 9.08030891418457, 9.09367561340332, 9.134988784790039, 9.103424072265625, 9.138724327087402, 9.099093437194824, 9.148544311523438, 9.121636390686035, 9.139052391052246, 9.174615859985352, 9.154459953308105, 9.182940483093262, 9.19161319732666, 9.176226615905762, 9.191561698913574, 9.189057350158691, 9.243419647216797, 9.255827903747559, 9.227087020874023, 9.200124740600586, 9.278923034667969, 9.262886047363281, 9.245074272155762, 9.294384956359863, 9.316097259521484, 9.320127487182617, 9.271126747131348, 9.268879890441895, 9.312228202819824, 9.32699966430664, 9.30872631072998, 9.277027130126953, 9.315185546875, 9.353362083435059, 9.345064163208008, 9.292256355285645, 9.399405479431152, 9.392840385437012, 9.387420654296875, 9.384929656982422, 9.436405181884766, 9.38337230682373, 9.37002182006836, 9.40088939666748, 9.454127311706543, 9.420952796936035, 9.450101852416992, 9.475909233093262, 9.432161331176758, 9.438759803771973, 9.441463470458984, 9.47204303741455, 9.403733253479004, 9.456913948059082, 9.489250183105469, 9.472453117370605, 9.467790603637695, 9.447869300842285, 9.50535774230957, 9.495697975158691, 9.550504684448242, 9.494595527648926, 9.526615142822266, 9.571975708007812, 9.5604248046875, 9.520313262939453, 9.625659942626953, 9.599746704101562, 9.614375114440918, 9.619553565979004, 9.54300594329834, 9.58000659942627, 9.659143447875977, 9.65058422088623, 9.589821815490723, 9.686781883239746, 9.678272247314453, 9.641669273376465, 9.632264137268066, 9.678268432617188, 9.668156623840332, 9.700486183166504, 9.670654296875, 9.736562728881836, 9.714948654174805, 9.747123718261719, 9.710671424865723, 9.726539611816406, 9.767770767211914, 9.706463813781738, 9.687151908874512, 9.706415176391602, 9.693958282470703, 9.683018684387207, 9.801871299743652, 9.735254287719727, 9.724715232849121, 9.698816299438477, 9.753783226013184, 9.760106086730957, 9.839076042175293, 9.845850944519043, 9.855257987976074, 9.79184341430664, 9.765809059143066, 9.850480079650879, 9.797479629516602, 9.804856300354004, 9.857549667358398, 9.81493091583252, 9.823090553283691, 9.786590576171875, 9.7866849899292, 9.8911714553833, 9.788925170898438, 9.90186595916748, 9.879353523254395, 9.860163688659668, 9.89746379852295, 9.779236793518066, 9.85682201385498, 9.872174263000488, 9.904027938842773, 9.97659969329834, 9.994986534118652, 9.93973159790039, 9.892644882202148, 9.907636642456055, 9.947927474975586, 9.991455078125, 9.984703063964844, 9.985127449035645, 9.975567817687988, 9.97638988494873, 9.952582359313965, 9.976996421813965, 9.938711166381836, 10.002985000610352, 10.014431953430176, 10.014984130859375, 10.060877799987793, 10.088844299316406, 10.02536392211914, 9.989370346069336, 10.029144287109375, 9.94666576385498, 10.048295974731445, 10.043638229370117, 10.055829048156738, 10.002419471740723, 10.03606128692627, 9.985846519470215, 10.056924819946289, 10.046748161315918, 10.043429374694824, 10.057329177856445, 10.089051246643066, 10.093863487243652, 10.153517723083496, 10.104842185974121, 10.064675331115723, 10.149765968322754, 10.174967765808105, 10.1535005569458, 10.148859977722168, 10.098540306091309, 10.18799114227295, 10.151997566223145, 10.110013008117676, 10.152444839477539, 10.204248428344727, 10.182126998901367, 10.177501678466797, 10.136330604553223, 10.192605018615723, 10.156577110290527, 10.183003425598145, 10.133132934570312, 10.110381126403809, 10.160709381103516, 10.199335098266602, 10.191929817199707, 10.230559349060059, 10.198878288269043, 10.20158863067627, 10.221324920654297, 10.235447883605957, 10.189408302307129, 10.219768524169922, 10.25086498260498, 10.29871654510498, 10.25256061553955, 10.304192543029785, 10.194900512695312, 10.247417449951172, 10.246251106262207, 10.29559326171875, 10.261749267578125, 10.271471977233887, 10.33713436126709, 10.273933410644531, 10.226823806762695, 10.266448974609375, 10.23887825012207, 10.33549976348877, 10.311206817626953, 10.280656814575195, 10.298513412475586, 10.356525421142578, 10.356785774230957, 10.358695983886719, 10.318659782409668, 10.338214874267578, 10.333951950073242, 10.359245300292969, 10.304974555969238, 10.414581298828125, 10.360187530517578, 10.422396659851074, 10.383631706237793, 10.391356468200684, 10.337711334228516, 10.399136543273926, 10.380802154541016, 10.424531936645508, 10.395012855529785, 10.465195655822754, 10.338091850280762, 10.4320068359375, 10.43752384185791, 10.413241386413574, 10.444828987121582, 10.409032821655273, 10.471036911010742, 10.342068672180176, 10.471902847290039, 10.459872245788574, 10.41877269744873, 10.499322891235352, 10.444331169128418, 10.44308853149414, 10.461743354797363, 10.463170051574707, 10.444615364074707, 10.432865142822266, 10.487117767333984, 10.523528099060059, 10.545230865478516, 10.504417419433594, 10.468966484069824, 10.44719123840332, 10.427950859069824, 10.499178886413574, 10.495201110839844, 10.548486709594727, 10.526596069335938, 10.525449752807617, 10.437758445739746, 10.4793119430542, 10.520360946655273, 10.438840866088867]}, {\"line\": {\"color\": \"firebrick\", \"dash\": \"dot\", \"width\": 2}, \"mode\": \"lines\", \"name\": \"validation_accuracy\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499], \"xaxis\": \"x\", \"y\": [0.05711717903614044, 0.05711717903614044, 0.05711717903614044, 0.05711717903614044, 0.06867542117834091, 0.0748165175318718, 0.08243047446012497, 0.08530130982398987, 0.09149233251810074, 0.0948624461889267, 0.0980827808380127, 0.10175246000289917, 0.10320036113262177, 0.1059214174747467, 0.10819312185049057, 0.10959109663963318, 0.11243696510791779, 0.11338558793067932, 0.11515802145004272, 0.11842828243970871, 0.11912726610898972, 0.11875280737876892, 0.12055020034313202, 0.12147386372089386, 0.1216985359787941, 0.12402017414569855, 0.12509360909461975, 0.12649159133434296, 0.12626691162586212, 0.1270158290863037, 0.12721553444862366, 0.1295870989561081, 0.1320335566997528, 0.13081032037734985, 0.13368116319179535, 0.13223326206207275, 0.13413050770759583, 0.13512906432151794, 0.13575315475463867, 0.1353038102388382, 0.1381496787071228, 0.13877378404140472, 0.13944779336452484, 0.13972240686416626, 0.1399720460176468, 0.1403215378522873, 0.14094562828540802, 0.14189425110816956, 0.14184433221817017, 0.143466979265213, 0.14449049532413483, 0.14518947899341583, 0.1459883153438568, 0.14611314237117767, 0.14696191251277924, 0.14796045422554016, 0.14791053533554077, 0.1489090770483017, 0.15008237957954407, 0.14908382296562195, 0.15083129703998566, 0.1503569781780243, 0.1499325931072235, 0.15220430493354797, 0.14950820803642273, 0.1517299860715866, 0.15220430493354797, 0.152104452252388, 0.15267860889434814, 0.15312796831130981, 0.1549253612756729, 0.15417644381523132, 0.1553747057914734, 0.1549253612756729, 0.1560736894607544, 0.1570972055196762, 0.1564231812953949, 0.1574966311454773, 0.1588696390390396, 0.15879474580287933, 0.15772131085395813, 0.158220574259758, 0.15809576213359833, 0.16054221987724304, 0.15944381058216095, 0.16059213876724243, 0.16169054806232452, 0.16061709821224213, 0.16064207255840302, 0.16079185903072357, 0.16418692469596863, 0.1635378748178482, 0.16411203145980835, 0.16383743286132812, 0.16483598947525024, 0.1661091446876526, 0.16481103003025055, 0.16590942442417145, 0.16735732555389404, 0.1653851866722107, 0.16673323512077332, 0.1692545861005783, 0.16673323512077332, 0.1682560294866562, 0.1682060956954956, 0.1678066849708557, 0.16942933201789856, 0.1703280210494995, 0.1689799726009369, 0.17087723314762115, 0.17025312781333923, 0.1728493720293045, 0.17349842190742493, 0.1710519790649414, 0.17257477343082428, 0.17377303540706635, 0.17384791374206543, 0.17449697852134705, 0.17459683120250702, 0.17552049458026886, 0.17621947824954987, 0.17479655146598816, 0.1764940768480301, 0.17761746048927307, 0.1761196255683899, 0.17584502696990967, 0.1761445850133896, 0.1775175929069519, 0.17844125628471375, 0.17869089543819427, 0.17661890387535095, 0.1778670996427536, 0.1785660833120346, 0.18066303431987762, 0.1807878613471985, 0.18023864924907684, 0.1821608692407608, 0.18131209909915924, 0.18305955827236176, 0.18410804867744446, 0.18445754051208496, 0.18498177826404572, 0.18378351628780365, 0.18600529432296753, 0.18488192558288574, 0.18498177826404572, 0.1843077540397644, 0.185755655169487, 0.18568076193332672, 0.18627989292144775, 0.1868790239095688, 0.18655449151992798, 0.18750311434268951, 0.18979978561401367, 0.18872635066509247, 0.1882520318031311, 0.18977482616901398, 0.1886514574289322, 0.188975989818573, 0.19027410447597504, 0.1904488503932953, 0.19172200560569763, 0.18977482616901398, 0.18984971940517426, 0.19029906392097473, 0.19349443912506104, 0.1917968988418579, 0.1925957351922989, 0.1936691850423813, 0.19334465265274048, 0.19481751322746277, 0.19496729969978333, 0.19461780786514282, 0.19314493238925934, 0.19411852955818176, 0.1957411766052246, 0.19496729969978333, 0.19671475887298584, 0.19678965210914612, 0.19621548056602478, 0.19693943858146667, 0.19676469266414642, 0.1968895047903061, 0.19691447913646698, 0.1975885033607483, 0.19918617606163025, 0.19873683154582977, 0.19803784787654877, 0.1996854543685913, 0.19943581521511078, 0.199710413813591, 0.19996005296707153, 0.20060911774635315, 0.2007589042186737, 0.2004842907190323, 0.20065905153751373, 0.20303060114383698, 0.20195716619491577, 0.20280593633651733, 0.20375455915927887, 0.202930748462677, 0.2036047726869583, 0.20323032140731812, 0.2043287307024002, 0.2043786495923996, 0.20457835495471954, 0.20642568171024323, 0.20712466537952423, 0.2054770588874817, 0.20592640340328217, 0.20487792789936066, 0.2065255343914032, 0.20709970593452454, 0.20729941129684448, 0.20879724621772766, 0.20802336931228638, 0.20804832875728607, 0.20907184481620789, 0.20912177860736847, 0.20949622988700867, 0.2090219110250473, 0.2097209095954895, 0.21051974594593048, 0.2115432620048523, 0.2108442783355713, 0.210769385099411, 0.21174296736717224, 0.21209245920181274, 0.2111688107252121, 0.21246692538261414, 0.2125917375087738, 0.2147136628627777, 0.21391482651233673, 0.2129662036895752, 0.21458885073661804, 0.2147386223077774, 0.21319086849689484, 0.21411453187465668, 0.21271656453609467, 0.2158370316028595, 0.21641120314598083, 0.21683558821678162, 0.21641120314598083, 0.21701033413410187, 0.2165110558271408, 0.2187328338623047, 0.21698537468910217, 0.21743471920490265, 0.21628639101982117, 0.21960656344890594, 0.21890757977962494, 0.21883268654346466, 0.21985620260238647, 0.21980628371238708, 0.21930700540542603, 0.22053022682666779, 0.22055520117282867, 0.2208547592163086, 0.22205302119255066, 0.22397524118423462, 0.2222527265548706, 0.22160367667675018, 0.2233511358499527, 0.22275200486183167, 0.22360077500343323, 0.22355085611343384, 0.22177842259407043, 0.2241000533103943, 0.22340106964111328, 0.2237256020307541, 0.22392530739307404, 0.2233012169599533, 0.22492386400699615, 0.22599729895591736, 0.2262219786643982, 0.22529831528663635, 0.22697089612483978, 0.22524839639663696, 0.2265964299440384, 0.2265215367078781, 0.22642168402671814, 0.22709570825099945, 0.22604723274707794, 0.22664636373519897, 0.22776973247528076, 0.22724549472332, 0.2290928214788437, 0.22891807556152344, 0.22854360938072205, 0.22931748628616333, 0.22999151051044464, 0.23006640374660492, 0.22829397022724152, 0.23061560094356537, 0.23006640374660492, 0.23034100234508514, 0.23143941164016724, 0.23099006712436676, 0.2322881817817688, 0.23039093613624573, 0.23223824799060822, 0.2316141575574875, 0.23178890347480774, 0.23103998601436615, 0.23293724656105042, 0.23391082882881165, 0.23293724656105042, 0.23308701813220978, 0.23276250064373016, 0.23321184515953064, 0.2337111234664917, 0.2326127141714096, 0.23308701813220978, 0.23426032066345215, 0.23416046798229218, 0.234385147690773, 0.23493434488773346, 0.23530879616737366, 0.23383593559265137, 0.23448500037193298, 0.23388586938381195, 0.23533377051353455, 0.23323680460453033, 0.23595786094665527, 0.23685656487941742, 0.23650705814361572, 0.2354835420846939, 0.23783014714717865, 0.23638224601745605, 0.23758050799369812, 0.23788008093833923, 0.23608267307281494, 0.23720605671405792, 0.2376554012298584, 0.23827949166297913, 0.23795495927333832, 0.23920315504074097, 0.23815467953681946, 0.2390533685684204, 0.2409256547689438, 0.23758050799369812, 0.24005192518234253, 0.24080084264278412, 0.24032652378082275, 0.2401517778635025, 0.23817963898181915, 0.24112537503242493, 0.23967747390270233, 0.239802286028862, 0.24070098996162415, 0.24115033447742462, 0.24212391674518585, 0.24152478575706482, 0.23985221982002258, 0.2416246384382248, 0.24284787476062775, 0.24137499928474426, 0.24257327616214752, 0.24359677731990814, 0.2426231950521469, 0.2441210299730301, 0.24147486686706543, 0.24169953167438507, 0.243022620677948, 0.24437066912651062, 0.24312247335910797, 0.24357181787490845, 0.2433970719575882, 0.24422088265419006, 0.24344700574874878, 0.24462029337882996, 0.24579359591007233, 0.24486993253231049, 0.2448200136423111, 0.24634280800819397, 0.24529431760311127, 0.24651755392551422, 0.2462679147720337, 0.24828997254371643, 0.24631783366203308, 0.2465674728155136, 0.2455189973115921, 0.24779070913791656, 0.24566878378391266, 0.24853961169719696, 0.24794048070907593, 0.246941938996315, 0.24789056181907654, 0.24809026718139648, 0.24736632406711578, 0.24601827561855316, 0.2483898401260376, 0.24958810210227966, 0.24973787367343903, 0.24918867647647858, 0.24796545505523682, 0.2498627007007599, 0.24901393055915833, 0.2509361505508423, 0.25076138973236084, 0.2501123249530792, 0.2512606680393219, 0.24828997254371643, 0.25138548016548157, 0.25036197900772095, 0.25243398547172546, 0.25255879759788513, 0.25111088156700134, 0.25041189789772034, 0.2519596517086029, 0.25255879759788513, 0.254181444644928, 0.25315791368484497, 0.2512107491493225, 0.2512856423854828, 0.254181444644928, 0.2534574866294861, 0.2533825933933258, 0.25223425030708313, 0.25353237986564636, 0.25508013367652893, 0.2544809877872467, 0.2548554539680481, 0.2540316581726074, 0.2552049458026886, 0.25353237986564636, 0.2541564702987671, 0.2541564702987671, 0.25530481338500977, 0.2556293308734894, 0.25605371594429016, 0.25537970662117004, 0.2547306418418884, 0.2549053728580475, 0.25602877140045166, 0.25652801990509033, 0.2566278874874115, 0.25607869029045105, 0.2566778063774109, 0.2573268711566925, 0.2577013373374939, 0.2573518455028534, 0.2563033699989319, 0.25650307536125183, 0.25787606835365295, 0.25782614946365356, 0.25707724690437317, 0.2583504021167755, 0.25790104269981384, 0.2572270333766937, 0.25902441143989563, 0.2580508291721344, 0.2602476477622986, 0.25967347621917725, 0.25862500071525574, 0.2597982883453369, 0.2594238221645355, 0.2590493857860565, 0.25972339510917664, 0.258000910282135, 0.26007288694381714, 0.26137101650238037, 0.260097861289978, 0.26034748554229736, 0.2612212300300598, 0.26004794239997864, 0.261321097612381, 0.2611713111400604, 0.262020081281662, 0.259773313999176, 0.26137101650238037, 0.260996550321579, 0.2620450258255005, 0.2627440094947815, 0.2612462043762207, 0.26291877031326294, 0.2625942528247833, 0.263093501329422, 0.26319336891174316, 0.26366767287254333, 0.2624194920063019, 0.2626441717147827, 0.2641420066356659, 0.26329323649406433, 0.26286885142326355, 0.26394227147102356, 0.26359277963638306, 0.2640671133995056, 0.2644166052341461, 0.26549002528190613, 0.26651355624198914, 0.26501572132110596, 0.2655898928642273, 0.26466622948646545, 0.26509061455726624, 0.2665884494781494, 0.265839546918869, 0.2656398117542267, 0.2661890387535095, 0.2666383683681488], \"yaxis\": \"y2\"}],\n",
              "                        {\"legend\": {\"orientation\": \"h\"}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Training Metrics\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.94]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"tickfont\": {\"color\": \"royalblue\"}, \"title\": {\"font\": {\"color\": \"royalblue\"}, \"text\": \"Loss\"}}, \"yaxis2\": {\"anchor\": \"x\", \"overlaying\": \"y\", \"side\": \"right\", \"tickfont\": {\"color\": \"firebrick\"}, \"title\": {\"font\": {\"color\": \"firebrick\"}, \"text\": \"Accuracy\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dc2c2089-688c-4027-84aa-30c456c68a31');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMTPlfM8I_Wd",
        "colab_type": "text"
      },
      "source": [
        "# Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W8epfdOM9vm",
        "colab_type": "text"
      },
      "source": [
        "### 100 Epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn7qrsCu-LI9",
        "colab_type": "text"
      },
      "source": [
        "<tr>\n",
        "    <th>LSTM Layers</th>\n",
        "    <th>LSTM Cells per Layer</th>\n",
        "    <th>Dropout %</th>\n",
        "    <th>Validation Loss</th>\n",
        "    <th>Validation Accuracy</th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>1</td>\n",
        "    <td>64</td>\n",
        "    <td>0.2</td>\n",
        "    <td>8.9918</td>\n",
        "    <td>0.2271</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>1</td>\n",
        "    <td>256</td>\n",
        "    <td>0.2</td>\n",
        "    <td>10.7950</td>\n",
        "    <td>0.2354</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>1</td>\n",
        "    <td>256</td>\n",
        "    <td>0.5</td>\n",
        "    <td>8.9682</td>\n",
        "    <td>0.2153</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>2</td>\n",
        "    <td>64</td>\n",
        "    <td>0.2, 0.5</td>\n",
        "    <td>6.9549</td>\n",
        "    <td>0.1490</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>2</td>\n",
        "    <td>256</td>\n",
        "    <td>0.2, 0.5</td>\n",
        "    <td>7.4581</td>\n",
        "    <td>0.1683</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>2</td>\n",
        "    <td>256</td>\n",
        "    <td>0.5, 0.5</td>\n",
        "    <td>7.3286</td>\n",
        "    <td>0.1650</td>\n",
        "</tr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXjdqe2PNKFv",
        "colab_type": "text"
      },
      "source": [
        "### 500 Epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUnZhzWmNGKs",
        "colab_type": "text"
      },
      "source": [
        "<tr>\n",
        "    <th>LSTM Layers</th>\n",
        "    <th>LSTM Cells per Layer</th>\n",
        "    <th>Dropout %</th>\n",
        "    <th>Validation Loss</th>\n",
        "    <th>Validation Accuracy</th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>1</td>\n",
        "    <td>64</td>\n",
        "    <td>0.2</td>\n",
        "    <td>16.4351</td>\n",
        "    <td>0.3229</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>1</td>\n",
        "    <td>256</td>\n",
        "    <td>0.2</td>\n",
        "    <td>22.5922</td>\n",
        "    <td>0.3373</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>1</td>\n",
        "    <td>256</td>\n",
        "    <td>0.5</td>\n",
        "    <td>18.8511</td>\n",
        "    <td>0.3329</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>2</td>\n",
        "    <td>64</td>\n",
        "    <td>0.2, 0.5</td>\n",
        "    <td>8.8127</td>\n",
        "    <td>0.2230</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>2</td>\n",
        "    <td>256</td>\n",
        "    <td>0.2, 0.5</td>\n",
        "    <td>10.8240</td>\n",
        "    <td>0.2854</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td>2</td>\n",
        "    <td>256</td>\n",
        "    <td>0.5, 0.5</td>\n",
        "    <td>10.4388</td>\n",
        "    <td>0.2666</td>\n",
        "</tr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TPnMMNvDAXC",
        "colab_type": "text"
      },
      "source": [
        "# Generate Text Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rmhEm6UESld",
        "colab_type": "text"
      },
      "source": [
        "### Load Objects To Infer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbsosSoSDBVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_filepath = os.path.join(ROOT_FOLDER, 'models', f'{content_type}-custom-2.h5')\n",
        "model = load_model(model_filepath)\n",
        "TRAINING_LENGTH = 10"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j56FokGJQUKc",
        "colab_type": "text"
      },
      "source": [
        "## Existing Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68jLzLENLLOK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "a9423db7-7860-4a7d-ca1a-b1d20c21a49c"
      },
      "source": [
        "original_sequence, gen_list, a = predict_utils.generate_output(\n",
        "    model,\n",
        "    sequences,\n",
        "    idx_word,\n",
        "    seed_length=TRAINING_LENGTH,\n",
        "    new_words=20,\n",
        "    diversity=1,\n",
        "    n_gen=1\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/src/predict_utils.py:42: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faaae033d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFkDMZOGLRKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46b6853e-1a0b-48b3-b5b1-4c48a79999fb"
      },
      "source": [
        "' '.join(word for word in original_sequence)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'and the current generation of mobiles using flash technology can'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x2HCA1iLRMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9493b70c-2fce-4044-bcad-12104394c8e6"
      },
      "source": [
        "' '.join(word for word in gen_list[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'< --- > store data for phones but some readers of the file sharing and both yahoo and bt in europe in the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmsySNZULlku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27d4747f-1f48-4e8e-c65b-095ebff456c3"
      },
      "source": [
        "' '.join(word for word in a)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'< --- > store up to one gigabyte of music enough for 250 songs we are working in the hard disk area and'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6sCL1XKLlo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "661cf7b2-0d72-47e8-805a-85d3b2e7f7c9"
      },
      "source": [
        "original_sequence, gen_list, a = predict_utils.generate_output(\n",
        "    model,\n",
        "    sequences,\n",
        "    idx_word,\n",
        "    seed_length=TRAINING_LENGTH,\n",
        "    new_words=20,\n",
        "    diversity=1,\n",
        "    n_gen=1\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/src/predict_utils.py:42: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYsGgzbRau3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ca31161-6ea4-49b9-bdb2-2872516ab903"
      },
      "source": [
        "' '.join(word for word in original_sequence)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'cut between 6 000 and 7 000 jobs and reduce'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trkWmwsXau7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b684a1b6-12db-41ce-8f42-7e6544fdc4bb"
      },
      "source": [
        "' '.join(word for word in gen_list[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'< --- > costs up from looking for to a international based development in california said iptv was scrapped in japan in 1976'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ckuynmaau-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d97ec79-8859-4545-c37a-24ff15a18f7c"
      },
      "source": [
        "' '.join(word for word in a)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'< --- > costs by 5bn £2 7bn a year analysts had warned recently that the airline might have to seek chapter 11'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VosI6KPavBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxudAXauQRiT",
        "colab_type": "text"
      },
      "source": [
        "## Custom Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvCuoZqgLls7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "875e9092-97c5-4101-d8ee-46ddf5c6a9e0"
      },
      "source": [
        "sentence = 'Stocks of major large technology firms are becoming even more fragile even though'\n",
        "predict_utils.generate_custom_sentence(sentence, word_idx, idx_word, model, new_words=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[None, 3, 546, 490, 45, 126, 13, 518, 150, 24, 9544, 150, 456]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-c04f970c9511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Stocks of major large technology firms are becoming even more fragile even though'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredict_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_custom_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/My Drive/Code/autocomplete_me/src/predict_utils.py\u001b[0m in \u001b[0;36mgenerate_custom_sentence\u001b[0;34m(sentence, word_idx, idx_word, model, new_words, diversity)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Make a prediction from the seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \t\tpreds = model.predict(np.array(seed).reshape(1, -1))[0].astype(\n\u001b[0m\u001b[1;32m     93\u001b[0m \t\t\tnp.float64)\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m                **kwargs):\n\u001b[1;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1006\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8_8bcGDQaG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "74b90cde-dcae-4035-ffc8-a9cb39a67f38"
      },
      "source": [
        "sentence = 'However, there have been many instances of'\n",
        "predict_utils.generate_custom_sentence(sentence, word_idx, idx_word, model, new_words=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[None, 56, 18, 46, 67, 7424, 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-833bdbd219b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'However, there have been many instances of'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredict_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_custom_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/drive/My Drive/Code/autocomplete_me/src/predict_utils.py\u001b[0m in \u001b[0;36mgenerate_custom_sentence\u001b[0;34m(sentence, word_idx, idx_word, model, new_words, diversity)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Make a prediction from the seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \t\tpreds = model.predict(np.array(seed).reshape(1, -1))[0].astype(\n\u001b[0m\u001b[1;32m     93\u001b[0m \t\t\tnp.float64)\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m                **kwargs):\n\u001b[1;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1006\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "240jLlPSQvDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}