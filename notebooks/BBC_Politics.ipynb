{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "BBC Politics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRwiWNu6INq5",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5LjiPvdBUHV",
        "colab_type": "text"
      },
      "source": [
        "## Google Only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjSCr2_-BUHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ad254e4f-cc7e-4e2c-b463-39543f39179e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvs4RSdij9st",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAJzt-moBUHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
        "sys.path.append('/content/drive/My Drive/Code/autocomplete_me')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3cVnuFRvRK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c42e4f71-3948-4d08-9737-4c8c7fd1f13f"
      },
      "source": [
        "!ls -l '/content/drive/My Drive/Code/autocomplete_me/src'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "-rw------- 1 root root 2516 Jul 12 14:10 predict_utils.py\n",
            "drwx------ 2 root root 4096 Jul 11 13:20 __pycache__\n",
            "-rw------- 1 root root 3266 Jul 12 16:08 reader.py\n",
            "-rw------- 1 root root 9341 Jul 12 14:24 utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q94gYQGGBUHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3eff1f49-e7d7-4a7a-b8e3-bf1db4f75ad4"
      },
      "source": [
        "from src import utils, reader, predict_utils"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK5LK2ohBUHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a43e8b4c-bb42-4298-d3bc-11fa2cb8c291"
      },
      "source": [
        "from importlib import reload\n",
        "reload(utils)\n",
        "reload(reader)\n",
        "reload(predict_utils)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'src.predict_utils' from '/content/drive/My Drive/Code/autocomplete_me/src/predict_utils.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2i_aQqeF444",
        "colab_type": "text"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6ACaCZLF9wP",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGdkdzSeBUHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = reader.read_bbc_politics()\n",
        "content_type = 'BBC-pol'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFB5H3BdLHAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "9690e3ef-2027-4a3b-f00e-7db3c90c7b46"
      },
      "source": [
        "text[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Tory expert denies defeat warning\\n\\nThe Conservatives\\' campaign director has denied a report claiming he warned Michael Howard the party could not win the next general election.\\n\\nThe Times on Monday said Australian Lynton Crosby told the party leader to focus on trying to increase the Tories\\' Commons presence by 25 to 30 seats. But Mr Crosby said in a statement: \"I have never had any such conversation... and I do not hold that view.\" Mr Howard later added there was not \"one iota\" of truth in the report. The strategist helped Australia\\'s PM, John Howard, win four elections. Mr Howard appointed Mr Crosby as his elections chief last October. Mr Crosby\\'s statement said: \"The Conservative Party has been making an impact on the issues of lower tax and controlled immigration over the past week.\" It added: \"The Labour Party will be wanting to do all they can to distract attention away from the issues that really matter to people.\"\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82o452gPmCxw",
        "colab_type": "text"
      },
      "source": [
        "### Long Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE3FbA3KBUHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68e8faa3-defa-47d1-8140-bafb427a8653"
      },
      "source": [
        "training_dict, word_idx, idx_word, sequences, num_words = utils.get_data(text)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 14136 unique words.\n",
            "There are 183458 sequences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkarC33qBUHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "69d0b610-e66f-4847-87a4-26ffb5468418"
      },
      "source": [
        "# embedding_matrix = utils.create_embedding_matrix(word_idx, num_words, '/Users/jaipancholi/data/glove.6B.100d.txt')\n",
        "embedding_matrix = utils.create_embedding_matrix(word_idx, num_words, '/content/drive/My Drive/Code/autocomplete_me/data/glove.6B.100d.txt')\n",
        "embedding_matrix"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove Vectors loading with dimension 100\n",
            "There were 4852 words without pre-trained embeddings.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/src/utils.py:175: RuntimeWarning: invalid value encountered in true_divide\n",
            "  embedding_matrix = embedding_matrix / np.linalg.norm(embedding_matrix, axis=1).reshape((-1, 1))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.00656124, -0.04206555,  0.12508174, ..., -0.02506376,\n",
              "         0.14220549,  0.04648907],\n",
              "       [-0.06223089,  0.03835242,  0.08488411, ..., -0.04284497,\n",
              "         0.08662399, -0.00527513],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M60nF8u2IW0",
        "colab_type": "text"
      },
      "source": [
        "#### Unidirectional, 1 layer, Trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f6U2I-p2Iej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = utils.make_word_level_model(\n",
        "    num_words,\n",
        "    embedding_matrix,\n",
        "    lstm_cells=64,\n",
        "    trainable=True,\n",
        "    lstm_layers=1,\n",
        "    bi_direc=False\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpytakqX2IhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9704f1b0-b178-4da5-c042-4782897556c6"
      },
      "source": [
        "train_history = utils.train_model(\n",
        "    training_dict,\n",
        "    f'{content_type}_uni-1_layer-trainable-50_seq',\n",
        "    model=model,\n",
        "    # use_pretrained_model=True,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 128420 samples, validate on 55038 samples\n",
            "Epoch 1/150\n",
            "128420/128420 [==============================] - 20s 154us/step - loss: 7.7903 - accuracy: 0.0392 - val_loss: 6.9065 - val_accuracy: 0.0537\n",
            "Epoch 2/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 6.8572 - accuracy: 0.0509 - val_loss: 6.8394 - val_accuracy: 0.0537\n",
            "Epoch 3/150\n",
            "128420/128420 [==============================] - 18s 139us/step - loss: 6.7501 - accuracy: 0.0516 - val_loss: 6.8059 - val_accuracy: 0.0537\n",
            "Epoch 4/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 6.6999 - accuracy: 0.0531 - val_loss: 6.8094 - val_accuracy: 0.0646\n",
            "Epoch 5/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 6.6622 - accuracy: 0.0614 - val_loss: 6.7902 - val_accuracy: 0.0692\n",
            "Epoch 6/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 6.5839 - accuracy: 0.0724 - val_loss: 6.7004 - val_accuracy: 0.0750\n",
            "Epoch 7/150\n",
            "128420/128420 [==============================] - 18s 138us/step - loss: 6.4802 - accuracy: 0.0775 - val_loss: 6.6197 - val_accuracy: 0.0790\n",
            "Epoch 8/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 6.3747 - accuracy: 0.0840 - val_loss: 6.5391 - val_accuracy: 0.0891\n",
            "Epoch 9/150\n",
            "128420/128420 [==============================] - 18s 138us/step - loss: 6.2740 - accuracy: 0.0897 - val_loss: 6.4692 - val_accuracy: 0.0956\n",
            "Epoch 10/150\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 6.1785 - accuracy: 0.0950 - val_loss: 6.4155 - val_accuracy: 0.1027\n",
            "Epoch 11/150\n",
            "128420/128420 [==============================] - 18s 136us/step - loss: 6.1015 - accuracy: 0.0996 - val_loss: 6.3792 - val_accuracy: 0.1030\n",
            "Epoch 12/150\n",
            "128420/128420 [==============================] - 18s 139us/step - loss: 6.0343 - accuracy: 0.1066 - val_loss: 6.3583 - val_accuracy: 0.1129\n",
            "Epoch 13/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 5.9731 - accuracy: 0.1112 - val_loss: 6.3332 - val_accuracy: 0.1165\n",
            "Epoch 14/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 5.9149 - accuracy: 0.1160 - val_loss: 6.3158 - val_accuracy: 0.1184\n",
            "Epoch 15/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 5.8590 - accuracy: 0.1227 - val_loss: 6.2863 - val_accuracy: 0.1223\n",
            "Epoch 16/150\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 5.7970 - accuracy: 0.1280 - val_loss: 6.2608 - val_accuracy: 0.1278\n",
            "Epoch 17/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 5.7327 - accuracy: 0.1339 - val_loss: 6.2327 - val_accuracy: 0.1318\n",
            "Epoch 18/150\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 5.6719 - accuracy: 0.1383 - val_loss: 6.2115 - val_accuracy: 0.1349\n",
            "Epoch 19/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 5.6101 - accuracy: 0.1422 - val_loss: 6.1900 - val_accuracy: 0.1389\n",
            "Epoch 20/150\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 5.5471 - accuracy: 0.1467 - val_loss: 6.1688 - val_accuracy: 0.1411\n",
            "Epoch 21/150\n",
            "128420/128420 [==============================] - 17s 135us/step - loss: 5.4911 - accuracy: 0.1491 - val_loss: 6.1435 - val_accuracy: 0.1428\n",
            "Epoch 22/150\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 5.4322 - accuracy: 0.1533 - val_loss: 6.1280 - val_accuracy: 0.1461\n",
            "Epoch 23/150\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 5.3801 - accuracy: 0.1564 - val_loss: 6.1523 - val_accuracy: 0.1484\n",
            "Epoch 24/150\n",
            "128420/128420 [==============================] - 17s 135us/step - loss: 5.3325 - accuracy: 0.1585 - val_loss: 6.1457 - val_accuracy: 0.1500\n",
            "Epoch 25/150\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 5.2873 - accuracy: 0.1620 - val_loss: 6.1296 - val_accuracy: 0.1509\n",
            "Epoch 26/150\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 5.2454 - accuracy: 0.1647 - val_loss: 6.1483 - val_accuracy: 0.1528\n",
            "Epoch 27/150\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 5.2055 - accuracy: 0.1666 - val_loss: 6.1528 - val_accuracy: 0.1536\n",
            "Epoch 28/150\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 5.1619 - accuracy: 0.1688 - val_loss: 6.1630 - val_accuracy: 0.1557\n",
            "Epoch 29/150\n",
            "128420/128420 [==============================] - 17s 135us/step - loss: 5.1218 - accuracy: 0.1716 - val_loss: 6.1609 - val_accuracy: 0.1554\n",
            "Epoch 30/150\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 5.0768 - accuracy: 0.1736 - val_loss: 6.1718 - val_accuracy: 0.1565\n",
            "Epoch 31/150\n",
            "128420/128420 [==============================] - 17s 135us/step - loss: 5.0428 - accuracy: 0.1766 - val_loss: 6.1971 - val_accuracy: 0.1578\n",
            "Epoch 32/150\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 5.0064 - accuracy: 0.1790 - val_loss: 6.2039 - val_accuracy: 0.1579\n",
            "Epoch 33/150\n",
            "128420/128420 [==============================] - 17s 135us/step - loss: 4.9630 - accuracy: 0.1812 - val_loss: 6.2070 - val_accuracy: 0.1597\n",
            "Epoch 34/150\n",
            "128420/128420 [==============================] - 17s 135us/step - loss: 4.9309 - accuracy: 0.1846 - val_loss: 6.2261 - val_accuracy: 0.1599\n",
            "Epoch 35/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.8952 - accuracy: 0.1866 - val_loss: 6.2305 - val_accuracy: 0.1617\n",
            "Epoch 36/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.8573 - accuracy: 0.1886 - val_loss: 6.2365 - val_accuracy: 0.1627\n",
            "Epoch 37/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 4.8229 - accuracy: 0.1900 - val_loss: 6.2896 - val_accuracy: 0.1627\n",
            "Epoch 38/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.7860 - accuracy: 0.1931 - val_loss: 6.2901 - val_accuracy: 0.1639\n",
            "Epoch 39/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.7493 - accuracy: 0.1950 - val_loss: 6.2997 - val_accuracy: 0.1640\n",
            "Epoch 40/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.7144 - accuracy: 0.1978 - val_loss: 6.3267 - val_accuracy: 0.1657\n",
            "Epoch 41/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 4.6813 - accuracy: 0.1981 - val_loss: 6.3177 - val_accuracy: 0.1666\n",
            "Epoch 42/150\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 4.6452 - accuracy: 0.2014 - val_loss: 6.3608 - val_accuracy: 0.1668\n",
            "Epoch 43/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 4.6150 - accuracy: 0.2028 - val_loss: 6.3688 - val_accuracy: 0.1681\n",
            "Epoch 44/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 4.5856 - accuracy: 0.2041 - val_loss: 6.3687 - val_accuracy: 0.1682\n",
            "Epoch 45/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.5504 - accuracy: 0.2071 - val_loss: 6.4194 - val_accuracy: 0.1681\n",
            "Epoch 46/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.5247 - accuracy: 0.2088 - val_loss: 6.4337 - val_accuracy: 0.1690\n",
            "Epoch 47/150\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 4.4911 - accuracy: 0.2106 - val_loss: 6.4320 - val_accuracy: 0.1699\n",
            "Epoch 48/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.4674 - accuracy: 0.2122 - val_loss: 6.4454 - val_accuracy: 0.1704\n",
            "Epoch 49/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.4348 - accuracy: 0.2138 - val_loss: 6.5023 - val_accuracy: 0.1712\n",
            "Epoch 50/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.4098 - accuracy: 0.2145 - val_loss: 6.5235 - val_accuracy: 0.1715\n",
            "Epoch 51/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.3819 - accuracy: 0.2167 - val_loss: 6.5302 - val_accuracy: 0.1721\n",
            "Epoch 52/150\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 4.3504 - accuracy: 0.2196 - val_loss: 6.5647 - val_accuracy: 0.1721\n",
            "Epoch 53/150\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 4.3230 - accuracy: 0.2214 - val_loss: 6.6015 - val_accuracy: 0.1728\n",
            "Epoch 54/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.2937 - accuracy: 0.2234 - val_loss: 6.6013 - val_accuracy: 0.1735\n",
            "Epoch 55/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 4.2691 - accuracy: 0.2233 - val_loss: 6.6615 - val_accuracy: 0.1738\n",
            "Epoch 56/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 4.2468 - accuracy: 0.2268 - val_loss: 6.6456 - val_accuracy: 0.1740\n",
            "Epoch 57/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 4.2161 - accuracy: 0.2279 - val_loss: 6.7059 - val_accuracy: 0.1745\n",
            "Epoch 58/150\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 4.1896 - accuracy: 0.2308 - val_loss: 6.7010 - val_accuracy: 0.1737\n",
            "Epoch 59/150\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.1642 - accuracy: 0.2310 - val_loss: 6.7299 - val_accuracy: 0.1753\n",
            "Epoch 60/150\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.1376 - accuracy: 0.2344 - val_loss: 6.7540 - val_accuracy: 0.1760\n",
            "Epoch 61/150\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.1171 - accuracy: 0.2354 - val_loss: 6.7934 - val_accuracy: 0.1761\n",
            "Epoch 62/150\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.0909 - accuracy: 0.2371 - val_loss: 6.8096 - val_accuracy: 0.1762\n",
            "Epoch 63/150\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 4.0672 - accuracy: 0.2390 - val_loss: 6.8356 - val_accuracy: 0.1756\n",
            "Epoch 64/150\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.0445 - accuracy: 0.2408 - val_loss: 6.8859 - val_accuracy: 0.1768\n",
            "Epoch 65/150\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.0192 - accuracy: 0.2433 - val_loss: 6.9106 - val_accuracy: 0.1777\n",
            "Epoch 66/150\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.9970 - accuracy: 0.2450 - val_loss: 6.9438 - val_accuracy: 0.1780\n",
            "Epoch 67/150\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 3.9773 - accuracy: 0.2472 - val_loss: 6.9452 - val_accuracy: 0.1778\n",
            "Epoch 68/150\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.9511 - accuracy: 0.2494 - val_loss: 6.9374 - val_accuracy: 0.1785\n",
            "Epoch 69/150\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.9289 - accuracy: 0.2503 - val_loss: 7.0066 - val_accuracy: 0.1787\n",
            "Epoch 70/150\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 3.9045 - accuracy: 0.2530 - val_loss: 7.0479 - val_accuracy: 0.1789\n",
            "Epoch 71/150\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.8910 - accuracy: 0.2532 - val_loss: 7.0922 - val_accuracy: 0.1789\n",
            "Epoch 72/150\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.8642 - accuracy: 0.2566 - val_loss: 7.1198 - val_accuracy: 0.1794\n",
            "Epoch 73/150\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.8417 - accuracy: 0.2587 - val_loss: 7.1461 - val_accuracy: 0.1800\n",
            "Epoch 74/150\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.8224 - accuracy: 0.2615 - val_loss: 7.1949 - val_accuracy: 0.1810\n",
            "Epoch 75/150\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 3.8068 - accuracy: 0.2627 - val_loss: 7.2011 - val_accuracy: 0.1804\n",
            "Epoch 76/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.7820 - accuracy: 0.2657 - val_loss: 7.2200 - val_accuracy: 0.1818\n",
            "Epoch 77/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.7683 - accuracy: 0.2664 - val_loss: 7.2333 - val_accuracy: 0.1822\n",
            "Epoch 78/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.7476 - accuracy: 0.2688 - val_loss: 7.2724 - val_accuracy: 0.1825\n",
            "Epoch 79/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.7268 - accuracy: 0.2702 - val_loss: 7.3098 - val_accuracy: 0.1808\n",
            "Epoch 80/150\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 3.7133 - accuracy: 0.2711 - val_loss: 7.3262 - val_accuracy: 0.1814\n",
            "Epoch 81/150\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 3.6952 - accuracy: 0.2725 - val_loss: 7.3958 - val_accuracy: 0.1819\n",
            "Epoch 82/150\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 3.6768 - accuracy: 0.2752 - val_loss: 7.3500 - val_accuracy: 0.1821\n",
            "Epoch 83/150\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 3.6645 - accuracy: 0.2767 - val_loss: 7.4028 - val_accuracy: 0.1837\n",
            "Epoch 84/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.6445 - accuracy: 0.2786 - val_loss: 7.4852 - val_accuracy: 0.1827\n",
            "Epoch 85/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.6279 - accuracy: 0.2806 - val_loss: 7.4829 - val_accuracy: 0.1835\n",
            "Epoch 86/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.6121 - accuracy: 0.2814 - val_loss: 7.4999 - val_accuracy: 0.1832\n",
            "Epoch 87/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.5947 - accuracy: 0.2851 - val_loss: 7.5218 - val_accuracy: 0.1837\n",
            "Epoch 88/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.5777 - accuracy: 0.2861 - val_loss: 7.5359 - val_accuracy: 0.1840\n",
            "Epoch 89/150\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 3.5628 - accuracy: 0.2879 - val_loss: 7.6286 - val_accuracy: 0.1842\n",
            "Epoch 90/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.5429 - accuracy: 0.2892 - val_loss: 7.6149 - val_accuracy: 0.1832\n",
            "Epoch 91/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.5365 - accuracy: 0.2907 - val_loss: 7.6546 - val_accuracy: 0.1841\n",
            "Epoch 92/150\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 3.5174 - accuracy: 0.2924 - val_loss: 7.6985 - val_accuracy: 0.1842\n",
            "Epoch 93/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.5090 - accuracy: 0.2928 - val_loss: 7.7435 - val_accuracy: 0.1848\n",
            "Epoch 94/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.4882 - accuracy: 0.2960 - val_loss: 7.7666 - val_accuracy: 0.1855\n",
            "Epoch 95/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.4802 - accuracy: 0.2953 - val_loss: 7.7827 - val_accuracy: 0.1859\n",
            "Epoch 96/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.4610 - accuracy: 0.2987 - val_loss: 7.8547 - val_accuracy: 0.1854\n",
            "Epoch 97/150\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 3.4482 - accuracy: 0.3011 - val_loss: 7.8409 - val_accuracy: 0.1859\n",
            "Epoch 98/150\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 3.4379 - accuracy: 0.3012 - val_loss: 7.9248 - val_accuracy: 0.1857\n",
            "Epoch 99/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.4230 - accuracy: 0.3029 - val_loss: 7.8924 - val_accuracy: 0.1859\n",
            "Epoch 100/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.4143 - accuracy: 0.3029 - val_loss: 7.9725 - val_accuracy: 0.1858\n",
            "Epoch 101/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.3997 - accuracy: 0.3064 - val_loss: 8.0104 - val_accuracy: 0.1867\n",
            "Epoch 102/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.3835 - accuracy: 0.3083 - val_loss: 8.0079 - val_accuracy: 0.1867\n",
            "Epoch 103/150\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 3.3754 - accuracy: 0.3083 - val_loss: 8.0873 - val_accuracy: 0.1870\n",
            "Epoch 104/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.3604 - accuracy: 0.3115 - val_loss: 8.0867 - val_accuracy: 0.1859\n",
            "Epoch 105/150\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 3.3469 - accuracy: 0.3131 - val_loss: 8.1154 - val_accuracy: 0.1861\n",
            "Epoch 106/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.3451 - accuracy: 0.3127 - val_loss: 8.1164 - val_accuracy: 0.1866\n",
            "Epoch 107/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.3226 - accuracy: 0.3143 - val_loss: 8.1495 - val_accuracy: 0.1857\n",
            "Epoch 108/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.3145 - accuracy: 0.3171 - val_loss: 8.2099 - val_accuracy: 0.1863\n",
            "Epoch 109/150\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 3.3020 - accuracy: 0.3180 - val_loss: 8.1960 - val_accuracy: 0.1873\n",
            "Epoch 110/150\n",
            "126976/128420 [============================>.] - ETA: 0s - loss: 3.2934 - accuracy: 0.3194"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/My Drive/Code/autocomplete_me/src/utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(training_dict, model_filename, model, use_pretrained_model, epochs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mtraining_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                                          verbose=0)\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-445587faffb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# use_pretrained_model=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/content/drive/My Drive/Code/autocomplete_me/src/utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(training_dict, model_filename, model, use_pretrained_model, epochs)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         )\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'history' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq3jTPmpuTpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d02c920d-955a-4767-c291-c439a1ccac3c"
      },
      "source": [
        "train_history = utils.train_model(\n",
        "    training_dict,\n",
        "    f'{content_type}_uni-1_layer-trainable-50_seq',\n",
        "    use_pretrained_model=True,\n",
        "    epochs=500\n",
        ")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 128420 samples, validate on 55038 samples\n",
            "Epoch 1/500\n",
            "128420/128420 [==============================] - 18s 141us/step - loss: 5.3775 - accuracy: 0.1558 - val_loss: 6.1201 - val_accuracy: 0.1485\n",
            "Epoch 2/500\n",
            "128420/128420 [==============================] - 17s 135us/step - loss: 5.3324 - accuracy: 0.1600 - val_loss: 6.1204 - val_accuracy: 0.1501\n",
            "Epoch 3/500\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 5.2882 - accuracy: 0.1620 - val_loss: 6.1334 - val_accuracy: 0.1513\n",
            "Epoch 4/500\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 5.2429 - accuracy: 0.1632 - val_loss: 6.1377 - val_accuracy: 0.1516\n",
            "Epoch 5/500\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 5.1999 - accuracy: 0.1667 - val_loss: 6.1517 - val_accuracy: 0.1540\n",
            "Epoch 6/500\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 5.1592 - accuracy: 0.1690 - val_loss: 6.1555 - val_accuracy: 0.1550\n",
            "Epoch 7/500\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 5.1189 - accuracy: 0.1713 - val_loss: 6.1618 - val_accuracy: 0.1551\n",
            "Epoch 8/500\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 5.0780 - accuracy: 0.1741 - val_loss: 6.1701 - val_accuracy: 0.1570\n",
            "Epoch 9/500\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 5.0372 - accuracy: 0.1764 - val_loss: 6.1684 - val_accuracy: 0.1574\n",
            "Epoch 10/500\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 5.0066 - accuracy: 0.1795 - val_loss: 6.2080 - val_accuracy: 0.1585\n",
            "Epoch 11/500\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 4.9645 - accuracy: 0.1809 - val_loss: 6.2161 - val_accuracy: 0.1597\n",
            "Epoch 12/500\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 4.9309 - accuracy: 0.1846 - val_loss: 6.2250 - val_accuracy: 0.1612\n",
            "Epoch 13/500\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 4.8960 - accuracy: 0.1864 - val_loss: 6.2407 - val_accuracy: 0.1608\n",
            "Epoch 14/500\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 4.8623 - accuracy: 0.1891 - val_loss: 6.2454 - val_accuracy: 0.1620\n",
            "Epoch 15/500\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 4.8226 - accuracy: 0.1901 - val_loss: 6.2634 - val_accuracy: 0.1635\n",
            "Epoch 16/500\n",
            "128420/128420 [==============================] - 17s 134us/step - loss: 4.7886 - accuracy: 0.1925 - val_loss: 6.2921 - val_accuracy: 0.1648\n",
            "Epoch 17/500\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 4.7549 - accuracy: 0.1953 - val_loss: 6.2939 - val_accuracy: 0.1650\n",
            "Epoch 18/500\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 4.7225 - accuracy: 0.1970 - val_loss: 6.3079 - val_accuracy: 0.1656\n",
            "Epoch 19/500\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 4.6918 - accuracy: 0.1979 - val_loss: 6.3298 - val_accuracy: 0.1657\n",
            "Epoch 20/500\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 4.6611 - accuracy: 0.1999 - val_loss: 6.3626 - val_accuracy: 0.1677\n",
            "Epoch 21/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 4.6237 - accuracy: 0.2035 - val_loss: 6.3717 - val_accuracy: 0.1672\n",
            "Epoch 22/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.5943 - accuracy: 0.2042 - val_loss: 6.3842 - val_accuracy: 0.1682\n",
            "Epoch 23/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.5644 - accuracy: 0.2059 - val_loss: 6.4100 - val_accuracy: 0.1694\n",
            "Epoch 24/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.5333 - accuracy: 0.2076 - val_loss: 6.4338 - val_accuracy: 0.1694\n",
            "Epoch 25/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.5013 - accuracy: 0.2101 - val_loss: 6.4526 - val_accuracy: 0.1701\n",
            "Epoch 26/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.4660 - accuracy: 0.2128 - val_loss: 6.4444 - val_accuracy: 0.1715\n",
            "Epoch 27/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.4370 - accuracy: 0.2146 - val_loss: 6.4627 - val_accuracy: 0.1711\n",
            "Epoch 28/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 4.4097 - accuracy: 0.2159 - val_loss: 6.4896 - val_accuracy: 0.1724\n",
            "Epoch 29/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 4.3753 - accuracy: 0.2184 - val_loss: 6.5134 - val_accuracy: 0.1734\n",
            "Epoch 30/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.3472 - accuracy: 0.2194 - val_loss: 6.5609 - val_accuracy: 0.1730\n",
            "Epoch 31/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 4.3142 - accuracy: 0.2209 - val_loss: 6.5627 - val_accuracy: 0.1740\n",
            "Epoch 32/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.2936 - accuracy: 0.2234 - val_loss: 6.6063 - val_accuracy: 0.1740\n",
            "Epoch 33/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.2621 - accuracy: 0.2259 - val_loss: 6.6299 - val_accuracy: 0.1740\n",
            "Epoch 34/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.2396 - accuracy: 0.2272 - val_loss: 6.6371 - val_accuracy: 0.1749\n",
            "Epoch 35/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.2119 - accuracy: 0.2289 - val_loss: 6.6710 - val_accuracy: 0.1760\n",
            "Epoch 36/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.1814 - accuracy: 0.2318 - val_loss: 6.7067 - val_accuracy: 0.1760\n",
            "Epoch 37/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.1544 - accuracy: 0.2342 - val_loss: 6.7292 - val_accuracy: 0.1761\n",
            "Epoch 38/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.1317 - accuracy: 0.2357 - val_loss: 6.7613 - val_accuracy: 0.1758\n",
            "Epoch 39/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.1053 - accuracy: 0.2366 - val_loss: 6.7628 - val_accuracy: 0.1771\n",
            "Epoch 40/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 4.0758 - accuracy: 0.2396 - val_loss: 6.8255 - val_accuracy: 0.1770\n",
            "Epoch 41/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.0604 - accuracy: 0.2407 - val_loss: 6.8065 - val_accuracy: 0.1773\n",
            "Epoch 42/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.0299 - accuracy: 0.2429 - val_loss: 6.8508 - val_accuracy: 0.1787\n",
            "Epoch 43/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.0122 - accuracy: 0.2440 - val_loss: 6.8981 - val_accuracy: 0.1782\n",
            "Epoch 44/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.9826 - accuracy: 0.2466 - val_loss: 6.9374 - val_accuracy: 0.1785\n",
            "Epoch 45/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 3.9641 - accuracy: 0.2487 - val_loss: 6.9392 - val_accuracy: 0.1795\n",
            "Epoch 46/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.9439 - accuracy: 0.2510 - val_loss: 6.9874 - val_accuracy: 0.1792\n",
            "Epoch 47/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.9198 - accuracy: 0.2536 - val_loss: 7.0213 - val_accuracy: 0.1804\n",
            "Epoch 48/500\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 3.9010 - accuracy: 0.2533 - val_loss: 7.0342 - val_accuracy: 0.1797\n",
            "Epoch 49/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.8826 - accuracy: 0.2560 - val_loss: 7.0798 - val_accuracy: 0.1801\n",
            "Epoch 50/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.8609 - accuracy: 0.2585 - val_loss: 7.1025 - val_accuracy: 0.1797\n",
            "Epoch 51/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.8415 - accuracy: 0.2614 - val_loss: 7.0923 - val_accuracy: 0.1803\n",
            "Epoch 52/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.8225 - accuracy: 0.2600 - val_loss: 7.1701 - val_accuracy: 0.1822\n",
            "Epoch 53/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.7989 - accuracy: 0.2640 - val_loss: 7.1880 - val_accuracy: 0.1815\n",
            "Epoch 54/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.7798 - accuracy: 0.2668 - val_loss: 7.2093 - val_accuracy: 0.1811\n",
            "Epoch 55/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.7632 - accuracy: 0.2684 - val_loss: 7.2500 - val_accuracy: 0.1817\n",
            "Epoch 56/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.7451 - accuracy: 0.2707 - val_loss: 7.2292 - val_accuracy: 0.1807\n",
            "Epoch 57/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.7249 - accuracy: 0.2711 - val_loss: 7.2846 - val_accuracy: 0.1828\n",
            "Epoch 58/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.7092 - accuracy: 0.2731 - val_loss: 7.3325 - val_accuracy: 0.1829\n",
            "Epoch 59/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 3.6930 - accuracy: 0.2740 - val_loss: 7.3530 - val_accuracy: 0.1822\n",
            "Epoch 60/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.6698 - accuracy: 0.2763 - val_loss: 7.4318 - val_accuracy: 0.1830\n",
            "Epoch 61/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 3.6582 - accuracy: 0.2780 - val_loss: 7.3972 - val_accuracy: 0.1839\n",
            "Epoch 62/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.6405 - accuracy: 0.2781 - val_loss: 7.4306 - val_accuracy: 0.1839\n",
            "Epoch 63/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.6186 - accuracy: 0.2825 - val_loss: 7.4640 - val_accuracy: 0.1842\n",
            "Epoch 64/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.6066 - accuracy: 0.2838 - val_loss: 7.5051 - val_accuracy: 0.1839\n",
            "Epoch 65/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.5894 - accuracy: 0.2853 - val_loss: 7.5294 - val_accuracy: 0.1859\n",
            "Epoch 66/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.5761 - accuracy: 0.2863 - val_loss: 7.5846 - val_accuracy: 0.1853\n",
            "Epoch 67/500\n",
            "128420/128420 [==============================] - 16s 123us/step - loss: 3.5505 - accuracy: 0.2898 - val_loss: 7.6120 - val_accuracy: 0.1866\n",
            "Epoch 68/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.5462 - accuracy: 0.2891 - val_loss: 7.5988 - val_accuracy: 0.1858\n",
            "Epoch 69/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.5319 - accuracy: 0.2918 - val_loss: 7.6632 - val_accuracy: 0.1849\n",
            "Epoch 70/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.5137 - accuracy: 0.2945 - val_loss: 7.6426 - val_accuracy: 0.1851\n",
            "Epoch 71/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.5020 - accuracy: 0.2978 - val_loss: 7.7233 - val_accuracy: 0.1854\n",
            "Epoch 72/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.4868 - accuracy: 0.2964 - val_loss: 7.7774 - val_accuracy: 0.1863\n",
            "Epoch 73/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 3.4690 - accuracy: 0.2979 - val_loss: 7.7531 - val_accuracy: 0.1855\n",
            "Epoch 74/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 3.4571 - accuracy: 0.2986 - val_loss: 7.8600 - val_accuracy: 0.1854\n",
            "Epoch 75/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 3.4464 - accuracy: 0.3011 - val_loss: 7.8150 - val_accuracy: 0.1862\n",
            "Epoch 76/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.4341 - accuracy: 0.3029 - val_loss: 7.8938 - val_accuracy: 0.1871\n",
            "Epoch 77/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.4150 - accuracy: 0.3043 - val_loss: 7.9264 - val_accuracy: 0.1870\n",
            "Epoch 78/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.4057 - accuracy: 0.3057 - val_loss: 7.8884 - val_accuracy: 0.1879\n",
            "Epoch 79/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 3.3946 - accuracy: 0.3077 - val_loss: 7.9457 - val_accuracy: 0.1870\n",
            "Epoch 80/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.3819 - accuracy: 0.3098 - val_loss: 8.0381 - val_accuracy: 0.1874\n",
            "Epoch 81/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.3644 - accuracy: 0.3107 - val_loss: 8.0538 - val_accuracy: 0.1876\n",
            "Epoch 82/500\n",
            "128420/128420 [==============================] - 15s 118us/step - loss: 3.3504 - accuracy: 0.3121 - val_loss: 8.0927 - val_accuracy: 0.1878\n",
            "Epoch 83/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 3.3381 - accuracy: 0.3138 - val_loss: 8.0962 - val_accuracy: 0.1892\n",
            "Epoch 84/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.3385 - accuracy: 0.3149 - val_loss: 8.1390 - val_accuracy: 0.1884\n",
            "Epoch 85/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.3179 - accuracy: 0.3160 - val_loss: 8.1587 - val_accuracy: 0.1887\n",
            "Epoch 86/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 3.3095 - accuracy: 0.3163 - val_loss: 8.1679 - val_accuracy: 0.1887\n",
            "Epoch 87/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.2967 - accuracy: 0.3181 - val_loss: 8.1781 - val_accuracy: 0.1894\n",
            "Epoch 88/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.2889 - accuracy: 0.3189 - val_loss: 8.2327 - val_accuracy: 0.1888\n",
            "Epoch 89/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 3.2700 - accuracy: 0.3233 - val_loss: 8.2685 - val_accuracy: 0.1901\n",
            "Epoch 90/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.2654 - accuracy: 0.3233 - val_loss: 8.3224 - val_accuracy: 0.1896\n",
            "Epoch 91/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 3.2499 - accuracy: 0.3252 - val_loss: 8.3600 - val_accuracy: 0.1884\n",
            "Epoch 92/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 3.2417 - accuracy: 0.3265 - val_loss: 8.3400 - val_accuracy: 0.1879\n",
            "Epoch 93/500\n",
            "128420/128420 [==============================] - 16s 123us/step - loss: 3.2331 - accuracy: 0.3268 - val_loss: 8.3784 - val_accuracy: 0.1889\n",
            "Epoch 94/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 3.2211 - accuracy: 0.3284 - val_loss: 8.4494 - val_accuracy: 0.1894\n",
            "Epoch 95/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.2137 - accuracy: 0.3291 - val_loss: 8.3624 - val_accuracy: 0.1899\n",
            "Epoch 96/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 3.2066 - accuracy: 0.3305 - val_loss: 8.4192 - val_accuracy: 0.1895\n",
            "Epoch 97/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.1920 - accuracy: 0.3308 - val_loss: 8.5024 - val_accuracy: 0.1900\n",
            "Epoch 98/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 3.1849 - accuracy: 0.3321 - val_loss: 8.5324 - val_accuracy: 0.1902\n",
            "Epoch 99/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.1743 - accuracy: 0.3354 - val_loss: 8.6050 - val_accuracy: 0.1905\n",
            "Epoch 100/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.1692 - accuracy: 0.3348 - val_loss: 8.5972 - val_accuracy: 0.1900\n",
            "Epoch 101/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.1494 - accuracy: 0.3373 - val_loss: 8.6380 - val_accuracy: 0.1921\n",
            "Epoch 102/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 3.1419 - accuracy: 0.3381 - val_loss: 8.7259 - val_accuracy: 0.1907\n",
            "Epoch 103/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.1348 - accuracy: 0.3404 - val_loss: 8.7022 - val_accuracy: 0.1908\n",
            "Epoch 104/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.1254 - accuracy: 0.3396 - val_loss: 8.7360 - val_accuracy: 0.1910\n",
            "Epoch 105/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.1171 - accuracy: 0.3415 - val_loss: 8.7452 - val_accuracy: 0.1919\n",
            "Epoch 106/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.1117 - accuracy: 0.3423 - val_loss: 8.7788 - val_accuracy: 0.1908\n",
            "Epoch 107/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.1050 - accuracy: 0.3435 - val_loss: 8.8587 - val_accuracy: 0.1923\n",
            "Epoch 108/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.0885 - accuracy: 0.3448 - val_loss: 8.8948 - val_accuracy: 0.1924\n",
            "Epoch 109/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.0880 - accuracy: 0.3448 - val_loss: 8.9213 - val_accuracy: 0.1915\n",
            "Epoch 110/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.0747 - accuracy: 0.3473 - val_loss: 8.9423 - val_accuracy: 0.1924\n",
            "Epoch 111/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.0649 - accuracy: 0.3486 - val_loss: 8.9658 - val_accuracy: 0.1922\n",
            "Epoch 112/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 3.0582 - accuracy: 0.3499 - val_loss: 9.0165 - val_accuracy: 0.1924\n",
            "Epoch 113/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.0472 - accuracy: 0.3501 - val_loss: 9.0397 - val_accuracy: 0.1918\n",
            "Epoch 114/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.0417 - accuracy: 0.3511 - val_loss: 9.0668 - val_accuracy: 0.1912\n",
            "Epoch 115/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.0339 - accuracy: 0.3525 - val_loss: 9.0950 - val_accuracy: 0.1932\n",
            "Epoch 116/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 3.0268 - accuracy: 0.3543 - val_loss: 9.1011 - val_accuracy: 0.1928\n",
            "Epoch 117/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 3.0233 - accuracy: 0.3541 - val_loss: 9.0971 - val_accuracy: 0.1933\n",
            "Epoch 118/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 3.0091 - accuracy: 0.3545 - val_loss: 9.2054 - val_accuracy: 0.1933\n",
            "Epoch 119/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 3.0027 - accuracy: 0.3547 - val_loss: 9.2597 - val_accuracy: 0.1929\n",
            "Epoch 120/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.9933 - accuracy: 0.3578 - val_loss: 9.2289 - val_accuracy: 0.1930\n",
            "Epoch 121/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.9905 - accuracy: 0.3585 - val_loss: 9.2465 - val_accuracy: 0.1935\n",
            "Epoch 122/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.9811 - accuracy: 0.3600 - val_loss: 9.3180 - val_accuracy: 0.1933\n",
            "Epoch 123/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 2.9752 - accuracy: 0.3601 - val_loss: 9.2643 - val_accuracy: 0.1940\n",
            "Epoch 124/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.9711 - accuracy: 0.3612 - val_loss: 9.3897 - val_accuracy: 0.1950\n",
            "Epoch 125/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.9596 - accuracy: 0.3622 - val_loss: 9.4087 - val_accuracy: 0.1934\n",
            "Epoch 126/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.9531 - accuracy: 0.3625 - val_loss: 9.4452 - val_accuracy: 0.1946\n",
            "Epoch 127/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.9504 - accuracy: 0.3639 - val_loss: 9.4448 - val_accuracy: 0.1944\n",
            "Epoch 128/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 2.9399 - accuracy: 0.3642 - val_loss: 9.4518 - val_accuracy: 0.1946\n",
            "Epoch 129/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 2.9259 - accuracy: 0.3659 - val_loss: 9.5091 - val_accuracy: 0.1944\n",
            "Epoch 130/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.9266 - accuracy: 0.3659 - val_loss: 9.5137 - val_accuracy: 0.1938\n",
            "Epoch 131/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.9215 - accuracy: 0.3670 - val_loss: 9.5436 - val_accuracy: 0.1944\n",
            "Epoch 132/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.9085 - accuracy: 0.3698 - val_loss: 9.5861 - val_accuracy: 0.1946\n",
            "Epoch 133/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.9067 - accuracy: 0.3688 - val_loss: 9.6538 - val_accuracy: 0.1952\n",
            "Epoch 134/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.8955 - accuracy: 0.3701 - val_loss: 9.6543 - val_accuracy: 0.1952\n",
            "Epoch 135/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.8944 - accuracy: 0.3714 - val_loss: 9.7145 - val_accuracy: 0.1945\n",
            "Epoch 136/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.8872 - accuracy: 0.3722 - val_loss: 9.6458 - val_accuracy: 0.1955\n",
            "Epoch 137/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.8820 - accuracy: 0.3728 - val_loss: 9.7541 - val_accuracy: 0.1949\n",
            "Epoch 138/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.8748 - accuracy: 0.3735 - val_loss: 9.7706 - val_accuracy: 0.1946\n",
            "Epoch 139/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.8704 - accuracy: 0.3732 - val_loss: 9.8167 - val_accuracy: 0.1954\n",
            "Epoch 140/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.8630 - accuracy: 0.3755 - val_loss: 9.8359 - val_accuracy: 0.1955\n",
            "Epoch 141/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.8520 - accuracy: 0.3775 - val_loss: 9.8269 - val_accuracy: 0.1946\n",
            "Epoch 142/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.8499 - accuracy: 0.3774 - val_loss: 9.8745 - val_accuracy: 0.1955\n",
            "Epoch 143/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.8387 - accuracy: 0.3790 - val_loss: 9.9577 - val_accuracy: 0.1947\n",
            "Epoch 144/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.8379 - accuracy: 0.3782 - val_loss: 10.0250 - val_accuracy: 0.1947\n",
            "Epoch 145/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.8349 - accuracy: 0.3794 - val_loss: 9.8845 - val_accuracy: 0.1947\n",
            "Epoch 146/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.8247 - accuracy: 0.3812 - val_loss: 9.9593 - val_accuracy: 0.1952\n",
            "Epoch 147/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.8218 - accuracy: 0.3806 - val_loss: 10.0475 - val_accuracy: 0.1950\n",
            "Epoch 148/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.8160 - accuracy: 0.3814 - val_loss: 10.0323 - val_accuracy: 0.1962\n",
            "Epoch 149/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.8134 - accuracy: 0.3824 - val_loss: 10.0068 - val_accuracy: 0.1965\n",
            "Epoch 150/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.8100 - accuracy: 0.3817 - val_loss: 10.0936 - val_accuracy: 0.1944\n",
            "Epoch 151/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.7990 - accuracy: 0.3849 - val_loss: 10.2053 - val_accuracy: 0.1960\n",
            "Epoch 152/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.7927 - accuracy: 0.3847 - val_loss: 10.1948 - val_accuracy: 0.1959\n",
            "Epoch 153/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.7886 - accuracy: 0.3868 - val_loss: 10.1361 - val_accuracy: 0.1960\n",
            "Epoch 154/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.7817 - accuracy: 0.3861 - val_loss: 10.1522 - val_accuracy: 0.1949\n",
            "Epoch 155/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.7716 - accuracy: 0.3865 - val_loss: 10.1800 - val_accuracy: 0.1967\n",
            "Epoch 156/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.7699 - accuracy: 0.3879 - val_loss: 10.2243 - val_accuracy: 0.1963\n",
            "Epoch 157/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.7645 - accuracy: 0.3885 - val_loss: 10.3235 - val_accuracy: 0.1956\n",
            "Epoch 158/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.7648 - accuracy: 0.3894 - val_loss: 10.3071 - val_accuracy: 0.1967\n",
            "Epoch 159/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.7580 - accuracy: 0.3879 - val_loss: 10.2764 - val_accuracy: 0.1956\n",
            "Epoch 160/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.7553 - accuracy: 0.3903 - val_loss: 10.3662 - val_accuracy: 0.1958\n",
            "Epoch 161/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.7521 - accuracy: 0.3905 - val_loss: 10.3257 - val_accuracy: 0.1954\n",
            "Epoch 162/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.7390 - accuracy: 0.3936 - val_loss: 10.4417 - val_accuracy: 0.1967\n",
            "Epoch 163/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 2.7335 - accuracy: 0.3937 - val_loss: 10.3997 - val_accuracy: 0.1950\n",
            "Epoch 164/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.7321 - accuracy: 0.3936 - val_loss: 10.4014 - val_accuracy: 0.1964\n",
            "Epoch 165/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.7291 - accuracy: 0.3945 - val_loss: 10.4390 - val_accuracy: 0.1953\n",
            "Epoch 166/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.7240 - accuracy: 0.3947 - val_loss: 10.5096 - val_accuracy: 0.1953\n",
            "Epoch 167/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.7179 - accuracy: 0.3961 - val_loss: 10.6746 - val_accuracy: 0.1957\n",
            "Epoch 168/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.7104 - accuracy: 0.3975 - val_loss: 10.5886 - val_accuracy: 0.1971\n",
            "Epoch 169/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.7042 - accuracy: 0.3973 - val_loss: 10.6472 - val_accuracy: 0.1961\n",
            "Epoch 170/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.7083 - accuracy: 0.3950 - val_loss: 10.6187 - val_accuracy: 0.1971\n",
            "Epoch 171/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.7002 - accuracy: 0.3982 - val_loss: 10.6790 - val_accuracy: 0.1967\n",
            "Epoch 172/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.6930 - accuracy: 0.3982 - val_loss: 10.6921 - val_accuracy: 0.1968\n",
            "Epoch 173/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.6859 - accuracy: 0.3999 - val_loss: 10.6723 - val_accuracy: 0.1974\n",
            "Epoch 174/500\n",
            "128420/128420 [==============================] - 15s 121us/step - loss: 2.6838 - accuracy: 0.3997 - val_loss: 10.7298 - val_accuracy: 0.1979\n",
            "Epoch 175/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.6811 - accuracy: 0.4002 - val_loss: 10.7165 - val_accuracy: 0.1960\n",
            "Epoch 176/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.6752 - accuracy: 0.4022 - val_loss: 10.8227 - val_accuracy: 0.1966\n",
            "Epoch 177/500\n",
            "128420/128420 [==============================] - 15s 121us/step - loss: 2.6672 - accuracy: 0.4049 - val_loss: 10.7936 - val_accuracy: 0.1984\n",
            "Epoch 178/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.6601 - accuracy: 0.4049 - val_loss: 10.8658 - val_accuracy: 0.1977\n",
            "Epoch 179/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.6614 - accuracy: 0.4039 - val_loss: 10.8606 - val_accuracy: 0.1978\n",
            "Epoch 180/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 2.6612 - accuracy: 0.4023 - val_loss: 10.9057 - val_accuracy: 0.1975\n",
            "Epoch 181/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.6517 - accuracy: 0.4041 - val_loss: 10.9466 - val_accuracy: 0.1983\n",
            "Epoch 182/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.6501 - accuracy: 0.4054 - val_loss: 10.9149 - val_accuracy: 0.1981\n",
            "Epoch 183/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 2.6516 - accuracy: 0.4062 - val_loss: 10.9159 - val_accuracy: 0.1982\n",
            "Epoch 184/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.6424 - accuracy: 0.4063 - val_loss: 11.0235 - val_accuracy: 0.1977\n",
            "Epoch 185/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.6402 - accuracy: 0.4070 - val_loss: 10.9725 - val_accuracy: 0.1971\n",
            "Epoch 186/500\n",
            "128420/128420 [==============================] - 15s 118us/step - loss: 2.6355 - accuracy: 0.4077 - val_loss: 10.9901 - val_accuracy: 0.1979\n",
            "Epoch 187/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 2.6311 - accuracy: 0.4083 - val_loss: 11.0618 - val_accuracy: 0.1986\n",
            "Epoch 188/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.6277 - accuracy: 0.4065 - val_loss: 11.0488 - val_accuracy: 0.1974\n",
            "Epoch 189/500\n",
            "128420/128420 [==============================] - 16s 123us/step - loss: 2.6229 - accuracy: 0.4087 - val_loss: 11.1007 - val_accuracy: 0.1988\n",
            "Epoch 190/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.6234 - accuracy: 0.4080 - val_loss: 11.0967 - val_accuracy: 0.1978\n",
            "Epoch 191/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.6163 - accuracy: 0.4113 - val_loss: 11.1074 - val_accuracy: 0.1973\n",
            "Epoch 192/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.6088 - accuracy: 0.4094 - val_loss: 11.1510 - val_accuracy: 0.1983\n",
            "Epoch 193/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.6048 - accuracy: 0.4110 - val_loss: 11.1607 - val_accuracy: 0.1985\n",
            "Epoch 194/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.5997 - accuracy: 0.4139 - val_loss: 11.1419 - val_accuracy: 0.1984\n",
            "Epoch 195/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.5959 - accuracy: 0.4123 - val_loss: 11.2496 - val_accuracy: 0.1976\n",
            "Epoch 196/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.5910 - accuracy: 0.4151 - val_loss: 11.2744 - val_accuracy: 0.1980\n",
            "Epoch 197/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.5949 - accuracy: 0.4139 - val_loss: 11.3524 - val_accuracy: 0.1981\n",
            "Epoch 198/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5827 - accuracy: 0.4153 - val_loss: 11.3350 - val_accuracy: 0.1987\n",
            "Epoch 199/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5805 - accuracy: 0.4149 - val_loss: 11.3335 - val_accuracy: 0.1976\n",
            "Epoch 200/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.5819 - accuracy: 0.4150 - val_loss: 11.3472 - val_accuracy: 0.1988\n",
            "Epoch 201/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5744 - accuracy: 0.4170 - val_loss: 11.4049 - val_accuracy: 0.1984\n",
            "Epoch 202/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5670 - accuracy: 0.4170 - val_loss: 11.4120 - val_accuracy: 0.1970\n",
            "Epoch 203/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5685 - accuracy: 0.4184 - val_loss: 11.4712 - val_accuracy: 0.1996\n",
            "Epoch 204/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.5585 - accuracy: 0.4194 - val_loss: 11.4772 - val_accuracy: 0.1988\n",
            "Epoch 205/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5583 - accuracy: 0.4196 - val_loss: 11.5240 - val_accuracy: 0.1975\n",
            "Epoch 206/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5510 - accuracy: 0.4205 - val_loss: 11.5329 - val_accuracy: 0.1989\n",
            "Epoch 207/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.5528 - accuracy: 0.4184 - val_loss: 11.5843 - val_accuracy: 0.1989\n",
            "Epoch 208/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5507 - accuracy: 0.4213 - val_loss: 11.5761 - val_accuracy: 0.1985\n",
            "Epoch 209/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5435 - accuracy: 0.4203 - val_loss: 11.5153 - val_accuracy: 0.1992\n",
            "Epoch 210/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.5426 - accuracy: 0.4201 - val_loss: 11.5568 - val_accuracy: 0.1995\n",
            "Epoch 211/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.5395 - accuracy: 0.4225 - val_loss: 11.6506 - val_accuracy: 0.1993\n",
            "Epoch 212/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.5326 - accuracy: 0.4238 - val_loss: 11.5971 - val_accuracy: 0.1995\n",
            "Epoch 213/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5323 - accuracy: 0.4227 - val_loss: 11.6533 - val_accuracy: 0.1987\n",
            "Epoch 214/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5303 - accuracy: 0.4229 - val_loss: 11.6927 - val_accuracy: 0.1983\n",
            "Epoch 215/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.5264 - accuracy: 0.4255 - val_loss: 11.7112 - val_accuracy: 0.1994\n",
            "Epoch 216/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.5200 - accuracy: 0.4250 - val_loss: 11.6968 - val_accuracy: 0.1992\n",
            "Epoch 217/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.5165 - accuracy: 0.4255 - val_loss: 11.7988 - val_accuracy: 0.1999\n",
            "Epoch 218/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.5188 - accuracy: 0.4247 - val_loss: 11.7653 - val_accuracy: 0.1997\n",
            "Epoch 219/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.5078 - accuracy: 0.4271 - val_loss: 11.8095 - val_accuracy: 0.1991\n",
            "Epoch 220/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.5093 - accuracy: 0.4257 - val_loss: 11.7738 - val_accuracy: 0.1990\n",
            "Epoch 221/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 2.5037 - accuracy: 0.4270 - val_loss: 11.9315 - val_accuracy: 0.1992\n",
            "Epoch 222/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.5053 - accuracy: 0.4260 - val_loss: 11.8650 - val_accuracy: 0.1998\n",
            "Epoch 223/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4951 - accuracy: 0.4292 - val_loss: 11.9437 - val_accuracy: 0.1991\n",
            "Epoch 224/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4930 - accuracy: 0.4306 - val_loss: 11.9310 - val_accuracy: 0.1995\n",
            "Epoch 225/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4859 - accuracy: 0.4293 - val_loss: 11.9159 - val_accuracy: 0.1997\n",
            "Epoch 226/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 2.4888 - accuracy: 0.4287 - val_loss: 11.8981 - val_accuracy: 0.1997\n",
            "Epoch 227/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.4867 - accuracy: 0.4299 - val_loss: 12.0059 - val_accuracy: 0.2002\n",
            "Epoch 228/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.4798 - accuracy: 0.4319 - val_loss: 11.9919 - val_accuracy: 0.1992\n",
            "Epoch 229/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.4763 - accuracy: 0.4322 - val_loss: 11.9378 - val_accuracy: 0.1992\n",
            "Epoch 230/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.4719 - accuracy: 0.4320 - val_loss: 12.0635 - val_accuracy: 0.1998\n",
            "Epoch 231/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4755 - accuracy: 0.4315 - val_loss: 12.0927 - val_accuracy: 0.1985\n",
            "Epoch 232/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4661 - accuracy: 0.4320 - val_loss: 12.0095 - val_accuracy: 0.2001\n",
            "Epoch 233/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.4665 - accuracy: 0.4339 - val_loss: 12.0781 - val_accuracy: 0.1997\n",
            "Epoch 234/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.4648 - accuracy: 0.4337 - val_loss: 12.1173 - val_accuracy: 0.2000\n",
            "Epoch 235/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.4578 - accuracy: 0.4353 - val_loss: 12.1184 - val_accuracy: 0.1992\n",
            "Epoch 236/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.4594 - accuracy: 0.4356 - val_loss: 12.1381 - val_accuracy: 0.2007\n",
            "Epoch 237/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.4559 - accuracy: 0.4352 - val_loss: 12.1676 - val_accuracy: 0.1996\n",
            "Epoch 238/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.4481 - accuracy: 0.4361 - val_loss: 12.1981 - val_accuracy: 0.1993\n",
            "Epoch 239/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.4518 - accuracy: 0.4355 - val_loss: 12.2358 - val_accuracy: 0.2006\n",
            "Epoch 240/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.4455 - accuracy: 0.4365 - val_loss: 12.2734 - val_accuracy: 0.1999\n",
            "Epoch 241/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4359 - accuracy: 0.4387 - val_loss: 12.2597 - val_accuracy: 0.2017\n",
            "Epoch 242/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.4391 - accuracy: 0.4370 - val_loss: 12.3676 - val_accuracy: 0.2002\n",
            "Epoch 243/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.4320 - accuracy: 0.4380 - val_loss: 12.4088 - val_accuracy: 0.2011\n",
            "Epoch 244/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.4394 - accuracy: 0.4364 - val_loss: 12.3487 - val_accuracy: 0.1999\n",
            "Epoch 245/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4302 - accuracy: 0.4398 - val_loss: 12.3510 - val_accuracy: 0.2010\n",
            "Epoch 246/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.4303 - accuracy: 0.4377 - val_loss: 12.2469 - val_accuracy: 0.2019\n",
            "Epoch 247/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.4323 - accuracy: 0.4381 - val_loss: 12.3462 - val_accuracy: 0.2001\n",
            "Epoch 248/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.4213 - accuracy: 0.4414 - val_loss: 12.3735 - val_accuracy: 0.2008\n",
            "Epoch 249/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4247 - accuracy: 0.4388 - val_loss: 12.4340 - val_accuracy: 0.2011\n",
            "Epoch 250/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.4179 - accuracy: 0.4405 - val_loss: 12.5290 - val_accuracy: 0.2003\n",
            "Epoch 251/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4196 - accuracy: 0.4399 - val_loss: 12.4309 - val_accuracy: 0.2006\n",
            "Epoch 252/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.4141 - accuracy: 0.4423 - val_loss: 12.4349 - val_accuracy: 0.2012\n",
            "Epoch 253/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4081 - accuracy: 0.4428 - val_loss: 12.5506 - val_accuracy: 0.2013\n",
            "Epoch 254/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.4067 - accuracy: 0.4429 - val_loss: 12.5352 - val_accuracy: 0.2006\n",
            "Epoch 255/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4043 - accuracy: 0.4425 - val_loss: 12.5895 - val_accuracy: 0.2014\n",
            "Epoch 256/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.4024 - accuracy: 0.4426 - val_loss: 12.5465 - val_accuracy: 0.2012\n",
            "Epoch 257/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.4018 - accuracy: 0.4441 - val_loss: 12.5598 - val_accuracy: 0.2012\n",
            "Epoch 258/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.3938 - accuracy: 0.4441 - val_loss: 12.5704 - val_accuracy: 0.2013\n",
            "Epoch 259/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.3967 - accuracy: 0.4446 - val_loss: 12.5727 - val_accuracy: 0.2004\n",
            "Epoch 260/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.3928 - accuracy: 0.4454 - val_loss: 12.5923 - val_accuracy: 0.2009\n",
            "Epoch 261/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.3924 - accuracy: 0.4465 - val_loss: 12.5515 - val_accuracy: 0.1992\n",
            "Epoch 262/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.3822 - accuracy: 0.4479 - val_loss: 12.6719 - val_accuracy: 0.2004\n",
            "Epoch 263/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.3857 - accuracy: 0.4455 - val_loss: 12.6573 - val_accuracy: 0.2004\n",
            "Epoch 264/500\n",
            "128420/128420 [==============================] - 16s 123us/step - loss: 2.3800 - accuracy: 0.4467 - val_loss: 12.7173 - val_accuracy: 0.2013\n",
            "Epoch 265/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.3815 - accuracy: 0.4458 - val_loss: 12.6435 - val_accuracy: 0.2000\n",
            "Epoch 266/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.3791 - accuracy: 0.4474 - val_loss: 12.6001 - val_accuracy: 0.1999\n",
            "Epoch 267/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.3724 - accuracy: 0.4467 - val_loss: 12.7524 - val_accuracy: 0.2002\n",
            "Epoch 268/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.3731 - accuracy: 0.4486 - val_loss: 12.6918 - val_accuracy: 0.1996\n",
            "Epoch 269/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 2.3686 - accuracy: 0.4484 - val_loss: 12.8419 - val_accuracy: 0.2001\n",
            "Epoch 270/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.3696 - accuracy: 0.4480 - val_loss: 12.8070 - val_accuracy: 0.2003\n",
            "Epoch 271/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.3628 - accuracy: 0.4491 - val_loss: 12.7426 - val_accuracy: 0.2006\n",
            "Epoch 272/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.3576 - accuracy: 0.4498 - val_loss: 12.8920 - val_accuracy: 0.2020\n",
            "Epoch 273/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 2.3633 - accuracy: 0.4483 - val_loss: 12.8406 - val_accuracy: 0.2007\n",
            "Epoch 274/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 2.3576 - accuracy: 0.4506 - val_loss: 12.9064 - val_accuracy: 0.2005\n",
            "Epoch 275/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.3532 - accuracy: 0.4515 - val_loss: 12.9654 - val_accuracy: 0.2007\n",
            "Epoch 276/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 2.3506 - accuracy: 0.4525 - val_loss: 12.9590 - val_accuracy: 0.2012\n",
            "Epoch 277/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.3470 - accuracy: 0.4523 - val_loss: 12.9854 - val_accuracy: 0.2006\n",
            "Epoch 278/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.3466 - accuracy: 0.4518 - val_loss: 12.9697 - val_accuracy: 0.2011\n",
            "Epoch 279/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.3474 - accuracy: 0.4509 - val_loss: 12.9244 - val_accuracy: 0.2012\n",
            "Epoch 280/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 2.3465 - accuracy: 0.4522 - val_loss: 12.9000 - val_accuracy: 0.2006\n",
            "Epoch 281/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.3399 - accuracy: 0.4529 - val_loss: 13.0025 - val_accuracy: 0.2012\n",
            "Epoch 282/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.3351 - accuracy: 0.4542 - val_loss: 13.0518 - val_accuracy: 0.2006\n",
            "Epoch 283/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.3342 - accuracy: 0.4537 - val_loss: 13.1418 - val_accuracy: 0.2011\n",
            "Epoch 284/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.3320 - accuracy: 0.4543 - val_loss: 13.0903 - val_accuracy: 0.2011\n",
            "Epoch 285/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 2.3323 - accuracy: 0.4547 - val_loss: 12.9374 - val_accuracy: 0.2013\n",
            "Epoch 286/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.3283 - accuracy: 0.4550 - val_loss: 13.0336 - val_accuracy: 0.2014\n",
            "Epoch 287/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.3262 - accuracy: 0.4544 - val_loss: 13.1085 - val_accuracy: 0.2020\n",
            "Epoch 288/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.3265 - accuracy: 0.4550 - val_loss: 13.1182 - val_accuracy: 0.2020\n",
            "Epoch 289/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.3261 - accuracy: 0.4553 - val_loss: 13.0477 - val_accuracy: 0.2014\n",
            "Epoch 290/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.3145 - accuracy: 0.4582 - val_loss: 13.2102 - val_accuracy: 0.2017\n",
            "Epoch 291/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.3197 - accuracy: 0.4558 - val_loss: 13.1455 - val_accuracy: 0.2023\n",
            "Epoch 292/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.3188 - accuracy: 0.4565 - val_loss: 13.1347 - val_accuracy: 0.2020\n",
            "Epoch 293/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 2.3176 - accuracy: 0.4577 - val_loss: 13.1897 - val_accuracy: 0.2016\n",
            "Epoch 294/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.3155 - accuracy: 0.4564 - val_loss: 13.2093 - val_accuracy: 0.2016\n",
            "Epoch 295/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.3054 - accuracy: 0.4584 - val_loss: 13.2934 - val_accuracy: 0.2009\n",
            "Epoch 296/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.3069 - accuracy: 0.4581 - val_loss: 13.2892 - val_accuracy: 0.2021\n",
            "Epoch 297/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.3042 - accuracy: 0.4604 - val_loss: 13.3079 - val_accuracy: 0.2026\n",
            "Epoch 298/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2996 - accuracy: 0.4605 - val_loss: 13.3343 - val_accuracy: 0.2015\n",
            "Epoch 299/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2988 - accuracy: 0.4607 - val_loss: 13.2388 - val_accuracy: 0.2007\n",
            "Epoch 300/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.3025 - accuracy: 0.4589 - val_loss: 13.3918 - val_accuracy: 0.2020\n",
            "Epoch 301/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2955 - accuracy: 0.4605 - val_loss: 13.4558 - val_accuracy: 0.2028\n",
            "Epoch 302/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2949 - accuracy: 0.4601 - val_loss: 13.4316 - val_accuracy: 0.2019\n",
            "Epoch 303/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.2998 - accuracy: 0.4595 - val_loss: 13.4211 - val_accuracy: 0.2030\n",
            "Epoch 304/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2907 - accuracy: 0.4617 - val_loss: 13.3390 - val_accuracy: 0.2017\n",
            "Epoch 305/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.2878 - accuracy: 0.4601 - val_loss: 13.3298 - val_accuracy: 0.2026\n",
            "Epoch 306/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2855 - accuracy: 0.4616 - val_loss: 13.4182 - val_accuracy: 0.2025\n",
            "Epoch 307/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2834 - accuracy: 0.4622 - val_loss: 13.3388 - val_accuracy: 0.2024\n",
            "Epoch 308/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 2.2835 - accuracy: 0.4625 - val_loss: 13.5346 - val_accuracy: 0.2023\n",
            "Epoch 309/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2808 - accuracy: 0.4623 - val_loss: 13.4833 - val_accuracy: 0.2023\n",
            "Epoch 310/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2740 - accuracy: 0.4630 - val_loss: 13.5618 - val_accuracy: 0.2012\n",
            "Epoch 311/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2770 - accuracy: 0.4645 - val_loss: 13.5123 - val_accuracy: 0.2018\n",
            "Epoch 312/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2744 - accuracy: 0.4646 - val_loss: 13.6264 - val_accuracy: 0.2020\n",
            "Epoch 313/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2712 - accuracy: 0.4647 - val_loss: 13.6657 - val_accuracy: 0.2016\n",
            "Epoch 314/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2704 - accuracy: 0.4647 - val_loss: 13.5688 - val_accuracy: 0.2016\n",
            "Epoch 315/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2670 - accuracy: 0.4642 - val_loss: 13.6608 - val_accuracy: 0.2026\n",
            "Epoch 316/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2735 - accuracy: 0.4636 - val_loss: 13.5996 - val_accuracy: 0.2015\n",
            "Epoch 317/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2654 - accuracy: 0.4656 - val_loss: 13.6179 - val_accuracy: 0.2030\n",
            "Epoch 318/500\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 2.2549 - accuracy: 0.4662 - val_loss: 13.4958 - val_accuracy: 0.2027\n",
            "Epoch 319/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2571 - accuracy: 0.4671 - val_loss: 13.6623 - val_accuracy: 0.2018\n",
            "Epoch 320/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2557 - accuracy: 0.4678 - val_loss: 13.5917 - val_accuracy: 0.2017\n",
            "Epoch 321/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.2625 - accuracy: 0.4666 - val_loss: 13.6333 - val_accuracy: 0.2028\n",
            "Epoch 322/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2532 - accuracy: 0.4679 - val_loss: 13.6094 - val_accuracy: 0.2025\n",
            "Epoch 323/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2550 - accuracy: 0.4667 - val_loss: 13.5927 - val_accuracy: 0.2018\n",
            "Epoch 324/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2584 - accuracy: 0.4673 - val_loss: 13.7581 - val_accuracy: 0.2023\n",
            "Epoch 325/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2496 - accuracy: 0.4691 - val_loss: 13.6307 - val_accuracy: 0.2031\n",
            "Epoch 326/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2493 - accuracy: 0.4679 - val_loss: 13.7267 - val_accuracy: 0.2023\n",
            "Epoch 327/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.2475 - accuracy: 0.4689 - val_loss: 13.8596 - val_accuracy: 0.2036\n",
            "Epoch 328/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2380 - accuracy: 0.4715 - val_loss: 13.6881 - val_accuracy: 0.2018\n",
            "Epoch 329/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2425 - accuracy: 0.4690 - val_loss: 13.7049 - val_accuracy: 0.2021\n",
            "Epoch 330/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2405 - accuracy: 0.4699 - val_loss: 13.8122 - val_accuracy: 0.2018\n",
            "Epoch 331/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.2355 - accuracy: 0.4695 - val_loss: 13.9215 - val_accuracy: 0.2013\n",
            "Epoch 332/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2332 - accuracy: 0.4720 - val_loss: 13.9019 - val_accuracy: 0.2028\n",
            "Epoch 333/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2347 - accuracy: 0.4697 - val_loss: 13.8544 - val_accuracy: 0.2026\n",
            "Epoch 334/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2326 - accuracy: 0.4723 - val_loss: 13.7939 - val_accuracy: 0.2027\n",
            "Epoch 335/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2359 - accuracy: 0.4707 - val_loss: 13.8907 - val_accuracy: 0.2022\n",
            "Epoch 336/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2352 - accuracy: 0.4708 - val_loss: 13.9082 - val_accuracy: 0.2027\n",
            "Epoch 337/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.2257 - accuracy: 0.4712 - val_loss: 13.8209 - val_accuracy: 0.2030\n",
            "Epoch 338/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2233 - accuracy: 0.4721 - val_loss: 13.8628 - val_accuracy: 0.2022\n",
            "Epoch 339/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2205 - accuracy: 0.4745 - val_loss: 13.8504 - val_accuracy: 0.2037\n",
            "Epoch 340/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2272 - accuracy: 0.4716 - val_loss: 13.9098 - val_accuracy: 0.2025\n",
            "Epoch 341/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2207 - accuracy: 0.4734 - val_loss: 13.9103 - val_accuracy: 0.2031\n",
            "Epoch 342/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2214 - accuracy: 0.4719 - val_loss: 13.9654 - val_accuracy: 0.2037\n",
            "Epoch 343/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2148 - accuracy: 0.4744 - val_loss: 14.0758 - val_accuracy: 0.2034\n",
            "Epoch 344/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.2175 - accuracy: 0.4748 - val_loss: 14.0779 - val_accuracy: 0.2022\n",
            "Epoch 345/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2150 - accuracy: 0.4753 - val_loss: 14.0753 - val_accuracy: 0.2028\n",
            "Epoch 346/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2090 - accuracy: 0.4753 - val_loss: 14.0033 - val_accuracy: 0.2031\n",
            "Epoch 347/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.2038 - accuracy: 0.4741 - val_loss: 14.1348 - val_accuracy: 0.2028\n",
            "Epoch 348/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2010 - accuracy: 0.4774 - val_loss: 13.9955 - val_accuracy: 0.2029\n",
            "Epoch 349/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2083 - accuracy: 0.4755 - val_loss: 14.0480 - val_accuracy: 0.2023\n",
            "Epoch 350/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.2020 - accuracy: 0.4763 - val_loss: 14.0083 - val_accuracy: 0.2028\n",
            "Epoch 351/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.2038 - accuracy: 0.4750 - val_loss: 14.1254 - val_accuracy: 0.2025\n",
            "Epoch 352/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1996 - accuracy: 0.4774 - val_loss: 14.2013 - val_accuracy: 0.2030\n",
            "Epoch 353/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.2005 - accuracy: 0.4770 - val_loss: 14.0808 - val_accuracy: 0.2024\n",
            "Epoch 354/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1957 - accuracy: 0.4779 - val_loss: 14.0612 - val_accuracy: 0.2030\n",
            "Epoch 355/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1975 - accuracy: 0.4755 - val_loss: 14.1999 - val_accuracy: 0.2027\n",
            "Epoch 356/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1960 - accuracy: 0.4783 - val_loss: 14.2167 - val_accuracy: 0.2028\n",
            "Epoch 357/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.1935 - accuracy: 0.4770 - val_loss: 14.1767 - val_accuracy: 0.2036\n",
            "Epoch 358/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1884 - accuracy: 0.4790 - val_loss: 14.0594 - val_accuracy: 0.2020\n",
            "Epoch 359/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1843 - accuracy: 0.4784 - val_loss: 14.2153 - val_accuracy: 0.2024\n",
            "Epoch 360/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1865 - accuracy: 0.4786 - val_loss: 14.2062 - val_accuracy: 0.2012\n",
            "Epoch 361/500\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 2.1861 - accuracy: 0.4783 - val_loss: 14.1982 - val_accuracy: 0.2021\n",
            "Epoch 362/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.1865 - accuracy: 0.4773 - val_loss: 14.3166 - val_accuracy: 0.2023\n",
            "Epoch 363/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1788 - accuracy: 0.4794 - val_loss: 14.1622 - val_accuracy: 0.2017\n",
            "Epoch 364/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.1803 - accuracy: 0.4799 - val_loss: 14.3788 - val_accuracy: 0.2026\n",
            "Epoch 365/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1801 - accuracy: 0.4808 - val_loss: 14.2906 - val_accuracy: 0.2022\n",
            "Epoch 366/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.1794 - accuracy: 0.4785 - val_loss: 14.2483 - val_accuracy: 0.2026\n",
            "Epoch 367/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.1757 - accuracy: 0.4809 - val_loss: 14.3721 - val_accuracy: 0.2029\n",
            "Epoch 368/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.1771 - accuracy: 0.4798 - val_loss: 14.3933 - val_accuracy: 0.2034\n",
            "Epoch 369/500\n",
            "128420/128420 [==============================] - 15s 121us/step - loss: 2.1752 - accuracy: 0.4803 - val_loss: 14.3723 - val_accuracy: 0.2031\n",
            "Epoch 370/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.1731 - accuracy: 0.4797 - val_loss: 14.4719 - val_accuracy: 0.2025\n",
            "Epoch 371/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.1699 - accuracy: 0.4822 - val_loss: 14.5592 - val_accuracy: 0.2039\n",
            "Epoch 372/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.1673 - accuracy: 0.4827 - val_loss: 14.3659 - val_accuracy: 0.2023\n",
            "Epoch 373/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.1612 - accuracy: 0.4827 - val_loss: 14.4725 - val_accuracy: 0.2029\n",
            "Epoch 374/500\n",
            "128420/128420 [==============================] - 15s 121us/step - loss: 2.1637 - accuracy: 0.4823 - val_loss: 14.4007 - val_accuracy: 0.2024\n",
            "Epoch 375/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1643 - accuracy: 0.4826 - val_loss: 14.4244 - val_accuracy: 0.2014\n",
            "Epoch 376/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.1672 - accuracy: 0.4827 - val_loss: 14.3782 - val_accuracy: 0.2028\n",
            "Epoch 377/500\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 2.1605 - accuracy: 0.4832 - val_loss: 14.5080 - val_accuracy: 0.2033\n",
            "Epoch 378/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1674 - accuracy: 0.4819 - val_loss: 14.4478 - val_accuracy: 0.2024\n",
            "Epoch 379/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1547 - accuracy: 0.4835 - val_loss: 14.5364 - val_accuracy: 0.2038\n",
            "Epoch 380/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1601 - accuracy: 0.4826 - val_loss: 14.6008 - val_accuracy: 0.2031\n",
            "Epoch 381/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1513 - accuracy: 0.4847 - val_loss: 14.5124 - val_accuracy: 0.2028\n",
            "Epoch 382/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1540 - accuracy: 0.4847 - val_loss: 14.5988 - val_accuracy: 0.2041\n",
            "Epoch 383/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1522 - accuracy: 0.4846 - val_loss: 14.5447 - val_accuracy: 0.2032\n",
            "Epoch 384/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1494 - accuracy: 0.4864 - val_loss: 14.5679 - val_accuracy: 0.2032\n",
            "Epoch 385/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1423 - accuracy: 0.4867 - val_loss: 14.5929 - val_accuracy: 0.2026\n",
            "Epoch 386/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1514 - accuracy: 0.4841 - val_loss: 14.6495 - val_accuracy: 0.2027\n",
            "Epoch 387/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1481 - accuracy: 0.4835 - val_loss: 14.5577 - val_accuracy: 0.2025\n",
            "Epoch 388/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1405 - accuracy: 0.4868 - val_loss: 14.6649 - val_accuracy: 0.2037\n",
            "Epoch 389/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1441 - accuracy: 0.4857 - val_loss: 14.5799 - val_accuracy: 0.2033\n",
            "Epoch 390/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.1469 - accuracy: 0.4864 - val_loss: 14.6573 - val_accuracy: 0.2035\n",
            "Epoch 391/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.1453 - accuracy: 0.4865 - val_loss: 14.5816 - val_accuracy: 0.2036\n",
            "Epoch 392/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.1395 - accuracy: 0.4869 - val_loss: 14.7991 - val_accuracy: 0.2038\n",
            "Epoch 393/500\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 2.1367 - accuracy: 0.4876 - val_loss: 14.7097 - val_accuracy: 0.2049\n",
            "Epoch 394/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1367 - accuracy: 0.4855 - val_loss: 14.7316 - val_accuracy: 0.2037\n",
            "Epoch 395/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.1295 - accuracy: 0.4881 - val_loss: 14.7057 - val_accuracy: 0.2047\n",
            "Epoch 396/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.1355 - accuracy: 0.4874 - val_loss: 14.7292 - val_accuracy: 0.2041\n",
            "Epoch 397/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1293 - accuracy: 0.4890 - val_loss: 14.7605 - val_accuracy: 0.2047\n",
            "Epoch 398/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.1340 - accuracy: 0.4877 - val_loss: 14.7980 - val_accuracy: 0.2041\n",
            "Epoch 399/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1239 - accuracy: 0.4892 - val_loss: 14.8913 - val_accuracy: 0.2047\n",
            "Epoch 400/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1245 - accuracy: 0.4900 - val_loss: 14.8364 - val_accuracy: 0.2015\n",
            "Epoch 401/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1234 - accuracy: 0.4899 - val_loss: 14.7310 - val_accuracy: 0.2035\n",
            "Epoch 402/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1240 - accuracy: 0.4886 - val_loss: 14.9556 - val_accuracy: 0.2034\n",
            "Epoch 403/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.1223 - accuracy: 0.4901 - val_loss: 14.9000 - val_accuracy: 0.2036\n",
            "Epoch 404/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.1219 - accuracy: 0.4913 - val_loss: 14.7780 - val_accuracy: 0.2029\n",
            "Epoch 405/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.1224 - accuracy: 0.4897 - val_loss: 14.8351 - val_accuracy: 0.2028\n",
            "Epoch 406/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1170 - accuracy: 0.4920 - val_loss: 14.8867 - val_accuracy: 0.2026\n",
            "Epoch 407/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.1208 - accuracy: 0.4900 - val_loss: 14.9261 - val_accuracy: 0.2026\n",
            "Epoch 408/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1193 - accuracy: 0.4897 - val_loss: 14.7886 - val_accuracy: 0.2027\n",
            "Epoch 409/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1133 - accuracy: 0.4923 - val_loss: 14.7480 - val_accuracy: 0.2026\n",
            "Epoch 410/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1149 - accuracy: 0.4905 - val_loss: 14.8279 - val_accuracy: 0.2027\n",
            "Epoch 411/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1086 - accuracy: 0.4920 - val_loss: 14.8742 - val_accuracy: 0.2035\n",
            "Epoch 412/500\n",
            "128420/128420 [==============================] - 17s 128us/step - loss: 2.1123 - accuracy: 0.4901 - val_loss: 15.0219 - val_accuracy: 0.2028\n",
            "Epoch 413/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1110 - accuracy: 0.4911 - val_loss: 14.8635 - val_accuracy: 0.2031\n",
            "Epoch 414/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1059 - accuracy: 0.4923 - val_loss: 14.9980 - val_accuracy: 0.2033\n",
            "Epoch 415/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.1090 - accuracy: 0.4920 - val_loss: 14.9280 - val_accuracy: 0.2025\n",
            "Epoch 416/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.1000 - accuracy: 0.4937 - val_loss: 14.9921 - val_accuracy: 0.2035\n",
            "Epoch 417/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0975 - accuracy: 0.4945 - val_loss: 15.0193 - val_accuracy: 0.2027\n",
            "Epoch 418/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.1018 - accuracy: 0.4933 - val_loss: 14.8227 - val_accuracy: 0.2032\n",
            "Epoch 419/500\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 2.1023 - accuracy: 0.4935 - val_loss: 15.0705 - val_accuracy: 0.2034\n",
            "Epoch 420/500\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 2.0969 - accuracy: 0.4946 - val_loss: 15.0496 - val_accuracy: 0.2029\n",
            "Epoch 421/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.1023 - accuracy: 0.4928 - val_loss: 15.0888 - val_accuracy: 0.2027\n",
            "Epoch 422/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0931 - accuracy: 0.4944 - val_loss: 15.0756 - val_accuracy: 0.2040\n",
            "Epoch 423/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0930 - accuracy: 0.4946 - val_loss: 15.2021 - val_accuracy: 0.2036\n",
            "Epoch 424/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0901 - accuracy: 0.4957 - val_loss: 14.9785 - val_accuracy: 0.2029\n",
            "Epoch 425/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0948 - accuracy: 0.4937 - val_loss: 15.0560 - val_accuracy: 0.2039\n",
            "Epoch 426/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0921 - accuracy: 0.4960 - val_loss: 15.1548 - val_accuracy: 0.2036\n",
            "Epoch 427/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0932 - accuracy: 0.4940 - val_loss: 15.0885 - val_accuracy: 0.2040\n",
            "Epoch 428/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.0875 - accuracy: 0.4960 - val_loss: 15.1567 - val_accuracy: 0.2037\n",
            "Epoch 429/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0831 - accuracy: 0.4960 - val_loss: 15.0816 - val_accuracy: 0.2041\n",
            "Epoch 430/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.0831 - accuracy: 0.4978 - val_loss: 15.1304 - val_accuracy: 0.2037\n",
            "Epoch 431/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0880 - accuracy: 0.4961 - val_loss: 15.1253 - val_accuracy: 0.2028\n",
            "Epoch 432/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0824 - accuracy: 0.4976 - val_loss: 15.0934 - val_accuracy: 0.2040\n",
            "Epoch 433/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.0851 - accuracy: 0.4972 - val_loss: 15.3456 - val_accuracy: 0.2046\n",
            "Epoch 434/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.0801 - accuracy: 0.4961 - val_loss: 15.1412 - val_accuracy: 0.2039\n",
            "Epoch 435/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0800 - accuracy: 0.4970 - val_loss: 15.1642 - val_accuracy: 0.2033\n",
            "Epoch 436/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0769 - accuracy: 0.4977 - val_loss: 15.2321 - val_accuracy: 0.2041\n",
            "Epoch 437/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0762 - accuracy: 0.4982 - val_loss: 15.2348 - val_accuracy: 0.2035\n",
            "Epoch 438/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0765 - accuracy: 0.4986 - val_loss: 15.1395 - val_accuracy: 0.2034\n",
            "Epoch 439/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0778 - accuracy: 0.4983 - val_loss: 15.2927 - val_accuracy: 0.2049\n",
            "Epoch 440/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0752 - accuracy: 0.4980 - val_loss: 15.2343 - val_accuracy: 0.2037\n",
            "Epoch 441/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0735 - accuracy: 0.4974 - val_loss: 15.4214 - val_accuracy: 0.2035\n",
            "Epoch 442/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0703 - accuracy: 0.5004 - val_loss: 15.3123 - val_accuracy: 0.2035\n",
            "Epoch 443/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0753 - accuracy: 0.4995 - val_loss: 15.2620 - val_accuracy: 0.2041\n",
            "Epoch 444/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0704 - accuracy: 0.4994 - val_loss: 15.2202 - val_accuracy: 0.2037\n",
            "Epoch 445/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0668 - accuracy: 0.4997 - val_loss: 15.2495 - val_accuracy: 0.2032\n",
            "Epoch 446/500\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 2.0619 - accuracy: 0.5013 - val_loss: 15.2294 - val_accuracy: 0.2028\n",
            "Epoch 447/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0619 - accuracy: 0.5004 - val_loss: 15.3044 - val_accuracy: 0.2026\n",
            "Epoch 448/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0641 - accuracy: 0.4994 - val_loss: 15.3700 - val_accuracy: 0.2033\n",
            "Epoch 449/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.0617 - accuracy: 0.4996 - val_loss: 15.2476 - val_accuracy: 0.2034\n",
            "Epoch 450/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0590 - accuracy: 0.5012 - val_loss: 15.3489 - val_accuracy: 0.2040\n",
            "Epoch 451/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.0591 - accuracy: 0.5017 - val_loss: 15.4957 - val_accuracy: 0.2040\n",
            "Epoch 452/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0578 - accuracy: 0.5009 - val_loss: 15.4503 - val_accuracy: 0.2032\n",
            "Epoch 453/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0520 - accuracy: 0.5016 - val_loss: 15.4308 - val_accuracy: 0.2040\n",
            "Epoch 454/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0619 - accuracy: 0.5013 - val_loss: 15.4628 - val_accuracy: 0.2040\n",
            "Epoch 455/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.0571 - accuracy: 0.5021 - val_loss: 15.4140 - val_accuracy: 0.2039\n",
            "Epoch 456/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.0482 - accuracy: 0.5037 - val_loss: 15.4243 - val_accuracy: 0.2039\n",
            "Epoch 457/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.0549 - accuracy: 0.5011 - val_loss: 15.4986 - val_accuracy: 0.2042\n",
            "Epoch 458/500\n",
            "128420/128420 [==============================] - 15s 118us/step - loss: 2.0522 - accuracy: 0.5041 - val_loss: 15.3357 - val_accuracy: 0.2047\n",
            "Epoch 459/500\n",
            "128420/128420 [==============================] - 15s 117us/step - loss: 2.0495 - accuracy: 0.5026 - val_loss: 15.4189 - val_accuracy: 0.2050\n",
            "Epoch 460/500\n",
            "128420/128420 [==============================] - 15s 118us/step - loss: 2.0434 - accuracy: 0.5039 - val_loss: 15.4512 - val_accuracy: 0.2042\n",
            "Epoch 461/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.0434 - accuracy: 0.5039 - val_loss: 15.5473 - val_accuracy: 0.2040\n",
            "Epoch 462/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.0507 - accuracy: 0.5033 - val_loss: 15.5010 - val_accuracy: 0.2043\n",
            "Epoch 463/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.0402 - accuracy: 0.5045 - val_loss: 15.6890 - val_accuracy: 0.2052\n",
            "Epoch 464/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.0446 - accuracy: 0.5046 - val_loss: 15.5393 - val_accuracy: 0.2041\n",
            "Epoch 465/500\n",
            "128420/128420 [==============================] - 15s 118us/step - loss: 2.0425 - accuracy: 0.5033 - val_loss: 15.5219 - val_accuracy: 0.2042\n",
            "Epoch 466/500\n",
            "128420/128420 [==============================] - 15s 121us/step - loss: 2.0488 - accuracy: 0.5014 - val_loss: 15.5521 - val_accuracy: 0.2041\n",
            "Epoch 467/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.0387 - accuracy: 0.5041 - val_loss: 15.5830 - val_accuracy: 0.2035\n",
            "Epoch 468/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.0410 - accuracy: 0.5042 - val_loss: 15.5963 - val_accuracy: 0.2041\n",
            "Epoch 469/500\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 2.0368 - accuracy: 0.5053 - val_loss: 15.7537 - val_accuracy: 0.2048\n",
            "Epoch 470/500\n",
            "128420/128420 [==============================] - 16s 121us/step - loss: 2.0330 - accuracy: 0.5065 - val_loss: 15.5002 - val_accuracy: 0.2050\n",
            "Epoch 471/500\n",
            "128420/128420 [==============================] - 15s 120us/step - loss: 2.0418 - accuracy: 0.5040 - val_loss: 15.5986 - val_accuracy: 0.2043\n",
            "Epoch 472/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.0398 - accuracy: 0.5044 - val_loss: 15.6154 - val_accuracy: 0.2042\n",
            "Epoch 473/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0370 - accuracy: 0.5059 - val_loss: 15.4941 - val_accuracy: 0.2041\n",
            "Epoch 474/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0292 - accuracy: 0.5078 - val_loss: 15.6307 - val_accuracy: 0.2042\n",
            "Epoch 475/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0407 - accuracy: 0.5042 - val_loss: 15.6898 - val_accuracy: 0.2043\n",
            "Epoch 476/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0365 - accuracy: 0.5050 - val_loss: 15.6448 - val_accuracy: 0.2056\n",
            "Epoch 477/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.0315 - accuracy: 0.5067 - val_loss: 15.6515 - val_accuracy: 0.2055\n",
            "Epoch 478/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0272 - accuracy: 0.5057 - val_loss: 15.6877 - val_accuracy: 0.2047\n",
            "Epoch 479/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.0253 - accuracy: 0.5075 - val_loss: 15.6952 - val_accuracy: 0.2046\n",
            "Epoch 480/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0251 - accuracy: 0.5076 - val_loss: 15.8441 - val_accuracy: 0.2050\n",
            "Epoch 481/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0210 - accuracy: 0.5067 - val_loss: 15.6976 - val_accuracy: 0.2041\n",
            "Epoch 482/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0234 - accuracy: 0.5077 - val_loss: 15.7750 - val_accuracy: 0.2045\n",
            "Epoch 483/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0228 - accuracy: 0.5064 - val_loss: 15.8493 - val_accuracy: 0.2053\n",
            "Epoch 484/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0205 - accuracy: 0.5084 - val_loss: 15.7074 - val_accuracy: 0.2041\n",
            "Epoch 485/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0206 - accuracy: 0.5094 - val_loss: 15.6652 - val_accuracy: 0.2044\n",
            "Epoch 486/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0218 - accuracy: 0.5084 - val_loss: 15.7981 - val_accuracy: 0.2045\n",
            "Epoch 487/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0225 - accuracy: 0.5064 - val_loss: 15.7469 - val_accuracy: 0.2051\n",
            "Epoch 488/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0198 - accuracy: 0.5079 - val_loss: 15.7619 - val_accuracy: 0.2047\n",
            "Epoch 489/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0185 - accuracy: 0.5083 - val_loss: 15.7646 - val_accuracy: 0.2054\n",
            "Epoch 490/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0140 - accuracy: 0.5091 - val_loss: 15.6878 - val_accuracy: 0.2049\n",
            "Epoch 491/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0130 - accuracy: 0.5076 - val_loss: 15.7992 - val_accuracy: 0.2046\n",
            "Epoch 492/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0201 - accuracy: 0.5085 - val_loss: 15.7455 - val_accuracy: 0.2041\n",
            "Epoch 493/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0170 - accuracy: 0.5079 - val_loss: 15.6884 - val_accuracy: 0.2043\n",
            "Epoch 494/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0179 - accuracy: 0.5096 - val_loss: 15.8261 - val_accuracy: 0.2032\n",
            "Epoch 495/500\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 2.0085 - accuracy: 0.5102 - val_loss: 15.8969 - val_accuracy: 0.2038\n",
            "Epoch 496/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0099 - accuracy: 0.5110 - val_loss: 15.7110 - val_accuracy: 0.2044\n",
            "Epoch 497/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0081 - accuracy: 0.5120 - val_loss: 16.0086 - val_accuracy: 0.2043\n",
            "Epoch 498/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0068 - accuracy: 0.5101 - val_loss: 15.8753 - val_accuracy: 0.2057\n",
            "Epoch 499/500\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 2.0036 - accuracy: 0.5124 - val_loss: 15.7852 - val_accuracy: 0.2049\n",
            "Epoch 500/500\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 2.0048 - accuracy: 0.5106 - val_loss: 15.9131 - val_accuracy: 0.2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-W0a9SjaKqP",
        "colab_type": "text"
      },
      "source": [
        "#### Unidirectional, 1 layer, trainable, lstm-dropout-0.2, lstm-recurrent-dropout-0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQrDyV_laWmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = utils.make_word_level_model(\n",
        "    num_words,\n",
        "    embedding_matrix,\n",
        "    lstm_cells=64,\n",
        "    trainable=True,\n",
        "    lstm_layers=1,\n",
        "    bi_direc=False,\n",
        "    lstm_dropout=0.2,\n",
        "    lstm_recurrent_dropout=0.2,\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-T5Et6-aWpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9468624c-daa2-4e75-b940-4530833fb80c"
      },
      "source": [
        "train_history = utils.train_model(\n",
        "    training_dict,\n",
        "    f'{content_type}_uni-1_layer-trainable-50_seq-lstm_drop_0.2-lstm_rec_drop_0.2',\n",
        "    model=model,\n",
        "    # use_pretrained_model=True,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 128420 samples, validate on 55038 samples\n",
            "Epoch 1/50\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 7.7973 - accuracy: 0.0390 - val_loss: 6.9081 - val_accuracy: 0.0537\n",
            "Epoch 2/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 6.8475 - accuracy: 0.0506 - val_loss: 6.8325 - val_accuracy: 0.0537\n",
            "Epoch 3/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 6.7430 - accuracy: 0.0513 - val_loss: 6.8037 - val_accuracy: 0.0537\n",
            "Epoch 4/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 6.6897 - accuracy: 0.0577 - val_loss: 6.7953 - val_accuracy: 0.0696\n",
            "Epoch 5/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 6.6323 - accuracy: 0.0674 - val_loss: 6.7517 - val_accuracy: 0.0731\n",
            "Epoch 6/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 6.5480 - accuracy: 0.0748 - val_loss: 6.6813 - val_accuracy: 0.0777\n",
            "Epoch 7/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 6.4573 - accuracy: 0.0788 - val_loss: 6.6099 - val_accuracy: 0.0807\n",
            "Epoch 8/50\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 6.3594 - accuracy: 0.0847 - val_loss: 6.5343 - val_accuracy: 0.0893\n",
            "Epoch 9/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 6.2609 - accuracy: 0.0910 - val_loss: 6.4545 - val_accuracy: 0.0971\n",
            "Epoch 10/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 6.1675 - accuracy: 0.0975 - val_loss: 6.4111 - val_accuracy: 0.1028\n",
            "Epoch 11/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 6.0979 - accuracy: 0.1038 - val_loss: 6.3705 - val_accuracy: 0.1098\n",
            "Epoch 12/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 6.0242 - accuracy: 0.1111 - val_loss: 6.3296 - val_accuracy: 0.1185\n",
            "Epoch 13/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 5.9460 - accuracy: 0.1192 - val_loss: 6.2825 - val_accuracy: 0.1229\n",
            "Epoch 14/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 5.8670 - accuracy: 0.1230 - val_loss: 6.2496 - val_accuracy: 0.1252\n",
            "Epoch 15/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 5.7988 - accuracy: 0.1278 - val_loss: 6.2274 - val_accuracy: 0.1283\n",
            "Epoch 16/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 5.7375 - accuracy: 0.1308 - val_loss: 6.2059 - val_accuracy: 0.1305\n",
            "Epoch 17/50\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 5.6783 - accuracy: 0.1349 - val_loss: 6.1808 - val_accuracy: 0.1334\n",
            "Epoch 18/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 5.6300 - accuracy: 0.1373 - val_loss: 6.1654 - val_accuracy: 0.1369\n",
            "Epoch 19/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 5.5794 - accuracy: 0.1396 - val_loss: 6.1733 - val_accuracy: 0.1388\n",
            "Epoch 20/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 5.5350 - accuracy: 0.1427 - val_loss: 6.1676 - val_accuracy: 0.1401\n",
            "Epoch 21/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 5.4931 - accuracy: 0.1459 - val_loss: 6.1588 - val_accuracy: 0.1417\n",
            "Epoch 22/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 5.4530 - accuracy: 0.1477 - val_loss: 6.1688 - val_accuracy: 0.1437\n",
            "Epoch 23/50\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 5.4125 - accuracy: 0.1496 - val_loss: 6.1616 - val_accuracy: 0.1451\n",
            "Epoch 24/50\n",
            "128420/128420 [==============================] - 16s 123us/step - loss: 5.3704 - accuracy: 0.1520 - val_loss: 6.1586 - val_accuracy: 0.1455\n",
            "Epoch 25/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 5.3305 - accuracy: 0.1544 - val_loss: 6.1633 - val_accuracy: 0.1472\n",
            "Epoch 26/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 5.2895 - accuracy: 0.1575 - val_loss: 6.1644 - val_accuracy: 0.1470\n",
            "Epoch 27/50\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 5.2520 - accuracy: 0.1591 - val_loss: 6.1657 - val_accuracy: 0.1489\n",
            "Epoch 28/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 5.2175 - accuracy: 0.1615 - val_loss: 6.1669 - val_accuracy: 0.1500\n",
            "Epoch 29/50\n",
            "128420/128420 [==============================] - 15s 119us/step - loss: 5.1817 - accuracy: 0.1638 - val_loss: 6.1845 - val_accuracy: 0.1512\n",
            "Epoch 30/50\n",
            "128420/128420 [==============================] - 16s 122us/step - loss: 5.1447 - accuracy: 0.1657 - val_loss: 6.1902 - val_accuracy: 0.1528\n",
            "Epoch 31/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 5.1143 - accuracy: 0.1671 - val_loss: 6.1755 - val_accuracy: 0.1536\n",
            "Epoch 32/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 5.0794 - accuracy: 0.1703 - val_loss: 6.1990 - val_accuracy: 0.1559\n",
            "Epoch 33/50\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 5.0463 - accuracy: 0.1715 - val_loss: 6.2019 - val_accuracy: 0.1563\n",
            "Epoch 34/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 5.0170 - accuracy: 0.1736 - val_loss: 6.2218 - val_accuracy: 0.1573\n",
            "Epoch 35/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 4.9851 - accuracy: 0.1765 - val_loss: 6.2301 - val_accuracy: 0.1575\n",
            "Epoch 36/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 4.9507 - accuracy: 0.1788 - val_loss: 6.2272 - val_accuracy: 0.1590\n",
            "Epoch 37/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 4.9197 - accuracy: 0.1786 - val_loss: 6.2375 - val_accuracy: 0.1600\n",
            "Epoch 38/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 4.8884 - accuracy: 0.1811 - val_loss: 6.2431 - val_accuracy: 0.1613\n",
            "Epoch 39/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 4.8583 - accuracy: 0.1834 - val_loss: 6.2539 - val_accuracy: 0.1621\n",
            "Epoch 40/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 4.8278 - accuracy: 0.1864 - val_loss: 6.2693 - val_accuracy: 0.1631\n",
            "Epoch 41/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 4.7992 - accuracy: 0.1878 - val_loss: 6.2745 - val_accuracy: 0.1638\n",
            "Epoch 42/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 4.7662 - accuracy: 0.1894 - val_loss: 6.2845 - val_accuracy: 0.1647\n",
            "Epoch 43/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 4.7404 - accuracy: 0.1914 - val_loss: 6.3068 - val_accuracy: 0.1656\n",
            "Epoch 44/50\n",
            "128420/128420 [==============================] - 16s 124us/step - loss: 4.7115 - accuracy: 0.1931 - val_loss: 6.3134 - val_accuracy: 0.1652\n",
            "Epoch 45/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 4.6819 - accuracy: 0.1942 - val_loss: 6.3530 - val_accuracy: 0.1672\n",
            "Epoch 46/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 4.6555 - accuracy: 0.1960 - val_loss: 6.3651 - val_accuracy: 0.1672\n",
            "Epoch 47/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 4.6301 - accuracy: 0.1990 - val_loss: 6.3640 - val_accuracy: 0.1692\n",
            "Epoch 48/50\n",
            "128420/128420 [==============================] - 16s 126us/step - loss: 4.6002 - accuracy: 0.2001 - val_loss: 6.3940 - val_accuracy: 0.1693\n",
            "Epoch 49/50\n",
            "128420/128420 [==============================] - 16s 127us/step - loss: 4.5742 - accuracy: 0.2024 - val_loss: 6.3850 - val_accuracy: 0.1693\n",
            "Epoch 50/50\n",
            "128420/128420 [==============================] - 16s 125us/step - loss: 4.5492 - accuracy: 0.2031 - val_loss: 6.4229 - val_accuracy: 0.1706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRIGwyWOa1ak",
        "colab_type": "text"
      },
      "source": [
        "#### Unidirectional, 1 layer, trainable, lstm-dropout-0.5, lstm-recurrent-dropout-0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKYP5jZxaeFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = utils.make_word_level_model(\n",
        "    num_words,\n",
        "    embedding_matrix,\n",
        "    lstm_cells=64,\n",
        "    trainable=True,\n",
        "    lstm_layers=1,\n",
        "    bi_direc=False,\n",
        "    lstm_dropout=0.5,\n",
        "    lstm_recurrent_dropout=0.5,\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ3tcY0maeIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f43b2a74-a806-4f84-81e9-41d2df5e6c60"
      },
      "source": [
        "train_history = utils.train_model(\n",
        "    training_dict,\n",
        "    f'{content_type}_uni-1_layer-trainable-50_seq-lstm_drop_0.5-lstm_rec_drop_0.5',\n",
        "    model=model,\n",
        "    # use_pretrained_model=True,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 128420 samples, validate on 55038 samples\n",
            "Epoch 1/50\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 7.8465 - accuracy: 0.0385 - val_loss: 6.9133 - val_accuracy: 0.0537\n",
            "Epoch 2/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 6.8556 - accuracy: 0.0515 - val_loss: 6.8423 - val_accuracy: 0.0537\n",
            "Epoch 3/50\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 6.7569 - accuracy: 0.0524 - val_loss: 6.8120 - val_accuracy: 0.0537\n",
            "Epoch 4/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 6.7077 - accuracy: 0.0549 - val_loss: 6.8065 - val_accuracy: 0.0596\n",
            "Epoch 5/50\n",
            "128420/128420 [==============================] - 17s 133us/step - loss: 6.6515 - accuracy: 0.0666 - val_loss: 6.7440 - val_accuracy: 0.0725\n",
            "Epoch 6/50\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 6.5521 - accuracy: 0.0742 - val_loss: 6.6689 - val_accuracy: 0.0771\n",
            "Epoch 7/50\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 6.4651 - accuracy: 0.0777 - val_loss: 6.6107 - val_accuracy: 0.0800\n",
            "Epoch 8/50\n",
            "128420/128420 [==============================] - 18s 138us/step - loss: 6.3862 - accuracy: 0.0829 - val_loss: 6.5482 - val_accuracy: 0.0882\n",
            "Epoch 9/50\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 6.2953 - accuracy: 0.0879 - val_loss: 6.4836 - val_accuracy: 0.0919\n",
            "Epoch 10/50\n",
            "128420/128420 [==============================] - 18s 138us/step - loss: 6.2157 - accuracy: 0.0924 - val_loss: 6.4412 - val_accuracy: 0.0936\n",
            "Epoch 11/50\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 6.1530 - accuracy: 0.0970 - val_loss: 6.4131 - val_accuracy: 0.1035\n",
            "Epoch 12/50\n",
            "128420/128420 [==============================] - 18s 138us/step - loss: 6.0978 - accuracy: 0.1018 - val_loss: 6.3817 - val_accuracy: 0.1090\n",
            "Epoch 13/50\n",
            "128420/128420 [==============================] - 18s 138us/step - loss: 6.0468 - accuracy: 0.1055 - val_loss: 6.3519 - val_accuracy: 0.1109\n",
            "Epoch 14/50\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 5.9880 - accuracy: 0.1101 - val_loss: 6.3182 - val_accuracy: 0.1179\n",
            "Epoch 15/50\n",
            "128420/128420 [==============================] - 18s 138us/step - loss: 5.9345 - accuracy: 0.1135 - val_loss: 6.2941 - val_accuracy: 0.1188\n",
            "Epoch 16/50\n",
            "128420/128420 [==============================] - 18s 138us/step - loss: 5.8805 - accuracy: 0.1180 - val_loss: 6.2600 - val_accuracy: 0.1235\n",
            "Epoch 17/50\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 5.8249 - accuracy: 0.1213 - val_loss: 6.2375 - val_accuracy: 0.1253\n",
            "Epoch 18/50\n",
            "128420/128420 [==============================] - 18s 138us/step - loss: 5.7717 - accuracy: 0.1246 - val_loss: 6.2155 - val_accuracy: 0.1277\n",
            "Epoch 19/50\n",
            "128420/128420 [==============================] - 18s 137us/step - loss: 5.7239 - accuracy: 0.1270 - val_loss: 6.1896 - val_accuracy: 0.1305\n",
            "Epoch 20/50\n",
            "128420/128420 [==============================] - 17s 136us/step - loss: 5.6740 - accuracy: 0.1299 - val_loss: 6.1840 - val_accuracy: 0.1335\n",
            "Epoch 21/50\n",
            "128420/128420 [==============================] - 17s 135us/step - loss: 5.6353 - accuracy: 0.1336 - val_loss: 6.1669 - val_accuracy: 0.1364\n",
            "Epoch 22/50\n",
            "128420/128420 [==============================] - 17s 132us/step - loss: 5.5939 - accuracy: 0.1363 - val_loss: 6.1614 - val_accuracy: 0.1385\n",
            "Epoch 23/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.5571 - accuracy: 0.1387 - val_loss: 6.1576 - val_accuracy: 0.1414\n",
            "Epoch 24/50\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 5.5225 - accuracy: 0.1415 - val_loss: 6.1552 - val_accuracy: 0.1430\n",
            "Epoch 25/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.4925 - accuracy: 0.1438 - val_loss: 6.1534 - val_accuracy: 0.1451\n",
            "Epoch 26/50\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 5.4596 - accuracy: 0.1459 - val_loss: 6.1434 - val_accuracy: 0.1472\n",
            "Epoch 27/50\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 5.4298 - accuracy: 0.1490 - val_loss: 6.1481 - val_accuracy: 0.1487\n",
            "Epoch 28/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.4074 - accuracy: 0.1507 - val_loss: 6.1550 - val_accuracy: 0.1492\n",
            "Epoch 29/50\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 5.3763 - accuracy: 0.1527 - val_loss: 6.1480 - val_accuracy: 0.1514\n",
            "Epoch 30/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.3516 - accuracy: 0.1544 - val_loss: 6.1437 - val_accuracy: 0.1522\n",
            "Epoch 31/50\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 5.3264 - accuracy: 0.1555 - val_loss: 6.1552 - val_accuracy: 0.1516\n",
            "Epoch 32/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.3017 - accuracy: 0.1580 - val_loss: 6.1549 - val_accuracy: 0.1535\n",
            "Epoch 33/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.2789 - accuracy: 0.1588 - val_loss: 6.1596 - val_accuracy: 0.1556\n",
            "Epoch 34/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.2572 - accuracy: 0.1612 - val_loss: 6.1481 - val_accuracy: 0.1554\n",
            "Epoch 35/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.2352 - accuracy: 0.1619 - val_loss: 6.1592 - val_accuracy: 0.1568\n",
            "Epoch 36/50\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 5.2101 - accuracy: 0.1634 - val_loss: 6.1606 - val_accuracy: 0.1574\n",
            "Epoch 37/50\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 5.1886 - accuracy: 0.1652 - val_loss: 6.1623 - val_accuracy: 0.1577\n",
            "Epoch 38/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.1679 - accuracy: 0.1673 - val_loss: 6.1632 - val_accuracy: 0.1577\n",
            "Epoch 39/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.1478 - accuracy: 0.1683 - val_loss: 6.1551 - val_accuracy: 0.1581\n",
            "Epoch 40/50\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 5.1223 - accuracy: 0.1688 - val_loss: 6.1734 - val_accuracy: 0.1588\n",
            "Epoch 41/50\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 5.1058 - accuracy: 0.1708 - val_loss: 6.1849 - val_accuracy: 0.1584\n",
            "Epoch 42/50\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 5.0858 - accuracy: 0.1719 - val_loss: 6.1820 - val_accuracy: 0.1600\n",
            "Epoch 43/50\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 5.0648 - accuracy: 0.1723 - val_loss: 6.1908 - val_accuracy: 0.1601\n",
            "Epoch 44/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.0473 - accuracy: 0.1730 - val_loss: 6.1986 - val_accuracy: 0.1608\n",
            "Epoch 45/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 5.0295 - accuracy: 0.1746 - val_loss: 6.1932 - val_accuracy: 0.1617\n",
            "Epoch 46/50\n",
            "128420/128420 [==============================] - 17s 131us/step - loss: 5.0124 - accuracy: 0.1759 - val_loss: 6.1946 - val_accuracy: 0.1618\n",
            "Epoch 47/50\n",
            "128420/128420 [==============================] - 16s 128us/step - loss: 4.9918 - accuracy: 0.1755 - val_loss: 6.2037 - val_accuracy: 0.1629\n",
            "Epoch 48/50\n",
            "128420/128420 [==============================] - 17s 129us/step - loss: 4.9749 - accuracy: 0.1770 - val_loss: 6.2127 - val_accuracy: 0.1642\n",
            "Epoch 49/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 4.9571 - accuracy: 0.1787 - val_loss: 6.2175 - val_accuracy: 0.1643\n",
            "Epoch 50/50\n",
            "128420/128420 [==============================] - 17s 130us/step - loss: 4.9373 - accuracy: 0.1803 - val_loss: 6.2247 - val_accuracy: 0.1638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdo1CDeJaXN0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jTtRx-nX8Ol",
        "colab_type": "text"
      },
      "source": [
        "### Short Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvyKn6MjXaXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3873df8b-7078-49cf-c2a4-ff4604b9211f"
      },
      "source": [
        "training_dict, word_idx, idx_word, sequences, num_words = utils.get_data(text, training_len=20)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 14136 unique words.\n",
            "There are 195968 sequences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp7d0n2qXkuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "347910b8-093b-4352-acb5-dcf3622a6e46"
      },
      "source": [
        "# embedding_matrix = utils.create_embedding_matrix(word_idx, num_words, '/Users/jaipancholi/data/glove.6B.100d.txt')\n",
        "embedding_matrix = utils.create_embedding_matrix(word_idx, num_words, '/content/drive/My Drive/Code/autocomplete_me/data/glove.6B.100d.txt')\n",
        "embedding_matrix"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove Vectors loading with dimension 100\n",
            "There were 4852 words without pre-trained embeddings.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/src/utils.py:175: RuntimeWarning: invalid value encountered in true_divide\n",
            "  embedding_matrix = embedding_matrix / np.linalg.norm(embedding_matrix, axis=1).reshape((-1, 1))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.00656124, -0.04206555,  0.12508174, ..., -0.02506376,\n",
              "         0.14220549,  0.04648907],\n",
              "       [-0.06223089,  0.03835242,  0.08488411, ..., -0.04284497,\n",
              "         0.08662399, -0.00527513],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO9SeBF0vGRb",
        "colab_type": "text"
      },
      "source": [
        "#### Unidirectional, 1 layer, Trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFcGJJduuqw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = utils.make_word_level_model(\n",
        "    num_words,\n",
        "    embedding_matrix,\n",
        "    lstm_cells=64,\n",
        "    trainable=True,\n",
        "    lstm_layers=1,\n",
        "    bi_direc=False\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EycVkVjAutzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "601b8d66-d521-4a8a-9070-49dcf699d7dd"
      },
      "source": [
        "history = utils.train_model(\n",
        "    training_dict,\n",
        "    f'{content_type}_uni-1_layer-trainable-20_seq',\n",
        "    model=model,\n",
        "    # use_pretrained_model=True,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 137177 samples, validate on 58791 samples\n",
            "Epoch 1/50\n",
            "137177/137177 [==============================] - 17s 124us/step - loss: 7.7482 - accuracy: 0.0391 - val_loss: 6.8966 - val_accuracy: 0.0543\n",
            "Epoch 2/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.8565 - accuracy: 0.0509 - val_loss: 6.8254 - val_accuracy: 0.0543\n",
            "Epoch 3/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.7516 - accuracy: 0.0510 - val_loss: 6.7993 - val_accuracy: 0.0726\n",
            "Epoch 4/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.7029 - accuracy: 0.0564 - val_loss: 6.7925 - val_accuracy: 0.0727\n",
            "Epoch 5/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 6.6408 - accuracy: 0.0667 - val_loss: 6.7274 - val_accuracy: 0.0765\n",
            "Epoch 6/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 6.5507 - accuracy: 0.0738 - val_loss: 6.6666 - val_accuracy: 0.0797\n",
            "Epoch 7/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.4655 - accuracy: 0.0778 - val_loss: 6.6082 - val_accuracy: 0.0820\n",
            "Epoch 8/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 6.3840 - accuracy: 0.0825 - val_loss: 6.5572 - val_accuracy: 0.0907\n",
            "Epoch 9/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 6.3004 - accuracy: 0.0891 - val_loss: 6.4995 - val_accuracy: 0.0929\n",
            "Epoch 10/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 6.2248 - accuracy: 0.0927 - val_loss: 6.4498 - val_accuracy: 0.0958\n",
            "Epoch 11/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.1519 - accuracy: 0.0975 - val_loss: 6.4145 - val_accuracy: 0.1044\n",
            "Epoch 12/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 6.0804 - accuracy: 0.1032 - val_loss: 6.3741 - val_accuracy: 0.1111\n",
            "Epoch 13/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 6.0136 - accuracy: 0.1100 - val_loss: 6.3440 - val_accuracy: 0.1170\n",
            "Epoch 14/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 5.9407 - accuracy: 0.1175 - val_loss: 6.2994 - val_accuracy: 0.1199\n",
            "Epoch 15/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 5.8659 - accuracy: 0.1234 - val_loss: 6.2596 - val_accuracy: 0.1250\n",
            "Epoch 16/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 5.7937 - accuracy: 0.1285 - val_loss: 6.2233 - val_accuracy: 0.1313\n",
            "Epoch 17/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.7221 - accuracy: 0.1331 - val_loss: 6.1833 - val_accuracy: 0.1341\n",
            "Epoch 18/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 5.6509 - accuracy: 0.1374 - val_loss: 6.1639 - val_accuracy: 0.1345\n",
            "Epoch 19/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 5.5851 - accuracy: 0.1402 - val_loss: 6.1456 - val_accuracy: 0.1371\n",
            "Epoch 20/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 5.5268 - accuracy: 0.1440 - val_loss: 6.1294 - val_accuracy: 0.1387\n",
            "Epoch 21/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.4751 - accuracy: 0.1476 - val_loss: 6.1296 - val_accuracy: 0.1400\n",
            "Epoch 22/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.4275 - accuracy: 0.1508 - val_loss: 6.1184 - val_accuracy: 0.1416\n",
            "Epoch 23/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.3845 - accuracy: 0.1531 - val_loss: 6.1200 - val_accuracy: 0.1452\n",
            "Epoch 24/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.3425 - accuracy: 0.1559 - val_loss: 6.1161 - val_accuracy: 0.1456\n",
            "Epoch 25/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.3034 - accuracy: 0.1582 - val_loss: 6.1142 - val_accuracy: 0.1458\n",
            "Epoch 26/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.2592 - accuracy: 0.1611 - val_loss: 6.1167 - val_accuracy: 0.1490\n",
            "Epoch 27/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 5.2228 - accuracy: 0.1632 - val_loss: 6.1074 - val_accuracy: 0.1499\n",
            "Epoch 28/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.1779 - accuracy: 0.1659 - val_loss: 6.1196 - val_accuracy: 0.1525\n",
            "Epoch 29/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 5.1356 - accuracy: 0.1690 - val_loss: 6.1391 - val_accuracy: 0.1535\n",
            "Epoch 30/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.0954 - accuracy: 0.1716 - val_loss: 6.1420 - val_accuracy: 0.1545\n",
            "Epoch 31/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.0574 - accuracy: 0.1737 - val_loss: 6.1404 - val_accuracy: 0.1558\n",
            "Epoch 32/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.0182 - accuracy: 0.1766 - val_loss: 6.1466 - val_accuracy: 0.1570\n",
            "Epoch 33/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 4.9792 - accuracy: 0.1796 - val_loss: 6.1602 - val_accuracy: 0.1593\n",
            "Epoch 34/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 4.9469 - accuracy: 0.1817 - val_loss: 6.1729 - val_accuracy: 0.1599\n",
            "Epoch 35/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 4.9104 - accuracy: 0.1835 - val_loss: 6.1795 - val_accuracy: 0.1609\n",
            "Epoch 36/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.8790 - accuracy: 0.1859 - val_loss: 6.1885 - val_accuracy: 0.1617\n",
            "Epoch 37/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.8451 - accuracy: 0.1880 - val_loss: 6.1938 - val_accuracy: 0.1627\n",
            "Epoch 38/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.8084 - accuracy: 0.1913 - val_loss: 6.2158 - val_accuracy: 0.1638\n",
            "Epoch 39/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 4.7793 - accuracy: 0.1931 - val_loss: 6.2292 - val_accuracy: 0.1647\n",
            "Epoch 40/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 4.7459 - accuracy: 0.1940 - val_loss: 6.2477 - val_accuracy: 0.1651\n",
            "Epoch 41/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.7132 - accuracy: 0.1964 - val_loss: 6.2527 - val_accuracy: 0.1667\n",
            "Epoch 42/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 4.6837 - accuracy: 0.1991 - val_loss: 6.2810 - val_accuracy: 0.1659\n",
            "Epoch 43/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.6530 - accuracy: 0.2009 - val_loss: 6.2971 - val_accuracy: 0.1672\n",
            "Epoch 44/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.6215 - accuracy: 0.2025 - val_loss: 6.3224 - val_accuracy: 0.1691\n",
            "Epoch 45/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 4.5937 - accuracy: 0.2035 - val_loss: 6.3443 - val_accuracy: 0.1699\n",
            "Epoch 46/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 4.5666 - accuracy: 0.2045 - val_loss: 6.3597 - val_accuracy: 0.1695\n",
            "Epoch 47/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 4.5370 - accuracy: 0.2064 - val_loss: 6.3756 - val_accuracy: 0.1709\n",
            "Epoch 48/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 4.5112 - accuracy: 0.2090 - val_loss: 6.3939 - val_accuracy: 0.1716\n",
            "Epoch 49/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 4.4841 - accuracy: 0.2110 - val_loss: 6.3920 - val_accuracy: 0.1703\n",
            "Epoch 50/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 4.4612 - accuracy: 0.2127 - val_loss: 6.4449 - val_accuracy: 0.1725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCSth3xmkM4T",
        "colab_type": "text"
      },
      "source": [
        "#### Unidirectional, 1 layer, trainable, lstm-dropout-0.2, lstm-recurrent-dropout-0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc746ADwkM-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = utils.make_word_level_model(\n",
        "    num_words,\n",
        "    embedding_matrix,\n",
        "    lstm_cells=64,\n",
        "    trainable=True,\n",
        "    lstm_layers=1,\n",
        "    bi_direc=False,\n",
        "    lstm_dropout=0.2,\n",
        "    lstm_recurrent_dropout=0.2,\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vsEjBDbkNCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db72d989-9147-4ca3-f1f4-74605f65ec8a"
      },
      "source": [
        "history = utils.train_model(\n",
        "    training_dict,\n",
        "    f'{content_type}_uni-1_layer-trainable-20_seq-lstm_drop_0.2-lstm_rec_drop_0.2',\n",
        "    model=model,\n",
        "    # use_pretrained_model=True,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 137177 samples, validate on 58791 samples\n",
            "Epoch 1/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 7.7788 - accuracy: 0.0371 - val_loss: 6.8971 - val_accuracy: 0.0543\n",
            "Epoch 2/50\n",
            "137177/137177 [==============================] - 14s 102us/step - loss: 6.8567 - accuracy: 0.0505 - val_loss: 6.8270 - val_accuracy: 0.0543\n",
            "Epoch 3/50\n",
            "137177/137177 [==============================] - 14s 102us/step - loss: 6.7525 - accuracy: 0.0514 - val_loss: 6.7986 - val_accuracy: 0.0543\n",
            "Epoch 4/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 6.7025 - accuracy: 0.0573 - val_loss: 6.7902 - val_accuracy: 0.0683\n",
            "Epoch 5/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 6.6399 - accuracy: 0.0682 - val_loss: 6.7259 - val_accuracy: 0.0769\n",
            "Epoch 6/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 6.5436 - accuracy: 0.0750 - val_loss: 6.6538 - val_accuracy: 0.0804\n",
            "Epoch 7/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 6.4554 - accuracy: 0.0791 - val_loss: 6.5880 - val_accuracy: 0.0832\n",
            "Epoch 8/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 6.3661 - accuracy: 0.0856 - val_loss: 6.5400 - val_accuracy: 0.0919\n",
            "Epoch 9/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 6.2840 - accuracy: 0.0899 - val_loss: 6.4815 - val_accuracy: 0.0963\n",
            "Epoch 10/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 6.2111 - accuracy: 0.0928 - val_loss: 6.4472 - val_accuracy: 0.0961\n",
            "Epoch 11/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 6.1510 - accuracy: 0.0979 - val_loss: 6.4158 - val_accuracy: 0.1040\n",
            "Epoch 12/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 6.0970 - accuracy: 0.1025 - val_loss: 6.3973 - val_accuracy: 0.1076\n",
            "Epoch 13/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 6.0444 - accuracy: 0.1067 - val_loss: 6.3623 - val_accuracy: 0.1118\n",
            "Epoch 14/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 5.9895 - accuracy: 0.1117 - val_loss: 6.3325 - val_accuracy: 0.1155\n",
            "Epoch 15/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 5.9297 - accuracy: 0.1173 - val_loss: 6.2962 - val_accuracy: 0.1193\n",
            "Epoch 16/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 5.8695 - accuracy: 0.1227 - val_loss: 6.2667 - val_accuracy: 0.1194\n",
            "Epoch 17/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 5.8143 - accuracy: 0.1265 - val_loss: 6.2397 - val_accuracy: 0.1262\n",
            "Epoch 18/50\n",
            "137177/137177 [==============================] - 14s 101us/step - loss: 5.7485 - accuracy: 0.1324 - val_loss: 6.2054 - val_accuracy: 0.1306\n",
            "Epoch 19/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 5.6955 - accuracy: 0.1368 - val_loss: 6.1795 - val_accuracy: 0.1346\n",
            "Epoch 20/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 5.6478 - accuracy: 0.1388 - val_loss: 6.1627 - val_accuracy: 0.1365\n",
            "Epoch 21/50\n",
            "137177/137177 [==============================] - 14s 100us/step - loss: 5.6005 - accuracy: 0.1425 - val_loss: 6.1454 - val_accuracy: 0.1396\n",
            "Epoch 22/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 5.5545 - accuracy: 0.1457 - val_loss: 6.1334 - val_accuracy: 0.1399\n",
            "Epoch 23/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.5085 - accuracy: 0.1483 - val_loss: 6.1322 - val_accuracy: 0.1422\n",
            "Epoch 24/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.4638 - accuracy: 0.1507 - val_loss: 6.1146 - val_accuracy: 0.1442\n",
            "Epoch 25/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.4235 - accuracy: 0.1541 - val_loss: 6.1063 - val_accuracy: 0.1454\n",
            "Epoch 26/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.3810 - accuracy: 0.1559 - val_loss: 6.0963 - val_accuracy: 0.1480\n",
            "Epoch 27/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.3362 - accuracy: 0.1577 - val_loss: 6.0990 - val_accuracy: 0.1499\n",
            "Epoch 28/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.2966 - accuracy: 0.1600 - val_loss: 6.0922 - val_accuracy: 0.1519\n",
            "Epoch 29/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.2594 - accuracy: 0.1631 - val_loss: 6.0962 - val_accuracy: 0.1521\n",
            "Epoch 30/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.2202 - accuracy: 0.1656 - val_loss: 6.0916 - val_accuracy: 0.1535\n",
            "Epoch 31/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.1862 - accuracy: 0.1680 - val_loss: 6.1025 - val_accuracy: 0.1542\n",
            "Epoch 32/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.1517 - accuracy: 0.1698 - val_loss: 6.1082 - val_accuracy: 0.1558\n",
            "Epoch 33/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 5.1223 - accuracy: 0.1713 - val_loss: 6.1198 - val_accuracy: 0.1574\n",
            "Epoch 34/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 5.0910 - accuracy: 0.1741 - val_loss: 6.1203 - val_accuracy: 0.1582\n",
            "Epoch 35/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.0610 - accuracy: 0.1758 - val_loss: 6.1180 - val_accuracy: 0.1600\n",
            "Epoch 36/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 5.0342 - accuracy: 0.1778 - val_loss: 6.1354 - val_accuracy: 0.1607\n",
            "Epoch 37/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 5.0054 - accuracy: 0.1796 - val_loss: 6.1443 - val_accuracy: 0.1620\n",
            "Epoch 38/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.9757 - accuracy: 0.1805 - val_loss: 6.1522 - val_accuracy: 0.1635\n",
            "Epoch 39/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.9440 - accuracy: 0.1833 - val_loss: 6.1553 - val_accuracy: 0.1649\n",
            "Epoch 40/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 4.9184 - accuracy: 0.1848 - val_loss: 6.1761 - val_accuracy: 0.1636\n",
            "Epoch 41/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.8892 - accuracy: 0.1869 - val_loss: 6.1735 - val_accuracy: 0.1650\n",
            "Epoch 42/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.8626 - accuracy: 0.1877 - val_loss: 6.1886 - val_accuracy: 0.1651\n",
            "Epoch 43/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.8373 - accuracy: 0.1891 - val_loss: 6.2125 - val_accuracy: 0.1665\n",
            "Epoch 44/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 4.8115 - accuracy: 0.1909 - val_loss: 6.2181 - val_accuracy: 0.1669\n",
            "Epoch 45/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 4.7856 - accuracy: 0.1918 - val_loss: 6.2147 - val_accuracy: 0.1682\n",
            "Epoch 46/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 4.7625 - accuracy: 0.1932 - val_loss: 6.2284 - val_accuracy: 0.1683\n",
            "Epoch 47/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.7410 - accuracy: 0.1944 - val_loss: 6.2524 - val_accuracy: 0.1687\n",
            "Epoch 48/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 4.7145 - accuracy: 0.1964 - val_loss: 6.2416 - val_accuracy: 0.1695\n",
            "Epoch 49/50\n",
            "137177/137177 [==============================] - 14s 103us/step - loss: 4.6907 - accuracy: 0.1984 - val_loss: 6.2739 - val_accuracy: 0.1696\n",
            "Epoch 50/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.6729 - accuracy: 0.1989 - val_loss: 6.2899 - val_accuracy: 0.1706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPxeyP01kNbx",
        "colab_type": "text"
      },
      "source": [
        "#### Unidirectional, 1 layer, trainable, lstm-dropout-0.5, lstm-recurrent-dropout-0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MLIOK5ykNpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = utils.make_word_level_model(\n",
        "    num_words,\n",
        "    embedding_matrix,\n",
        "    lstm_cells=64,\n",
        "    trainable=True,\n",
        "    lstm_layers=1,\n",
        "    bi_direc=False,\n",
        "    lstm_dropout=0.5,\n",
        "    lstm_recurrent_dropout=0.5,\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOF3akHbkNtE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64f55d46-cc84-4c9b-e71f-c39b3fc95605"
      },
      "source": [
        "history = utils.train_model(\n",
        "    training_dict,\n",
        "    f'{content_type}_uni-1_layer-trainable-20_seq-lstm_drop_0.5-lstm_rec_drop_0.5',\n",
        "    model=model,\n",
        "    # use_pretrained_model=True,\n",
        "    epochs=50\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 137177 samples, validate on 58791 samples\n",
            "Epoch 1/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 7.7921 - accuracy: 0.0378 - val_loss: 6.8946 - val_accuracy: 0.0543\n",
            "Epoch 2/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 6.8547 - accuracy: 0.0505 - val_loss: 6.8311 - val_accuracy: 0.0543\n",
            "Epoch 3/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 6.7629 - accuracy: 0.0507 - val_loss: 6.8057 - val_accuracy: 0.0543\n",
            "Epoch 4/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.7194 - accuracy: 0.0527 - val_loss: 6.8063 - val_accuracy: 0.0543\n",
            "Epoch 5/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.6749 - accuracy: 0.0633 - val_loss: 6.7488 - val_accuracy: 0.0732\n",
            "Epoch 6/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.5788 - accuracy: 0.0726 - val_loss: 6.6579 - val_accuracy: 0.0780\n",
            "Epoch 7/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 6.4710 - accuracy: 0.0782 - val_loss: 6.5860 - val_accuracy: 0.0840\n",
            "Epoch 8/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.3895 - accuracy: 0.0852 - val_loss: 6.5505 - val_accuracy: 0.0909\n",
            "Epoch 9/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.3242 - accuracy: 0.0884 - val_loss: 6.5149 - val_accuracy: 0.0921\n",
            "Epoch 10/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.2606 - accuracy: 0.0906 - val_loss: 6.4701 - val_accuracy: 0.0942\n",
            "Epoch 11/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 6.2009 - accuracy: 0.0943 - val_loss: 6.4393 - val_accuracy: 0.1019\n",
            "Epoch 12/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.1438 - accuracy: 0.0993 - val_loss: 6.4034 - val_accuracy: 0.1054\n",
            "Epoch 13/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.0884 - accuracy: 0.1046 - val_loss: 6.3746 - val_accuracy: 0.1113\n",
            "Epoch 14/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 6.0359 - accuracy: 0.1102 - val_loss: 6.3431 - val_accuracy: 0.1148\n",
            "Epoch 15/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 5.9842 - accuracy: 0.1153 - val_loss: 6.3026 - val_accuracy: 0.1199\n",
            "Epoch 16/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.9222 - accuracy: 0.1198 - val_loss: 6.2644 - val_accuracy: 0.1205\n",
            "Epoch 17/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.8573 - accuracy: 0.1231 - val_loss: 6.2230 - val_accuracy: 0.1236\n",
            "Epoch 18/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 5.7967 - accuracy: 0.1276 - val_loss: 6.1895 - val_accuracy: 0.1299\n",
            "Epoch 19/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.7417 - accuracy: 0.1307 - val_loss: 6.1645 - val_accuracy: 0.1328\n",
            "Epoch 20/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 5.6931 - accuracy: 0.1346 - val_loss: 6.1469 - val_accuracy: 0.1357\n",
            "Epoch 21/50\n",
            "137177/137177 [==============================] - 15s 108us/step - loss: 5.6457 - accuracy: 0.1380 - val_loss: 6.1284 - val_accuracy: 0.1377\n",
            "Epoch 22/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.6059 - accuracy: 0.1401 - val_loss: 6.1200 - val_accuracy: 0.1397\n",
            "Epoch 23/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 5.5650 - accuracy: 0.1421 - val_loss: 6.1112 - val_accuracy: 0.1404\n",
            "Epoch 24/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 5.5272 - accuracy: 0.1447 - val_loss: 6.0970 - val_accuracy: 0.1432\n",
            "Epoch 25/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.4869 - accuracy: 0.1464 - val_loss: 6.0902 - val_accuracy: 0.1441\n",
            "Epoch 26/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.4532 - accuracy: 0.1488 - val_loss: 6.0879 - val_accuracy: 0.1453\n",
            "Epoch 27/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.4178 - accuracy: 0.1510 - val_loss: 6.0723 - val_accuracy: 0.1488\n",
            "Epoch 28/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 5.3896 - accuracy: 0.1539 - val_loss: 6.0766 - val_accuracy: 0.1500\n",
            "Epoch 29/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.3572 - accuracy: 0.1557 - val_loss: 6.0778 - val_accuracy: 0.1515\n",
            "Epoch 30/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.3213 - accuracy: 0.1568 - val_loss: 6.0794 - val_accuracy: 0.1518\n",
            "Epoch 31/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.2961 - accuracy: 0.1588 - val_loss: 6.0723 - val_accuracy: 0.1541\n",
            "Epoch 32/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.2658 - accuracy: 0.1606 - val_loss: 6.0835 - val_accuracy: 0.1555\n",
            "Epoch 33/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.2395 - accuracy: 0.1616 - val_loss: 6.0767 - val_accuracy: 0.1565\n",
            "Epoch 34/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.2103 - accuracy: 0.1638 - val_loss: 6.0876 - val_accuracy: 0.1569\n",
            "Epoch 35/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.1835 - accuracy: 0.1666 - val_loss: 6.0802 - val_accuracy: 0.1584\n",
            "Epoch 36/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.1564 - accuracy: 0.1670 - val_loss: 6.0812 - val_accuracy: 0.1593\n",
            "Epoch 37/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.1327 - accuracy: 0.1680 - val_loss: 6.0969 - val_accuracy: 0.1593\n",
            "Epoch 38/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 5.1085 - accuracy: 0.1704 - val_loss: 6.0919 - val_accuracy: 0.1606\n",
            "Epoch 39/50\n",
            "137177/137177 [==============================] - 14s 106us/step - loss: 5.0868 - accuracy: 0.1721 - val_loss: 6.1023 - val_accuracy: 0.1611\n",
            "Epoch 40/50\n",
            "137177/137177 [==============================] - 15s 107us/step - loss: 5.0636 - accuracy: 0.1717 - val_loss: 6.1111 - val_accuracy: 0.1639\n",
            "Epoch 41/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.0395 - accuracy: 0.1741 - val_loss: 6.1076 - val_accuracy: 0.1637\n",
            "Epoch 42/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 5.0164 - accuracy: 0.1750 - val_loss: 6.1073 - val_accuracy: 0.1650\n",
            "Epoch 43/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 4.9949 - accuracy: 0.1758 - val_loss: 6.1156 - val_accuracy: 0.1653\n",
            "Epoch 44/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 4.9785 - accuracy: 0.1779 - val_loss: 6.1122 - val_accuracy: 0.1662\n",
            "Epoch 45/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 4.9551 - accuracy: 0.1790 - val_loss: 6.1395 - val_accuracy: 0.1666\n",
            "Epoch 46/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 4.9335 - accuracy: 0.1801 - val_loss: 6.1483 - val_accuracy: 0.1681\n",
            "Epoch 47/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 4.9176 - accuracy: 0.1812 - val_loss: 6.1515 - val_accuracy: 0.1689\n",
            "Epoch 48/50\n",
            "137177/137177 [==============================] - 15s 106us/step - loss: 4.8968 - accuracy: 0.1812 - val_loss: 6.1545 - val_accuracy: 0.1699\n",
            "Epoch 49/50\n",
            "137177/137177 [==============================] - 14s 105us/step - loss: 4.8795 - accuracy: 0.1827 - val_loss: 6.1764 - val_accuracy: 0.1715\n",
            "Epoch 50/50\n",
            "137177/137177 [==============================] - 14s 104us/step - loss: 4.8599 - accuracy: 0.1836 - val_loss: 6.1667 - val_accuracy: 0.1719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-AP8swgwKuL",
        "colab_type": "text"
      },
      "source": [
        "## Compare Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ5j11YH-Ilt",
        "colab_type": "text"
      },
      "source": [
        "<tr>\n",
        "    <th>Name of Model</th>\n",
        "    <th>LTSM Layers</th>\n",
        "    <th>Bidirectional</th>\n",
        "    <th>Trainable Embeddings</th>\n",
        "    <th>Sequence Length</th>\n",
        "    <th>LSTM Dropout</th>\n",
        "    <th>LSTM Recurrent Dropout</th>\n",
        "    <th>Val Loss</th>\n",
        "    <th>Val Accuracy</th>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>50</td>\n",
        "    <td>0.1</td>\n",
        "    <td>0.1</td>\n",
        "    <td>6.5235</td>\n",
        "    <td>0.1715</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>50</td>\n",
        "    <td>0.2</td>\n",
        "    <td>0.2</td>\n",
        "    <td>6.4229</td>\n",
        "    <td>0.1706</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>50</td>\n",
        "    <td>0.5</td>\n",
        "    <td>0.5</td>\n",
        "    <td>6.2247</td>\n",
        "    <td>0.1638</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>20</td>\n",
        "    <td>0.1</td>\n",
        "    <td>0.1</td>\n",
        "    <td>6.4449</td>\n",
        "    <td>0.1725</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>20</td>\n",
        "    <td>0.2</td>\n",
        "    <td>0.2</td>\n",
        "    <td>6.2899</td>\n",
        "    <td>0.1706</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>20</td>\n",
        "    <td>0.5</td>\n",
        "    <td>0.5</td>\n",
        "    <td>6.1667</td>\n",
        "    <td>0.1719</td>\n",
        "</tr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4sO-VEvxo27",
        "colab_type": "text"
      },
      "source": [
        "# Sample Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYttbKDgsWU-",
        "colab_type": "text"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TYDcQIf6-Yz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cd1e7177-d63b-41a7-bde7-6374e3752325"
      },
      "source": [
        "from keras.models import load_model\n",
        "# Get Model Weights and Architecture\n",
        "\n",
        "# MODELS_DIR = os.path.join(os.path.dirname(os.path.abspath('')), 'models')\n",
        "MODELS_DIR = '/content/drive/My Drive/Code/autocomplete_me/models'\n",
        "model_filepath = os.path.join(MODELS_DIR, f'{content_type}_uni-1_layer-trainable-50_seq.h5')\n",
        "\n",
        "model = load_model(model_filepath)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHGsZlQj6-b6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c44efd5-6254-4ea3-bdaf-835eede48a32"
      },
      "source": [
        "# Get Text Data\n",
        "# text = reader.read_bbc_politics()\n",
        "\n",
        "TRAINING_LENGTH = 50\n",
        "training_dict, word_idx, idx_word, sequences, num_words = utils.get_data(text, training_len=TRAINING_LENGTH)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 14136 unique words.\n",
            "There are 183458 sequences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaZAatAF6-hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_sequence, gen_list, a = predict_utils.generate_output(\n",
        "    model,\n",
        "    sequences,\n",
        "    idx_word,\n",
        "    seed_length=TRAINING_LENGTH,\n",
        "    new_words=50,\n",
        "    diversity=1,\n",
        "    n_gen=1\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64w4-h_e7Jr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6c3f7a7c-bc22-4e17-d5ff-7921affa5281"
      },
      "source": [
        "' '.join(word for word in original_sequence)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'He has also started to recruit 25,000 Community Support Officers (CSOs) and the new plans would allow all police forces to give them the power to detain suspects . An extra £50m was promised on Tuesday so 2,000 new CSOs can be recruited now rather than next year . Within'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1jQ8g547Ju7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7ea1f3f8-8feb-4789-e887-b9dbf92b1b41"
      },
      "source": [
        "' '.join(word for word in gen_list[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'< --- > mass squabbling in them living and get in ducking by nationality to door , leaving to tackle clear that you know him as the Poland . But he was wrong up their backbencher plans , which chairman for responsibility for new benefits to an £71,433 had confess of his Union'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKpJGPVZZyai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8006d703-7f41-4a8a-9fa3-5c325ded316a"
      },
      "source": [
        "' '.join(word for word in a)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"< --- > two years , every force will be expected to keep to a coppers' contract on what kind of service the public can expect . A Mori poll this summer suggested policing , unlike health and education , was the one major public service where people were less satisfied the more\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3UVTdcZ7Jz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a4c9942f-c4bf-4507-dd3e-4a97e0fed7d3"
      },
      "source": [
        "sentence = 'Stocks of major large technology firms are becoming'\n",
        "predict_utils.generate_custom_sentence(sentence, word_idx, idx_word, model, new_words=50)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[None, 5, 479, 714, 2354, 2532, 25, 1215]\n",
            "role . Many accused the US . Mr Campbell said the cost of Constitutional second record - in tax and Amnesty intervals . And it can new pair around as the English country of or match the House of other year's binge child , UKIP Party feels Veritas , .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG6xgAXVu0Og",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "10ec261b-bf4e-4282-8ed6-ebacb66e5e20"
      },
      "source": [
        "sentence = 'However, there have been many instances of'\n",
        "predict_utils.generate_custom_sentence(sentence, word_idx, idx_word, model, new_words=50)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[None, 55, 21, 42, 169, 5319, 5]\n",
            "its party's approach to the watchdog AND visit to part for a maximum credits have have shown to new slow at Iraq has straightforward by they , gaming minister has under affect Washington would not Defra's trying on the next Dem 10 vote , despite act in it's changed had\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGtMQQWYZ1EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}