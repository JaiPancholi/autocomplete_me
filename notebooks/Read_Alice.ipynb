{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Read Alice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRwiWNu6INq5",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5LjiPvdBUHV",
        "colab_type": "text"
      },
      "source": [
        "## Google Only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjSCr2_-BUHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5a691905-ec86-4200-f24e-cf7bdf9e7064"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvs4RSdij9st",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAJzt-moBUHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
        "sys.path.append('/content/drive/My Drive/Code/autocomplete_me')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3cVnuFRvRK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a2fcfd57-2802-4d63-ce08-3add6131886f"
      },
      "source": [
        "!ls -l '/content/drive/My Drive/Code/autocomplete_me/src'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 19\n",
            "-rw------- 1 root root 2516 Jul 12 14:10 predict_utils.py\n",
            "drwx------ 2 root root 4096 Jul 11 13:20 __pycache__\n",
            "-rw------- 1 root root 2943 Jul 12 15:50 reader.py\n",
            "-rw------- 1 root root 9341 Jul 12 14:24 utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q94gYQGGBUHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e90d9b9-f567-4435-fc85-3280e033a9d0"
      },
      "source": [
        "from src import utils, reader, predict_utils"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK5LK2ohBUHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "446b9ba3-6620-45e7-a06e-f25e749ade4b"
      },
      "source": [
        "from importlib import reload\n",
        "reload(utils)\n",
        "reload(reader)\n",
        "reload(predict_utils)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'src.predict_utils' from '/content/drive/My Drive/Code/autocomplete_me/src/predict_utils.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2i_aQqeF444",
        "colab_type": "text"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6ACaCZLF9wP",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGdkdzSeBUHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = reader.read_alice()\n",
        "content_type = 'Alice'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFB5H3BdLHAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f892592-5cd6-4e10-dd92-ff682e8d5d87"
      },
      "source": [
        "text[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'           ALICE’S ADVENTURES IN WONDERLAND  Lewis Carroll  THE MILLENNIUM FULCRUM EDITION 3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ptgRgRReTyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c71485b1-62bb-40c7-f90b-1870d6462948"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "991"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jTtRx-nX8Ol",
        "colab_type": "text"
      },
      "source": [
        "### Short Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvyKn6MjXaXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7bad53c4-9cc5-4039-cd35-7c8678db4350"
      },
      "source": [
        "training_dict, word_idx, idx_word, sequences, num_words = utils.get_data(text, training_len=20, short=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 3659 unique words.\n",
            "There are 13925 sequences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4XMvOm0Zd6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c97262da-229b-478f-832a-bdd226b0f9e8"
      },
      "source": [
        "len(training_dict)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp7d0n2qXkuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "eb8f2f2f-3f7e-4c1f-e1f6-a70b9c1e719a"
      },
      "source": [
        "# embedding_matrix = utils.create_embedding_matrix(word_idx, num_words, '/Users/jaipancholi/data/glove.6B.100d.txt')\n",
        "embedding_matrix = utils.create_embedding_matrix(word_idx, num_words, '/content/drive/My Drive/Code/autocomplete_me/data/glove.6B.100d.txt')\n",
        "embedding_matrix"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove Vectors loading with dimension 100\n",
            "There were 1361 words without pre-trained embeddings.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/src/utils.py:180: RuntimeWarning: invalid value encountered in true_divide\n",
            "  embedding_matrix = embedding_matrix / np.linalg.norm(embedding_matrix, axis=1).reshape((-1, 1))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.01938821,  0.01990321,  0.10770387, ..., -0.14973777,\n",
              "         0.08155941,  0.0148697 ],\n",
              "       [-0.00656124, -0.04206555,  0.12508174, ..., -0.02506376,\n",
              "         0.14220549,  0.04648907],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO9SeBF0vGRb",
        "colab_type": "text"
      },
      "source": [
        "#### Unidirectional, 1 layer, Trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFcGJJduuqw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = utils.make_word_level_model(\n",
        "    num_words,\n",
        "    embedding_matrix,\n",
        "    lstm_cells=64,\n",
        "    trainable=True,\n",
        "    lstm_layers=1,\n",
        "    bi_direc=False\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EycVkVjAutzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "052c8183-4c97-4929-9ab4-b38d299361bf"
      },
      "source": [
        "history = utils.train_model(\n",
        "    training_dict,\n",
        "    f'{content_type}_uni-1_layer-trainable-20_seq',\n",
        "    model=model,\n",
        "    # use_pretrained_model=True,\n",
        "    epochs=250\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 9747 samples, validate on 4178 samples\n",
            "Epoch 1/250\n",
            "9747/9747 [==============================] - 3s 289us/step - loss: 8.1963 - accuracy: 0.0070 - val_loss: 8.1758 - val_accuracy: 0.0476\n",
            "Epoch 2/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 8.1396 - accuracy: 0.0330 - val_loss: 8.0671 - val_accuracy: 0.0481\n",
            "Epoch 3/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 7.9322 - accuracy: 0.0361 - val_loss: 7.6935 - val_accuracy: 0.0479\n",
            "Epoch 4/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 7.3538 - accuracy: 0.0363 - val_loss: 6.9723 - val_accuracy: 0.0479\n",
            "Epoch 5/250\n",
            "9747/9747 [==============================] - 1s 72us/step - loss: 6.5641 - accuracy: 0.0421 - val_loss: 6.5211 - val_accuracy: 0.0479\n",
            "Epoch 6/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 6.1974 - accuracy: 0.0488 - val_loss: 6.6320 - val_accuracy: 0.0479\n",
            "Epoch 7/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 6.2009 - accuracy: 0.0603 - val_loss: 6.6440 - val_accuracy: 0.0742\n",
            "Epoch 8/250\n",
            "9747/9747 [==============================] - 1s 69us/step - loss: 6.1231 - accuracy: 0.0660 - val_loss: 6.5265 - val_accuracy: 0.0742\n",
            "Epoch 9/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 6.0711 - accuracy: 0.0675 - val_loss: 6.5263 - val_accuracy: 0.0742\n",
            "Epoch 10/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 6.0794 - accuracy: 0.0678 - val_loss: 6.5335 - val_accuracy: 0.0742\n",
            "Epoch 11/250\n",
            "9747/9747 [==============================] - 1s 69us/step - loss: 6.0541 - accuracy: 0.0684 - val_loss: 6.5511 - val_accuracy: 0.0742\n",
            "Epoch 12/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 6.0367 - accuracy: 0.0681 - val_loss: 6.5879 - val_accuracy: 0.0742\n",
            "Epoch 13/250\n",
            "9747/9747 [==============================] - 1s 72us/step - loss: 6.0322 - accuracy: 0.0660 - val_loss: 6.5886 - val_accuracy: 0.0742\n",
            "Epoch 14/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 6.0182 - accuracy: 0.0659 - val_loss: 6.5773 - val_accuracy: 0.0742\n",
            "Epoch 15/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 6.0208 - accuracy: 0.0670 - val_loss: 6.5769 - val_accuracy: 0.0742\n",
            "Epoch 16/250\n",
            "9747/9747 [==============================] - 1s 73us/step - loss: 6.0056 - accuracy: 0.0695 - val_loss: 6.5844 - val_accuracy: 0.0742\n",
            "Epoch 17/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 5.9960 - accuracy: 0.0691 - val_loss: 6.5949 - val_accuracy: 0.0742\n",
            "Epoch 18/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 5.9911 - accuracy: 0.0695 - val_loss: 6.5940 - val_accuracy: 0.0742\n",
            "Epoch 19/250\n",
            "9747/9747 [==============================] - 1s 69us/step - loss: 5.9825 - accuracy: 0.0689 - val_loss: 6.5873 - val_accuracy: 0.0742\n",
            "Epoch 20/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 5.9731 - accuracy: 0.0708 - val_loss: 6.5823 - val_accuracy: 0.0742\n",
            "Epoch 21/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 5.9571 - accuracy: 0.0697 - val_loss: 6.5795 - val_accuracy: 0.0742\n",
            "Epoch 22/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 5.9483 - accuracy: 0.0688 - val_loss: 6.5751 - val_accuracy: 0.0742\n",
            "Epoch 23/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 5.9340 - accuracy: 0.0682 - val_loss: 6.5678 - val_accuracy: 0.0742\n",
            "Epoch 24/250\n",
            "9747/9747 [==============================] - 1s 72us/step - loss: 5.9175 - accuracy: 0.0673 - val_loss: 6.5562 - val_accuracy: 0.0742\n",
            "Epoch 25/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 5.9042 - accuracy: 0.0690 - val_loss: 6.5462 - val_accuracy: 0.0742\n",
            "Epoch 26/250\n",
            "9747/9747 [==============================] - 1s 69us/step - loss: 5.8849 - accuracy: 0.0683 - val_loss: 6.5380 - val_accuracy: 0.0742\n",
            "Epoch 27/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 5.8666 - accuracy: 0.0711 - val_loss: 6.5357 - val_accuracy: 0.0742\n",
            "Epoch 28/250\n",
            "9747/9747 [==============================] - 1s 70us/step - loss: 5.8554 - accuracy: 0.0718 - val_loss: 6.5320 - val_accuracy: 0.0742\n",
            "Epoch 29/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.8423 - accuracy: 0.0700 - val_loss: 6.5291 - val_accuracy: 0.0742\n",
            "Epoch 30/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 5.8324 - accuracy: 0.0705 - val_loss: 6.5306 - val_accuracy: 0.0742\n",
            "Epoch 31/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.8197 - accuracy: 0.0689 - val_loss: 6.5339 - val_accuracy: 0.0742\n",
            "Epoch 32/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.8142 - accuracy: 0.0693 - val_loss: 6.5409 - val_accuracy: 0.0742\n",
            "Epoch 33/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 5.8022 - accuracy: 0.0699 - val_loss: 6.5502 - val_accuracy: 0.0742\n",
            "Epoch 34/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 5.7976 - accuracy: 0.0712 - val_loss: 6.5628 - val_accuracy: 0.0742\n",
            "Epoch 35/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 5.7939 - accuracy: 0.0696 - val_loss: 6.5693 - val_accuracy: 0.0742\n",
            "Epoch 36/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 5.7827 - accuracy: 0.0714 - val_loss: 6.5789 - val_accuracy: 0.0742\n",
            "Epoch 37/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 5.7762 - accuracy: 0.0707 - val_loss: 6.5848 - val_accuracy: 0.0742\n",
            "Epoch 38/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 5.7768 - accuracy: 0.0706 - val_loss: 6.6006 - val_accuracy: 0.0742\n",
            "Epoch 39/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.7713 - accuracy: 0.0710 - val_loss: 6.6107 - val_accuracy: 0.0742\n",
            "Epoch 40/250\n",
            "9747/9747 [==============================] - 1s 69us/step - loss: 5.7668 - accuracy: 0.0707 - val_loss: 6.6214 - val_accuracy: 0.0742\n",
            "Epoch 41/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 5.7575 - accuracy: 0.0714 - val_loss: 6.6334 - val_accuracy: 0.0742\n",
            "Epoch 42/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 5.7539 - accuracy: 0.0716 - val_loss: 6.6448 - val_accuracy: 0.0742\n",
            "Epoch 43/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 5.7512 - accuracy: 0.0719 - val_loss: 6.6525 - val_accuracy: 0.0740\n",
            "Epoch 44/250\n",
            "9747/9747 [==============================] - 1s 69us/step - loss: 5.7462 - accuracy: 0.0716 - val_loss: 6.6583 - val_accuracy: 0.0737\n",
            "Epoch 45/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 5.7383 - accuracy: 0.0725 - val_loss: 6.6757 - val_accuracy: 0.0737\n",
            "Epoch 46/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 5.7402 - accuracy: 0.0729 - val_loss: 6.6849 - val_accuracy: 0.0737\n",
            "Epoch 47/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.7322 - accuracy: 0.0742 - val_loss: 6.6890 - val_accuracy: 0.0768\n",
            "Epoch 48/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 5.7209 - accuracy: 0.0763 - val_loss: 6.7008 - val_accuracy: 0.0768\n",
            "Epoch 49/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.7169 - accuracy: 0.0747 - val_loss: 6.7129 - val_accuracy: 0.0778\n",
            "Epoch 50/250\n",
            "9747/9747 [==============================] - 1s 70us/step - loss: 5.7015 - accuracy: 0.0793 - val_loss: 6.7225 - val_accuracy: 0.0761\n",
            "Epoch 51/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.6952 - accuracy: 0.0786 - val_loss: 6.7274 - val_accuracy: 0.0754\n",
            "Epoch 52/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.6854 - accuracy: 0.0811 - val_loss: 6.7359 - val_accuracy: 0.0761\n",
            "Epoch 53/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 5.6732 - accuracy: 0.0802 - val_loss: 6.7424 - val_accuracy: 0.0756\n",
            "Epoch 54/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 5.6661 - accuracy: 0.0805 - val_loss: 6.7583 - val_accuracy: 0.0759\n",
            "Epoch 55/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.6545 - accuracy: 0.0823 - val_loss: 6.7681 - val_accuracy: 0.0756\n",
            "Epoch 56/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 5.6505 - accuracy: 0.0849 - val_loss: 6.7753 - val_accuracy: 0.0756\n",
            "Epoch 57/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 5.6343 - accuracy: 0.0827 - val_loss: 6.7816 - val_accuracy: 0.0768\n",
            "Epoch 58/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 5.6296 - accuracy: 0.0841 - val_loss: 6.7875 - val_accuracy: 0.0775\n",
            "Epoch 59/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 5.6116 - accuracy: 0.0847 - val_loss: 6.7944 - val_accuracy: 0.0807\n",
            "Epoch 60/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 5.5968 - accuracy: 0.0868 - val_loss: 6.8091 - val_accuracy: 0.0814\n",
            "Epoch 61/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.5885 - accuracy: 0.0868 - val_loss: 6.8200 - val_accuracy: 0.0814\n",
            "Epoch 62/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 5.5676 - accuracy: 0.0881 - val_loss: 6.8243 - val_accuracy: 0.0809\n",
            "Epoch 63/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 5.5550 - accuracy: 0.0910 - val_loss: 6.8377 - val_accuracy: 0.0821\n",
            "Epoch 64/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 5.5376 - accuracy: 0.0906 - val_loss: 6.8540 - val_accuracy: 0.0833\n",
            "Epoch 65/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.5233 - accuracy: 0.0923 - val_loss: 6.8580 - val_accuracy: 0.0835\n",
            "Epoch 66/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 5.5107 - accuracy: 0.0938 - val_loss: 6.8676 - val_accuracy: 0.0838\n",
            "Epoch 67/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 5.4905 - accuracy: 0.0940 - val_loss: 6.8847 - val_accuracy: 0.0843\n",
            "Epoch 68/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.4722 - accuracy: 0.0936 - val_loss: 6.8981 - val_accuracy: 0.0859\n",
            "Epoch 69/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 5.4587 - accuracy: 0.0962 - val_loss: 6.9126 - val_accuracy: 0.0869\n",
            "Epoch 70/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.4412 - accuracy: 0.0953 - val_loss: 6.9244 - val_accuracy: 0.0876\n",
            "Epoch 71/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.4295 - accuracy: 0.0979 - val_loss: 6.9388 - val_accuracy: 0.0881\n",
            "Epoch 72/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 5.4135 - accuracy: 0.0977 - val_loss: 6.9569 - val_accuracy: 0.0876\n",
            "Epoch 73/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.3930 - accuracy: 0.1003 - val_loss: 6.9621 - val_accuracy: 0.0890\n",
            "Epoch 74/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 5.3766 - accuracy: 0.1002 - val_loss: 6.9870 - val_accuracy: 0.0907\n",
            "Epoch 75/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.3658 - accuracy: 0.1027 - val_loss: 7.0022 - val_accuracy: 0.0917\n",
            "Epoch 76/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 5.3512 - accuracy: 0.1017 - val_loss: 7.0225 - val_accuracy: 0.0907\n",
            "Epoch 77/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.3377 - accuracy: 0.1048 - val_loss: 7.0380 - val_accuracy: 0.0926\n",
            "Epoch 78/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.3171 - accuracy: 0.1046 - val_loss: 7.0456 - val_accuracy: 0.0914\n",
            "Epoch 79/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.2954 - accuracy: 0.1072 - val_loss: 7.0591 - val_accuracy: 0.0921\n",
            "Epoch 80/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 5.2879 - accuracy: 0.1083 - val_loss: 7.0786 - val_accuracy: 0.0921\n",
            "Epoch 81/250\n",
            "9747/9747 [==============================] - 1s 70us/step - loss: 5.2577 - accuracy: 0.1083 - val_loss: 7.0888 - val_accuracy: 0.0926\n",
            "Epoch 82/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 5.2445 - accuracy: 0.1098 - val_loss: 7.1149 - val_accuracy: 0.0926\n",
            "Epoch 83/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 5.2289 - accuracy: 0.1091 - val_loss: 7.1250 - val_accuracy: 0.0931\n",
            "Epoch 84/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.2079 - accuracy: 0.1105 - val_loss: 7.1382 - val_accuracy: 0.0941\n",
            "Epoch 85/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 5.1927 - accuracy: 0.1103 - val_loss: 7.1539 - val_accuracy: 0.0943\n",
            "Epoch 86/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 5.1719 - accuracy: 0.1135 - val_loss: 7.1787 - val_accuracy: 0.0948\n",
            "Epoch 87/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 5.1491 - accuracy: 0.1152 - val_loss: 7.1977 - val_accuracy: 0.0948\n",
            "Epoch 88/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 5.1323 - accuracy: 0.1147 - val_loss: 7.2080 - val_accuracy: 0.0960\n",
            "Epoch 89/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 5.1210 - accuracy: 0.1128 - val_loss: 7.2318 - val_accuracy: 0.0969\n",
            "Epoch 90/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.1064 - accuracy: 0.1169 - val_loss: 7.2545 - val_accuracy: 0.0943\n",
            "Epoch 91/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 5.0837 - accuracy: 0.1170 - val_loss: 7.2667 - val_accuracy: 0.0972\n",
            "Epoch 92/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 5.0706 - accuracy: 0.1192 - val_loss: 7.2947 - val_accuracy: 0.0965\n",
            "Epoch 93/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 5.0526 - accuracy: 0.1197 - val_loss: 7.3097 - val_accuracy: 0.0945\n",
            "Epoch 94/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 5.0353 - accuracy: 0.1205 - val_loss: 7.3316 - val_accuracy: 0.0962\n",
            "Epoch 95/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 5.0212 - accuracy: 0.1203 - val_loss: 7.3511 - val_accuracy: 0.0981\n",
            "Epoch 96/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 5.0078 - accuracy: 0.1247 - val_loss: 7.3730 - val_accuracy: 0.0965\n",
            "Epoch 97/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 4.9946 - accuracy: 0.1230 - val_loss: 7.3824 - val_accuracy: 0.0969\n",
            "Epoch 98/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.9785 - accuracy: 0.1253 - val_loss: 7.4038 - val_accuracy: 0.0974\n",
            "Epoch 99/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 4.9566 - accuracy: 0.1271 - val_loss: 7.4272 - val_accuracy: 0.1010\n",
            "Epoch 100/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.9516 - accuracy: 0.1277 - val_loss: 7.4397 - val_accuracy: 0.1044\n",
            "Epoch 101/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 4.9261 - accuracy: 0.1320 - val_loss: 7.4673 - val_accuracy: 0.1106\n",
            "Epoch 102/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.9204 - accuracy: 0.1346 - val_loss: 7.4779 - val_accuracy: 0.1099\n",
            "Epoch 103/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 4.8920 - accuracy: 0.1352 - val_loss: 7.5084 - val_accuracy: 0.1123\n",
            "Epoch 104/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 4.8817 - accuracy: 0.1391 - val_loss: 7.5179 - val_accuracy: 0.1132\n",
            "Epoch 105/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 4.8701 - accuracy: 0.1389 - val_loss: 7.5337 - val_accuracy: 0.1144\n",
            "Epoch 106/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.8475 - accuracy: 0.1379 - val_loss: 7.5639 - val_accuracy: 0.1146\n",
            "Epoch 107/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 4.8360 - accuracy: 0.1396 - val_loss: 7.5809 - val_accuracy: 0.1144\n",
            "Epoch 108/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 4.8237 - accuracy: 0.1423 - val_loss: 7.5933 - val_accuracy: 0.1130\n",
            "Epoch 109/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 4.8035 - accuracy: 0.1419 - val_loss: 7.6182 - val_accuracy: 0.1149\n",
            "Epoch 110/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 4.7889 - accuracy: 0.1450 - val_loss: 7.6410 - val_accuracy: 0.1142\n",
            "Epoch 111/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 4.7694 - accuracy: 0.1480 - val_loss: 7.6477 - val_accuracy: 0.1142\n",
            "Epoch 112/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 4.7568 - accuracy: 0.1476 - val_loss: 7.6652 - val_accuracy: 0.1146\n",
            "Epoch 113/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 4.7489 - accuracy: 0.1488 - val_loss: 7.6722 - val_accuracy: 0.1135\n",
            "Epoch 114/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 4.7211 - accuracy: 0.1469 - val_loss: 7.6954 - val_accuracy: 0.1130\n",
            "Epoch 115/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 4.7165 - accuracy: 0.1506 - val_loss: 7.7109 - val_accuracy: 0.1168\n",
            "Epoch 116/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 4.6944 - accuracy: 0.1490 - val_loss: 7.7332 - val_accuracy: 0.1161\n",
            "Epoch 117/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.6788 - accuracy: 0.1521 - val_loss: 7.7532 - val_accuracy: 0.1149\n",
            "Epoch 118/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 4.6500 - accuracy: 0.1515 - val_loss: 7.7656 - val_accuracy: 0.1175\n",
            "Epoch 119/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 4.6393 - accuracy: 0.1536 - val_loss: 7.7801 - val_accuracy: 0.1158\n",
            "Epoch 120/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 4.6151 - accuracy: 0.1565 - val_loss: 7.7966 - val_accuracy: 0.1170\n",
            "Epoch 121/250\n",
            "9747/9747 [==============================] - 1s 70us/step - loss: 4.6052 - accuracy: 0.1559 - val_loss: 7.8319 - val_accuracy: 0.1187\n",
            "Epoch 122/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.5858 - accuracy: 0.1575 - val_loss: 7.8458 - val_accuracy: 0.1170\n",
            "Epoch 123/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 4.5677 - accuracy: 0.1587 - val_loss: 7.8680 - val_accuracy: 0.1194\n",
            "Epoch 124/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.5605 - accuracy: 0.1559 - val_loss: 7.8813 - val_accuracy: 0.1211\n",
            "Epoch 125/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 4.5396 - accuracy: 0.1584 - val_loss: 7.8935 - val_accuracy: 0.1178\n",
            "Epoch 126/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 4.5242 - accuracy: 0.1623 - val_loss: 7.9139 - val_accuracy: 0.1192\n",
            "Epoch 127/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 4.4934 - accuracy: 0.1638 - val_loss: 7.9384 - val_accuracy: 0.1190\n",
            "Epoch 128/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 4.4795 - accuracy: 0.1624 - val_loss: 7.9647 - val_accuracy: 0.1187\n",
            "Epoch 129/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 4.4577 - accuracy: 0.1646 - val_loss: 7.9614 - val_accuracy: 0.1185\n",
            "Epoch 130/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 4.4426 - accuracy: 0.1633 - val_loss: 7.9856 - val_accuracy: 0.1192\n",
            "Epoch 131/250\n",
            "9747/9747 [==============================] - 1s 72us/step - loss: 4.4234 - accuracy: 0.1664 - val_loss: 8.0088 - val_accuracy: 0.1204\n",
            "Epoch 132/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 4.4122 - accuracy: 0.1699 - val_loss: 8.0320 - val_accuracy: 0.1216\n",
            "Epoch 133/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.3832 - accuracy: 0.1691 - val_loss: 8.0455 - val_accuracy: 0.1194\n",
            "Epoch 134/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 4.3667 - accuracy: 0.1740 - val_loss: 8.0757 - val_accuracy: 0.1213\n",
            "Epoch 135/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.3523 - accuracy: 0.1731 - val_loss: 8.1122 - val_accuracy: 0.1216\n",
            "Epoch 136/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 4.3268 - accuracy: 0.1754 - val_loss: 8.1251 - val_accuracy: 0.1223\n",
            "Epoch 137/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 4.3112 - accuracy: 0.1741 - val_loss: 8.1779 - val_accuracy: 0.1216\n",
            "Epoch 138/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 4.2876 - accuracy: 0.1775 - val_loss: 8.1541 - val_accuracy: 0.1204\n",
            "Epoch 139/250\n",
            "9747/9747 [==============================] - 1s 70us/step - loss: 4.2789 - accuracy: 0.1761 - val_loss: 8.2126 - val_accuracy: 0.1225\n",
            "Epoch 140/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 4.2601 - accuracy: 0.1781 - val_loss: 8.2431 - val_accuracy: 0.1221\n",
            "Epoch 141/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 4.2360 - accuracy: 0.1816 - val_loss: 8.2471 - val_accuracy: 0.1228\n",
            "Epoch 142/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 4.2265 - accuracy: 0.1765 - val_loss: 8.2905 - val_accuracy: 0.1237\n",
            "Epoch 143/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 4.2058 - accuracy: 0.1857 - val_loss: 8.3050 - val_accuracy: 0.1216\n",
            "Epoch 144/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 4.1863 - accuracy: 0.1849 - val_loss: 8.3274 - val_accuracy: 0.1233\n",
            "Epoch 145/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 4.1706 - accuracy: 0.1845 - val_loss: 8.3512 - val_accuracy: 0.1235\n",
            "Epoch 146/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.1605 - accuracy: 0.1860 - val_loss: 8.3843 - val_accuracy: 0.1223\n",
            "Epoch 147/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 4.1435 - accuracy: 0.1853 - val_loss: 8.3970 - val_accuracy: 0.1223\n",
            "Epoch 148/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 4.1275 - accuracy: 0.1914 - val_loss: 8.4392 - val_accuracy: 0.1233\n",
            "Epoch 149/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 4.1050 - accuracy: 0.1911 - val_loss: 8.4471 - val_accuracy: 0.1228\n",
            "Epoch 150/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 4.0912 - accuracy: 0.1901 - val_loss: 8.4893 - val_accuracy: 0.1209\n",
            "Epoch 151/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 4.0807 - accuracy: 0.1908 - val_loss: 8.5185 - val_accuracy: 0.1230\n",
            "Epoch 152/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 4.0651 - accuracy: 0.1947 - val_loss: 8.5418 - val_accuracy: 0.1242\n",
            "Epoch 153/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 4.0357 - accuracy: 0.1930 - val_loss: 8.5818 - val_accuracy: 0.1245\n",
            "Epoch 154/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 4.0308 - accuracy: 0.1951 - val_loss: 8.5959 - val_accuracy: 0.1247\n",
            "Epoch 155/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 4.0114 - accuracy: 0.2024 - val_loss: 8.6314 - val_accuracy: 0.1245\n",
            "Epoch 156/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 4.0065 - accuracy: 0.1965 - val_loss: 8.6593 - val_accuracy: 0.1257\n",
            "Epoch 157/250\n",
            "9747/9747 [==============================] - 1s 70us/step - loss: 3.9902 - accuracy: 0.2010 - val_loss: 8.6967 - val_accuracy: 0.1237\n",
            "Epoch 158/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 3.9770 - accuracy: 0.1993 - val_loss: 8.6960 - val_accuracy: 0.1235\n",
            "Epoch 159/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 3.9580 - accuracy: 0.2030 - val_loss: 8.7619 - val_accuracy: 0.1235\n",
            "Epoch 160/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.9446 - accuracy: 0.2072 - val_loss: 8.7852 - val_accuracy: 0.1230\n",
            "Epoch 161/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.9292 - accuracy: 0.2056 - val_loss: 8.7965 - val_accuracy: 0.1223\n",
            "Epoch 162/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 3.9205 - accuracy: 0.2078 - val_loss: 8.8574 - val_accuracy: 0.1245\n",
            "Epoch 163/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 3.9073 - accuracy: 0.2025 - val_loss: 8.8373 - val_accuracy: 0.1221\n",
            "Epoch 164/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.8858 - accuracy: 0.2084 - val_loss: 8.8966 - val_accuracy: 0.1230\n",
            "Epoch 165/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.8776 - accuracy: 0.2097 - val_loss: 8.9034 - val_accuracy: 0.1257\n",
            "Epoch 166/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.8593 - accuracy: 0.2130 - val_loss: 8.9527 - val_accuracy: 0.1247\n",
            "Epoch 167/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 3.8561 - accuracy: 0.2080 - val_loss: 8.9637 - val_accuracy: 0.1233\n",
            "Epoch 168/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 3.8301 - accuracy: 0.2151 - val_loss: 9.0008 - val_accuracy: 0.1237\n",
            "Epoch 169/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.8314 - accuracy: 0.2139 - val_loss: 9.0138 - val_accuracy: 0.1245\n",
            "Epoch 170/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.8016 - accuracy: 0.2156 - val_loss: 9.0533 - val_accuracy: 0.1223\n",
            "Epoch 171/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 3.7736 - accuracy: 0.2172 - val_loss: 9.1031 - val_accuracy: 0.1242\n",
            "Epoch 172/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 3.7877 - accuracy: 0.2170 - val_loss: 9.1163 - val_accuracy: 0.1228\n",
            "Epoch 173/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.7559 - accuracy: 0.2175 - val_loss: 9.1788 - val_accuracy: 0.1249\n",
            "Epoch 174/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.7559 - accuracy: 0.2231 - val_loss: 9.1887 - val_accuracy: 0.1242\n",
            "Epoch 175/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.7437 - accuracy: 0.2202 - val_loss: 9.2324 - val_accuracy: 0.1202\n",
            "Epoch 176/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.7362 - accuracy: 0.2174 - val_loss: 9.2354 - val_accuracy: 0.1204\n",
            "Epoch 177/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 3.7112 - accuracy: 0.2206 - val_loss: 9.2713 - val_accuracy: 0.1204\n",
            "Epoch 178/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 3.7042 - accuracy: 0.2213 - val_loss: 9.2766 - val_accuracy: 0.1211\n",
            "Epoch 179/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 3.6908 - accuracy: 0.2259 - val_loss: 9.3476 - val_accuracy: 0.1233\n",
            "Epoch 180/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.6708 - accuracy: 0.2284 - val_loss: 9.3437 - val_accuracy: 0.1211\n",
            "Epoch 181/250\n",
            "9747/9747 [==============================] - 1s 69us/step - loss: 3.6582 - accuracy: 0.2295 - val_loss: 9.4010 - val_accuracy: 0.1225\n",
            "Epoch 182/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.6526 - accuracy: 0.2302 - val_loss: 9.4377 - val_accuracy: 0.1209\n",
            "Epoch 183/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 3.6319 - accuracy: 0.2313 - val_loss: 9.4456 - val_accuracy: 0.1223\n",
            "Epoch 184/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 3.6266 - accuracy: 0.2329 - val_loss: 9.4784 - val_accuracy: 0.1199\n",
            "Epoch 185/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 3.6195 - accuracy: 0.2348 - val_loss: 9.5335 - val_accuracy: 0.1218\n",
            "Epoch 186/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.6000 - accuracy: 0.2341 - val_loss: 9.5167 - val_accuracy: 0.1202\n",
            "Epoch 187/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 3.5906 - accuracy: 0.2379 - val_loss: 9.5483 - val_accuracy: 0.1211\n",
            "Epoch 188/250\n",
            "9747/9747 [==============================] - 1s 68us/step - loss: 3.5888 - accuracy: 0.2308 - val_loss: 9.5833 - val_accuracy: 0.1197\n",
            "Epoch 189/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 3.5569 - accuracy: 0.2373 - val_loss: 9.6089 - val_accuracy: 0.1204\n",
            "Epoch 190/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.5558 - accuracy: 0.2389 - val_loss: 9.6477 - val_accuracy: 0.1209\n",
            "Epoch 191/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.5477 - accuracy: 0.2427 - val_loss: 9.6638 - val_accuracy: 0.1211\n",
            "Epoch 192/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.5323 - accuracy: 0.2365 - val_loss: 9.7076 - val_accuracy: 0.1202\n",
            "Epoch 193/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 3.5272 - accuracy: 0.2410 - val_loss: 9.6811 - val_accuracy: 0.1182\n",
            "Epoch 194/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.5080 - accuracy: 0.2420 - val_loss: 9.7648 - val_accuracy: 0.1185\n",
            "Epoch 195/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.4956 - accuracy: 0.2472 - val_loss: 9.7461 - val_accuracy: 0.1180\n",
            "Epoch 196/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 3.4811 - accuracy: 0.2472 - val_loss: 9.8177 - val_accuracy: 0.1180\n",
            "Epoch 197/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 3.4797 - accuracy: 0.2478 - val_loss: 9.8202 - val_accuracy: 0.1192\n",
            "Epoch 198/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.4625 - accuracy: 0.2506 - val_loss: 9.8616 - val_accuracy: 0.1173\n",
            "Epoch 199/250\n",
            "9747/9747 [==============================] - 1s 70us/step - loss: 3.4406 - accuracy: 0.2533 - val_loss: 9.9283 - val_accuracy: 0.1180\n",
            "Epoch 200/250\n",
            "9747/9747 [==============================] - 1s 69us/step - loss: 3.4387 - accuracy: 0.2541 - val_loss: 9.8972 - val_accuracy: 0.1149\n",
            "Epoch 201/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.4343 - accuracy: 0.2535 - val_loss: 9.9785 - val_accuracy: 0.1204\n",
            "Epoch 202/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 3.4117 - accuracy: 0.2545 - val_loss: 9.9323 - val_accuracy: 0.1190\n",
            "Epoch 203/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.4083 - accuracy: 0.2548 - val_loss: 10.0347 - val_accuracy: 0.1158\n",
            "Epoch 204/250\n",
            "9747/9747 [==============================] - 1s 69us/step - loss: 3.3861 - accuracy: 0.2595 - val_loss: 10.0224 - val_accuracy: 0.1170\n",
            "Epoch 205/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 3.3748 - accuracy: 0.2591 - val_loss: 10.0881 - val_accuracy: 0.1190\n",
            "Epoch 206/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 3.3664 - accuracy: 0.2605 - val_loss: 10.0964 - val_accuracy: 0.1168\n",
            "Epoch 207/250\n",
            "9747/9747 [==============================] - 1s 60us/step - loss: 3.3455 - accuracy: 0.2647 - val_loss: 10.1300 - val_accuracy: 0.1166\n",
            "Epoch 208/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.3277 - accuracy: 0.2677 - val_loss: 10.1861 - val_accuracy: 0.1168\n",
            "Epoch 209/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 3.3325 - accuracy: 0.2610 - val_loss: 10.1874 - val_accuracy: 0.1158\n",
            "Epoch 210/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 3.3265 - accuracy: 0.2687 - val_loss: 10.2536 - val_accuracy: 0.1180\n",
            "Epoch 211/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.3003 - accuracy: 0.2689 - val_loss: 10.2309 - val_accuracy: 0.1137\n",
            "Epoch 212/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 3.3072 - accuracy: 0.2680 - val_loss: 10.3039 - val_accuracy: 0.1158\n",
            "Epoch 213/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.2872 - accuracy: 0.2729 - val_loss: 10.3060 - val_accuracy: 0.1156\n",
            "Epoch 214/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 3.2812 - accuracy: 0.2687 - val_loss: 10.3366 - val_accuracy: 0.1146\n",
            "Epoch 215/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.2667 - accuracy: 0.2718 - val_loss: 10.3522 - val_accuracy: 0.1158\n",
            "Epoch 216/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.2484 - accuracy: 0.2722 - val_loss: 10.3875 - val_accuracy: 0.1146\n",
            "Epoch 217/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 3.2453 - accuracy: 0.2770 - val_loss: 10.4056 - val_accuracy: 0.1154\n",
            "Epoch 218/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 3.2313 - accuracy: 0.2800 - val_loss: 10.4374 - val_accuracy: 0.1149\n",
            "Epoch 219/250\n",
            "9747/9747 [==============================] - 1s 59us/step - loss: 3.2152 - accuracy: 0.2782 - val_loss: 10.4720 - val_accuracy: 0.1135\n",
            "Epoch 220/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.2029 - accuracy: 0.2807 - val_loss: 10.4944 - val_accuracy: 0.1149\n",
            "Epoch 221/250\n",
            "9747/9747 [==============================] - 1s 59us/step - loss: 3.1928 - accuracy: 0.2823 - val_loss: 10.4997 - val_accuracy: 0.1142\n",
            "Epoch 222/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.1861 - accuracy: 0.2850 - val_loss: 10.5895 - val_accuracy: 0.1161\n",
            "Epoch 223/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.1724 - accuracy: 0.2831 - val_loss: 10.5986 - val_accuracy: 0.1142\n",
            "Epoch 224/250\n",
            "9747/9747 [==============================] - 1s 60us/step - loss: 3.1670 - accuracy: 0.2850 - val_loss: 10.6148 - val_accuracy: 0.1127\n",
            "Epoch 225/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.1681 - accuracy: 0.2894 - val_loss: 10.6461 - val_accuracy: 0.1144\n",
            "Epoch 226/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 3.1556 - accuracy: 0.2876 - val_loss: 10.6630 - val_accuracy: 0.1149\n",
            "Epoch 227/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 3.1406 - accuracy: 0.2902 - val_loss: 10.6951 - val_accuracy: 0.1149\n",
            "Epoch 228/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 3.1162 - accuracy: 0.2937 - val_loss: 10.7255 - val_accuracy: 0.1161\n",
            "Epoch 229/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.1043 - accuracy: 0.2962 - val_loss: 10.7524 - val_accuracy: 0.1156\n",
            "Epoch 230/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 3.1018 - accuracy: 0.2891 - val_loss: 10.8000 - val_accuracy: 0.1137\n",
            "Epoch 231/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 3.0807 - accuracy: 0.2967 - val_loss: 10.8299 - val_accuracy: 0.1139\n",
            "Epoch 232/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.0548 - accuracy: 0.2966 - val_loss: 10.8657 - val_accuracy: 0.1127\n",
            "Epoch 233/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 3.0571 - accuracy: 0.3032 - val_loss: 10.8620 - val_accuracy: 0.1132\n",
            "Epoch 234/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 3.0571 - accuracy: 0.3006 - val_loss: 10.9301 - val_accuracy: 0.1144\n",
            "Epoch 235/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.0523 - accuracy: 0.2992 - val_loss: 10.8750 - val_accuracy: 0.1130\n",
            "Epoch 236/250\n",
            "9747/9747 [==============================] - 1s 61us/step - loss: 3.0331 - accuracy: 0.3037 - val_loss: 10.9815 - val_accuracy: 0.1115\n",
            "Epoch 237/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 3.0255 - accuracy: 0.3092 - val_loss: 10.9658 - val_accuracy: 0.1132\n",
            "Epoch 238/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 3.0110 - accuracy: 0.3088 - val_loss: 11.0408 - val_accuracy: 0.1130\n",
            "Epoch 239/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 2.9998 - accuracy: 0.3079 - val_loss: 11.0266 - val_accuracy: 0.1118\n",
            "Epoch 240/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 2.9726 - accuracy: 0.3125 - val_loss: 11.0959 - val_accuracy: 0.1149\n",
            "Epoch 241/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 2.9742 - accuracy: 0.3176 - val_loss: 11.0826 - val_accuracy: 0.1120\n",
            "Epoch 242/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 2.9721 - accuracy: 0.3106 - val_loss: 11.1359 - val_accuracy: 0.1103\n",
            "Epoch 243/250\n",
            "9747/9747 [==============================] - 1s 67us/step - loss: 2.9493 - accuracy: 0.3228 - val_loss: 11.1702 - val_accuracy: 0.1127\n",
            "Epoch 244/250\n",
            "9747/9747 [==============================] - 1s 63us/step - loss: 2.9342 - accuracy: 0.3207 - val_loss: 11.1820 - val_accuracy: 0.1120\n",
            "Epoch 245/250\n",
            "9747/9747 [==============================] - 1s 66us/step - loss: 2.9439 - accuracy: 0.3189 - val_loss: 11.2316 - val_accuracy: 0.1127\n",
            "Epoch 246/250\n",
            "9747/9747 [==============================] - 1s 62us/step - loss: 2.9165 - accuracy: 0.3162 - val_loss: 11.2713 - val_accuracy: 0.1123\n",
            "Epoch 247/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 2.9182 - accuracy: 0.3196 - val_loss: 11.2756 - val_accuracy: 0.1135\n",
            "Epoch 248/250\n",
            "9747/9747 [==============================] - 1s 65us/step - loss: 2.9004 - accuracy: 0.3229 - val_loss: 11.3085 - val_accuracy: 0.1144\n",
            "Epoch 249/250\n",
            "9747/9747 [==============================] - 1s 64us/step - loss: 2.8929 - accuracy: 0.3244 - val_loss: 11.3219 - val_accuracy: 0.1135\n",
            "Epoch 250/250\n",
            "9747/9747 [==============================] - 1s 60us/step - loss: 2.8882 - accuracy: 0.3251 - val_loss: 11.3426 - val_accuracy: 0.1118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-AP8swgwKuL",
        "colab_type": "text"
      },
      "source": [
        "## Compare Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ5j11YH-Ilt",
        "colab_type": "text"
      },
      "source": [
        "<tr>\n",
        "    <th>Name of Model</th>\n",
        "    <th>LTSM Layers</th>\n",
        "    <th>Bidirectional</th>\n",
        "    <th>Trainable Embeddings</th>\n",
        "    <th>Sequence Length</th>\n",
        "    <th>LSTM Dropout</th>\n",
        "    <th>LSTM Recurrent Dropout</th>\n",
        "    <th>Val Loss</th>\n",
        "    <th>Val Accuracy</th>\n",
        "</tr>\n",
        "<!-- <tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>50</td>\n",
        "    <td>0.1</td>\n",
        "    <td>0.1</td>\n",
        "    <td>6.5235</td>\n",
        "    <td>0.1715</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>50</td>\n",
        "    <td>0.2</td>\n",
        "    <td>0.2</td>\n",
        "    <td>6.4229</td>\n",
        "    <td>0.1706</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>50</td>\n",
        "    <td>0.5</td>\n",
        "    <td>0.5</td>\n",
        "    <td>6.2247</td>\n",
        "    <td>0.1638</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>20</td>\n",
        "    <td>0.1</td>\n",
        "    <td>0.1</td>\n",
        "    <td>6.4449</td>\n",
        "    <td>0.1725</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>20</td>\n",
        "    <td>0.2</td>\n",
        "    <td>0.2</td>\n",
        "    <td>6.2899</td>\n",
        "    <td>0.1706</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>20</td>\n",
        "    <td>0.5</td>\n",
        "    <td>0.5</td>\n",
        "    <td>6.1667</td>\n",
        "    <td>0.1719</td>\n",
        "</tr> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4sO-VEvxo27",
        "colab_type": "text"
      },
      "source": [
        "# Sample Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYttbKDgsWU-",
        "colab_type": "text"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TYDcQIf6-Yz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "693a5f21-f7a1-4598-fc82-8c7c2cd5ef8d"
      },
      "source": [
        "from keras.models import load_model\n",
        "# Get Model Weights and Architecture\n",
        "\n",
        "# MODELS_DIR = os.path.join(os.path.dirname(os.path.abspath('')), 'models')\n",
        "MODELS_DIR = '/content/drive/My Drive/Code/autocomplete_me/models'\n",
        "model_filepath = os.path.join(MODELS_DIR, f'{content_type}_uni-1_layer-trainable-20_seq.h5')\n",
        "\n",
        "model = load_model(model_filepath)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHGsZlQj6-b6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0ddcbbba-6d66-4a0f-ec81-0a8cecd5d3fd"
      },
      "source": [
        "# Get Text Data\n",
        "TRAINING_LENGTH = 50\n",
        "training_dict, word_idx, idx_word, sequences, num_words = utils.get_data(text, training_len=TRAINING_LENGTH)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 3659 unique words.\n",
            "There are 4272 sequences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaZAatAF6-hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_sequence, gen_list, a = predict_utils.generate_output(\n",
        "    model,\n",
        "    sequences,\n",
        "    idx_word,\n",
        "    seed_length=TRAINING_LENGTH,\n",
        "    new_words=50,\n",
        "    diversity=1,\n",
        "    n_gen=1\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64w4-h_e7Jr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3668576c-5d88-4c60-bb6f-ff803f4b2ce1"
      },
      "source": [
        "' '.join(word for word in original_sequence)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'was all finished , the Owl , as a boon , Was kindly permitted to pocket the spoon: While the Panther received knife and fork with a growl , And concluded the banquet-- ‘What IS the use of repeating all that stuff ,’ the Mock Turtle interrupted , ‘if you'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1jQ8g547Ju7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a0e4136b-0995-4642-b26d-292980de51d7"
      },
      "source": [
        "' '.join(word for word in gen_list[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'< --- > mouse who sobbing all added on them his for at they some knows crowd want second all hall faster WATCH that if , my into mark ever she thing ’ again Alice)--‘and at like fair Mock head have like same'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3UVTdcZ7Jz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c83ac00c-e65b-4a72-86d8-2fb9bae60d0b"
      },
      "source": [
        "sentence = 'Stocks of major large technology firms are becoming'\n",
        "predict_utils.generate_custom_sentence(sentence, word_idx, idx_word, model, new_words=50)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[None, 6, None, 130, None, None, 106, 3366]\n",
            "‘It (look taking weeks ready not Mouse tell leaves told who advance dreadfully ‘All little it ‘It’s then door such or to put I’ll I were ,’ time when ‘’Tis door of an ‘Would up ?’ it’s the arches words better killing sitting do:-- purple perfectly do of she ‘You’ll\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG6xgAXVu0Og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}