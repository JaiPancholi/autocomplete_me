{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Trump.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRwiWNu6INq5",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5LjiPvdBUHV",
        "colab_type": "text"
      },
      "source": [
        "## Google Only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjSCr2_-BUHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a5ebfb89-6b4a-4001-fbd1-0f7cd862d192"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvs4RSdij9st",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAJzt-moBUHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
        "sys.path.append('/content/drive/My Drive/Code/autocomplete_me')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3cVnuFRvRK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "356b79f1-a058-4d9d-e718-0ec5b9159c54"
      },
      "source": [
        "!ls -l '/content/drive/My Drive/Code/autocomplete_me/src'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 19\n",
            "-rw------- 1 root root 2516 Jul 12 14:10 predict_utils.py\n",
            "drwx------ 2 root root 4096 Jul 12 14:39 __pycache__\n",
            "-rw------- 1 root root 2673 Jul 12 14:38 reader.py\n",
            "-rw------- 1 root root 9341 Jul 12 14:24 utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q94gYQGGBUHe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "daed1b66-6639-4c85-f8e6-c601ed22acf7"
      },
      "source": [
        "from src import utils, reader, predict_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK5LK2ohBUHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9369ce6-ffac-423a-dbaf-95cfa2bda885"
      },
      "source": [
        "from importlib import reload\n",
        "reload(utils)\n",
        "reload(reader)\n",
        "reload(predict_utils)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'src.predict_utils' from '/content/drive/My Drive/Code/autocomplete_me/src/predict_utils.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2i_aQqeF444",
        "colab_type": "text"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6ACaCZLF9wP",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGdkdzSeBUHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "198da9e4-0106-491d-ec9a-5a3f5e050b8e"
      },
      "source": [
        "text = reader.read_trump_tweet()\n",
        "content_type = 'Twitter - Trump'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFB5H3BdLHAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f03db7d2-aa6d-4721-f8c2-856489e831d7"
      },
      "source": [
        "text[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'New documents just released reveal General Flynn was telling the truth, and the FBI knew it! @OANN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ptgRgRReTyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text[:10000] # crashes at 400K"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jTtRx-nX8Ol",
        "colab_type": "text"
      },
      "source": [
        "### Short Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvyKn6MjXaXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ba0c84a5-8530-49d6-ed3d-a042e35cf956"
      },
      "source": [
        "training_dict, word_idx, idx_word, sequences, num_words = utils.get_data(text, training_len=10, short=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 23406 unique words.\n",
            "There are 174910 sequences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4XMvOm0Zd6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74e5027b-d574-46c9-c1a8-fdf431886233"
      },
      "source": [
        "len(training_dict)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp7d0n2qXkuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "ea8e8d76-d395-41cb-f32f-31768950be50"
      },
      "source": [
        "# embedding_matrix = utils.create_embedding_matrix(word_idx, num_words, '/Users/jaipancholi/data/glove.6B.100d.txt')\n",
        "embedding_matrix = utils.create_embedding_matrix(word_idx, num_words, '/content/drive/My Drive/Code/autocomplete_me/data/glove.6B.100d.txt')\n",
        "embedding_matrix"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove Vectors loading with dimension 100\n",
            "There were 15016 words without pre-trained embeddings.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Code/autocomplete_me/src/utils.py:180: RuntimeWarning: invalid value encountered in true_divide\n",
            "  embedding_matrix = embedding_matrix / np.linalg.norm(embedding_matrix, axis=1).reshape((-1, 1))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.06223089,  0.03835242,  0.08488411, ..., -0.04284497,\n",
              "         0.08662399, -0.00527513],\n",
              "       [-0.01938821,  0.01990321,  0.10770387, ..., -0.14973777,\n",
              "         0.08155941,  0.0148697 ],\n",
              "       ...,\n",
              "       [ 0.07559662,  0.09019867, -0.1500041 , ..., -0.0066243 ,\n",
              "         0.01093789,  0.03745238],\n",
              "       [ 0.10883924, -0.06250692,  0.10208854, ...,  0.07560617,\n",
              "        -0.03567615,  0.05948319],\n",
              "       [ 0.03400484, -0.2261346 , -0.040496  , ...,  0.06427987,\n",
              "        -0.01206196,  0.06095745]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO9SeBF0vGRb",
        "colab_type": "text"
      },
      "source": [
        "#### Unidirectional, 1 layer, Trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFcGJJduuqw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = utils.make_word_level_model(\n",
        "    num_words,\n",
        "    embedding_matrix,\n",
        "    lstm_cells=64,\n",
        "    trainable=True,\n",
        "    lstm_layers=1,\n",
        "    bi_direc=False\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EycVkVjAutzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "e8ad63dd-cd6b-413f-ea20-35210fa85105"
      },
      "source": [
        "history = utils.train_model(\n",
        "    training_dict,\n",
        "    f'{content_type}_uni-1_layer-trainable-20_seq',\n",
        "    # model=model,\n",
        "    use_pretrained_model=True,\n",
        "    epochs=250\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "122436/122436 [==============================] - 15s 124us/step - loss: 2.6609 - accuracy: 0.4122 - val_loss: 12.9202 - val_accuracy: 0.1689\n",
            "Epoch 148/250\n",
            " 77824/122436 [==================>...........] - ETA: 4s - loss: 2.6281 - accuracy: 0.4171"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/drive/My Drive/Code/autocomplete_me/src/utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(training_dict, model_filename, model, use_pretrained_model, epochs)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c81c88e389a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# model=model,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0muse_pretrained_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/content/drive/My Drive/Code/autocomplete_me/src/utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(training_dict, model_filename, model, use_pretrained_model, epochs)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'history' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-AP8swgwKuL",
        "colab_type": "text"
      },
      "source": [
        "## Compare Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ5j11YH-Ilt",
        "colab_type": "text"
      },
      "source": [
        "<tr>\n",
        "    <th>Name of Model</th>\n",
        "    <th>LTSM Layers</th>\n",
        "    <th>Bidirectional</th>\n",
        "    <th>Trainable Embeddings</th>\n",
        "    <th>Sequence Length</th>\n",
        "    <th>LSTM Dropout</th>\n",
        "    <th>LSTM Recurrent Dropout</th>\n",
        "    <th>Val Loss</th>\n",
        "    <th>Val Accuracy</th>\n",
        "</tr>\n",
        "<!-- <tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>50</td>\n",
        "    <td>0.1</td>\n",
        "    <td>0.1</td>\n",
        "    <td>6.5235</td>\n",
        "    <td>0.1715</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>50</td>\n",
        "    <td>0.2</td>\n",
        "    <td>0.2</td>\n",
        "    <td>6.4229</td>\n",
        "    <td>0.1706</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>50</td>\n",
        "    <td>0.5</td>\n",
        "    <td>0.5</td>\n",
        "    <td>6.2247</td>\n",
        "    <td>0.1638</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>20</td>\n",
        "    <td>0.1</td>\n",
        "    <td>0.1</td>\n",
        "    <td>6.4449</td>\n",
        "    <td>0.1725</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>20</td>\n",
        "    <td>0.2</td>\n",
        "    <td>0.2</td>\n",
        "    <td>6.2899</td>\n",
        "    <td>0.1706</td>\n",
        "</tr>\n",
        "<tr>\n",
        "    <td></td>\n",
        "    <td>1</td>\n",
        "    <td>False</td>\n",
        "    <td>True</td>\n",
        "    <td>20</td>\n",
        "    <td>0.5</td>\n",
        "    <td>0.5</td>\n",
        "    <td>6.1667</td>\n",
        "    <td>0.1719</td>\n",
        "</tr> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4sO-VEvxo27",
        "colab_type": "text"
      },
      "source": [
        "# Sample Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYttbKDgsWU-",
        "colab_type": "text"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TYDcQIf6-Yz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ad51018d-4822-4c38-994a-a4f4b17589ad"
      },
      "source": [
        "from keras.models import load_model\n",
        "# Get Model Weights and Architecture\n",
        "\n",
        "# MODELS_DIR = os.path.join(os.path.dirname(os.path.abspath('')), 'models')\n",
        "MODELS_DIR = '/content/drive/My Drive/Code/autocomplete_me/models'\n",
        "model_filepath = os.path.join(MODELS_DIR, f'{content_type}_uni-1_layer-trainable-20_seq.h5')\n",
        "\n",
        "model = load_model(model_filepath)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHGsZlQj6-b6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "11beaafe-56fa-4ad1-b2d6-f8ff8c042356"
      },
      "source": [
        "# Get Text Data\n",
        "TRAINING_LENGTH = 50\n",
        "training_dict, word_idx, idx_word, sequences, num_words = utils.get_data(text, training_len=TRAINING_LENGTH)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 23406 unique words.\n",
            "There are 22 sequences.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaZAatAF6-hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_sequence, gen_list, a = predict_utils.generate_output(\n",
        "    model,\n",
        "    sequences,\n",
        "    idx_word,\n",
        "    seed_length=TRAINING_LENGTH,\n",
        "    new_words=50,\n",
        "    diversity=1,\n",
        "    n_gen=1\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64w4-h_e7Jr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "231496c8-ed4b-45dd-fad7-2a556bc76667"
      },
      "source": [
        "' '.join(word for word in original_sequence)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'us to get out of these ridiculous Endless Wars , many of them tribal , and bring our soldiers home . WE WILL FIGHT WHERE IT IS TO OUR BENEFIT , AND ONLY FIGHT TO WIN . Turkey , Europe , Syria , Iran , Iraq , Russia and the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1jQ8g547Ju7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb1e9942-6766-45d4-fad3-4c9bc892a167"
      },
      "source": [
        "' '.join(word for word in gen_list[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'< --- > . of This heard •Seeks , and no impacted ,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3UVTdcZ7Jz1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d0d7f4c6-cfdd-4e68-c12c-205d063804f4"
      },
      "source": [
        "sentence = 'Stocks of major large technology firms are becoming'\n",
        "predict_utils.generate_custom_sentence(sentence, word_idx, idx_word, model, new_words=50)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4052, 6, 520, 642, 2983, 6522, 15, 2331]\n",
            "getting honor are did are looking to keep a really Left job long against him that Infrastructure , on ZERO exit on what to make lets come more long Manchin of the foreign hit work with heights Taylor: .taxpayer was great specifically made we want &amp any light of got\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG6xgAXVu0Og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}